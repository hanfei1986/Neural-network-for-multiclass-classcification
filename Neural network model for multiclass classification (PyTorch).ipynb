{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df.dropna(subset=['Credit_Score'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = df.columns.tolist()\n",
    "x_columns.remove('Credit_Score')\n",
    "X = df[x_columns]\n",
    "y = df['Credit_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class Data_Transformer(object):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.mean_age = X[\"Age\"].mean()\n",
    "        self.occu_le = LabelEncoder() # create label-encoder\n",
    "        encoded_occupation = pd.Series(self.occu_le.fit_transform(X[\"Occupation\"])) # fit and transform occupation with label-encoder\n",
    "        self.majority_occupation = encoded_occupation.mode()[0] # obtain majority occupation code\n",
    "        self.mean_annual_income = X[\"Annual_Income\"].mean()\n",
    "        self.mean_monthly_inhand_salary = X[\"Monthly_Inhand_Salary\"].mean()\n",
    "        self.mean_num_bank_accounts = X[\"Num_Bank_Accounts\"].mean()\n",
    "        self.mean_num_creadit_card = X[\"Num_Credit_Card\"].mean()\n",
    "        self.mean_num_interest_rate = X['Interest_Rate'].mean()\n",
    "        self.mean_num_of_loan = X['Num_of_Loan'].mean()\n",
    "        self.mean_delay_from_due_date = X['Delay_from_due_date'].mean()\n",
    "        self.mean_num_of_delayed_payment = X['Num_of_Delayed_Payment'].mean()\n",
    "        self.mean_changed_credit_limit = X['Changed_Credit_Limit'].mean()\n",
    "        self.mean_num_credit_inquiries = X['Num_Credit_Inquiries'].mean()\n",
    "        self.cm_le = LabelEncoder() # create label-encoder\n",
    "        encoded_credit_mix = pd.Series(self.cm_le.fit_transform(X[\"Credit_Mix\"])) # fit and transform credit mix with label-encoder\n",
    "        self.majority_credit_mix = encoded_credit_mix.mode()[0] # obtain majority credit mix code\n",
    "        self.mean_outstanding_debt = X['Outstanding_Debt'].mean()\n",
    "        self.mean_credit_history_age = X['Credit_History_Age'].mean()\n",
    "        self.pma_le = LabelEncoder() # create label-encoder\n",
    "        encoded_payment_of_min_amount = pd.Series(self.pma_le.fit_transform(X[\"Payment_of_Min_Amount\"])) # fit and transform payment of min amount with label-encoder\n",
    "        self.majority_payment_of_min_amount = encoded_payment_of_min_amount.mode()[0] # obtain majority payment of min amount\n",
    "        self.mean_total_EMI_per_month = X['Total_EMI_per_month'].mean()\n",
    "        self.mean_amount_invested_monthly = X['Amount_invested_monthly'].mean()\n",
    "        self.pb_le = LabelEncoder() # create label-encoder\n",
    "        encoded_payment_behaviour = pd.Series(self.pb_le.fit_transform(X[\"Payment_Behaviour\"])) # fit and transform payment behaviour with label-encoder\n",
    "        self.majority_payment_behaviour = encoded_payment_behaviour.mode()[0] # obtain majority payment behaviour\n",
    "        self.mean_monthly_balance = X['Monthly_Balance'].mean()\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Age\"] = X[\"Age\"]\n",
    "        new_df[\"Age\"].fillna(self.mean_age,inplace=True)\n",
    "        new_df[\"Occupation\"] = self.occu_le.transform(X[\"Occupation\"])\n",
    "        new_df[\"Occupation\"].fillna(self.majority_occupation,inplace=True)\n",
    "        new_df[\"Annual_Income\"] = X[\"Annual_Income\"]\n",
    "        new_df[\"Annual_Income\"].fillna(self.mean_annual_income,inplace=True)\n",
    "        new_df[\"Monthly_Inhand_Salary\"] = X[\"Monthly_Inhand_Salary\"]\n",
    "        new_df[\"Monthly_Inhand_Salary\"].fillna(self.mean_monthly_inhand_salary,inplace=True)\n",
    "        new_df[\"Num_Bank_Accounts\"] = X[\"Num_Bank_Accounts\"]\n",
    "        new_df[\"Num_Bank_Accounts\"].fillna(self.mean_num_bank_accounts,inplace=True)\n",
    "        new_df[\"Num_Credit_Card\"] = X[\"Num_Credit_Card\"]\n",
    "        new_df[\"Num_Credit_Card\"].fillna(self.mean_num_creadit_card,inplace=True)\n",
    "        new_df[\"Interest_Rate\"] = X[\"Interest_Rate\"]\n",
    "        new_df[\"Interest_Rate\"].fillna(self.mean_num_interest_rate,inplace=True)\n",
    "        new_df[\"Num_of_Loan\"] = X[\"Num_of_Loan\"]\n",
    "        new_df[\"Num_of_Loan\"].fillna(self.mean_num_of_loan,inplace=True)\n",
    "        new_df[\"Delay_from_due_date\"] = X[\"Delay_from_due_date\"]\n",
    "        new_df[\"Delay_from_due_date\"].fillna(self.mean_delay_from_due_date,inplace=True)\n",
    "        new_df[\"Num_of_Delayed_Payment\"] = X[\"Num_of_Delayed_Payment\"]\n",
    "        new_df[\"Num_of_Delayed_Payment\"].fillna(self.mean_num_of_delayed_payment,inplace=True)\n",
    "        new_df[\"Changed_Credit_Limit\"] = X[\"Changed_Credit_Limit\"]\n",
    "        new_df[\"Changed_Credit_Limit\"].fillna(self.mean_changed_credit_limit,inplace=True)\n",
    "        new_df[\"Num_Credit_Inquiries\"] = X[\"Num_Credit_Inquiries\"]\n",
    "        new_df[\"Num_Credit_Inquiries\"].fillna(self.mean_num_credit_inquiries,inplace=True)\n",
    "        new_df[\"Credit_Mix\"] = self.cm_le.transform(X[\"Credit_Mix\"])\n",
    "        new_df[\"Credit_Mix\"].fillna(self.majority_credit_mix,inplace=True)\n",
    "        new_df[\"Outstanding_Debt\"] = X[\"Outstanding_Debt\"]\n",
    "        new_df[\"Outstanding_Debt\"].fillna(self.mean_outstanding_debt,inplace=True)\n",
    "        new_df[\"Credit_History_Age\"] = X[\"Credit_History_Age\"]\n",
    "        new_df[\"Credit_History_Age\"].fillna(self.mean_credit_history_age,inplace=True)\n",
    "        new_df[\"Payment_of_Min_Amount\"] = self.pma_le.transform(X[\"Payment_of_Min_Amount\"])\n",
    "        new_df[\"Payment_of_Min_Amount\"].fillna(self.majority_payment_of_min_amount,inplace=True)\n",
    "        new_df[\"Total_EMI_per_month\"] = X[\"Total_EMI_per_month\"]\n",
    "        new_df[\"Total_EMI_per_month\"].fillna(self.mean_total_EMI_per_month,inplace=True)\n",
    "        new_df[\"Amount_invested_monthly\"] = X[\"Amount_invested_monthly\"]\n",
    "        new_df[\"Amount_invested_monthly\"].fillna(self.mean_amount_invested_monthly,inplace=True)\n",
    "        new_df[\"Payment_Behaviour\"] = self.pb_le.transform(X[\"Payment_Behaviour\"])\n",
    "        new_df[\"Payment_Behaviour\"].fillna(self.majority_payment_behaviour,inplace=True)\n",
    "        new_df[\"Monthly_Balance\"] = X[\"Monthly_Balance\"]\n",
    "        new_df[\"Monthly_Balance\"].fillna(self.mean_monthly_balance,inplace=True)\n",
    "        return new_df\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch.classifier import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 3)\n",
    "        #If binary classification, last layer outputs 2 values\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.softmax(self.fc3(x), dim=1)\n",
    "        #If binary classification, last layer uses nn.functional.sigmoid\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler():\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = self.scaler.transform(X)\n",
    "        return torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps =[('dtf', Data_Transformer()),\n",
    "        ('rescale', CustomScaler()),\n",
    "        ('nn_model', NeuralNetClassifier(module=NeuralNetwork, device='cuda' if torch.cuda.is_available() else 'cpu'))]\n",
    "        #If binary classification, nn_model uses NeuralNetBinaryClassifier \n",
    "model = Pipeline(steps)\n",
    "param_grid = {'nn_model__batch_size': [32, 64],\n",
    "                'nn_model__max_epochs': [10, 50, 100],\n",
    "                'nn_model__lr': [0.01, 0.1],\n",
    "                'nn_model__optimizer': [optim.Adam, optim.RMSprop]}\n",
    "model_gsv = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, scoring=make_scorer(recall_score, average='micro', greater_is_better=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8229\u001b[0m       \u001b[32m0.6580\u001b[0m        \u001b[35m0.7258\u001b[0m  0.2216\n",
      "      2        \u001b[36m0.7053\u001b[0m       \u001b[32m0.6710\u001b[0m        \u001b[35m0.7085\u001b[0m  0.1422\n",
      "      3        \u001b[36m0.6727\u001b[0m       \u001b[32m0.6910\u001b[0m        \u001b[35m0.6870\u001b[0m  0.1487\n",
      "      4        \u001b[36m0.6557\u001b[0m       \u001b[32m0.6990\u001b[0m        0.6890  0.1462\n",
      "      5        \u001b[36m0.6449\u001b[0m       0.6990        \u001b[35m0.6800\u001b[0m  0.1502\n",
      "      6        \u001b[36m0.6349\u001b[0m       \u001b[32m0.7030\u001b[0m        \u001b[35m0.6665\u001b[0m  0.1542\n",
      "      7        \u001b[36m0.6255\u001b[0m       0.7010        \u001b[35m0.6665\u001b[0m  0.1500\n",
      "      8        \u001b[36m0.6206\u001b[0m       0.7030        \u001b[35m0.6595\u001b[0m  0.1490\n",
      "      9        \u001b[36m0.6153\u001b[0m       0.6990        0.6740  0.1498\n",
      "     10        \u001b[36m0.6129\u001b[0m       0.6990        0.6603  0.1501\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7834\u001b[0m       \u001b[32m0.6670\u001b[0m        \u001b[35m0.7393\u001b[0m  0.1590\n",
      "      2        \u001b[36m0.6747\u001b[0m       \u001b[32m0.7190\u001b[0m        \u001b[35m0.6912\u001b[0m  0.1507\n",
      "      3        \u001b[36m0.6403\u001b[0m       \u001b[32m0.7480\u001b[0m        \u001b[35m0.6284\u001b[0m  0.1436\n",
      "      4        \u001b[36m0.6251\u001b[0m       0.7470        \u001b[35m0.6221\u001b[0m  0.1612\n",
      "      5        \u001b[36m0.6190\u001b[0m       \u001b[32m0.7490\u001b[0m        0.6231  0.1570\n",
      "      6        \u001b[36m0.6157\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6072\u001b[0m  0.1439\n",
      "      7        \u001b[36m0.6106\u001b[0m       \u001b[32m0.7530\u001b[0m        0.6128  0.1520\n",
      "      8        \u001b[36m0.6078\u001b[0m       \u001b[32m0.7550\u001b[0m        \u001b[35m0.6071\u001b[0m  0.1452\n",
      "      9        \u001b[36m0.6050\u001b[0m       \u001b[32m0.7590\u001b[0m        \u001b[35m0.6053\u001b[0m  0.1479\n",
      "     10        \u001b[36m0.6049\u001b[0m       0.7490        0.6210  0.1501\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8577\u001b[0m       \u001b[32m0.6620\u001b[0m        \u001b[35m0.7373\u001b[0m  0.1255\n",
      "      2        \u001b[36m0.6852\u001b[0m       \u001b[32m0.7000\u001b[0m        \u001b[35m0.7000\u001b[0m  0.1252\n",
      "      3        \u001b[36m0.6549\u001b[0m       0.7000        \u001b[35m0.6907\u001b[0m  0.1276\n",
      "      4        \u001b[36m0.6443\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.6761\u001b[0m  0.1260\n",
      "      5        \u001b[36m0.6384\u001b[0m       \u001b[32m0.7180\u001b[0m        \u001b[35m0.6661\u001b[0m  0.1253\n",
      "      6        \u001b[36m0.6320\u001b[0m       0.7060        0.6724  0.1231\n",
      "      7        \u001b[36m0.6278\u001b[0m       0.7110        \u001b[35m0.6567\u001b[0m  0.1262\n",
      "      8        \u001b[36m0.6233\u001b[0m       0.7170        \u001b[35m0.6558\u001b[0m  0.1167\n",
      "      9        \u001b[36m0.6197\u001b[0m       \u001b[32m0.7240\u001b[0m        0.6575  0.1226\n",
      "     10        \u001b[36m0.6155\u001b[0m       \u001b[32m0.7270\u001b[0m        0.6565  0.1288\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7746\u001b[0m       \u001b[32m0.5020\u001b[0m        \u001b[35m1.1173\u001b[0m  0.1359\n",
      "      2        \u001b[36m0.6586\u001b[0m       \u001b[32m0.5550\u001b[0m        \u001b[35m0.8896\u001b[0m  0.1502\n",
      "      3        \u001b[36m0.6366\u001b[0m       \u001b[32m0.6070\u001b[0m        \u001b[35m0.8388\u001b[0m  0.1331\n",
      "      4        \u001b[36m0.6276\u001b[0m       \u001b[32m0.6350\u001b[0m        \u001b[35m0.7880\u001b[0m  0.1298\n",
      "      5        \u001b[36m0.6221\u001b[0m       \u001b[32m0.6520\u001b[0m        \u001b[35m0.7649\u001b[0m  0.1339\n",
      "      6        \u001b[36m0.6170\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.7594\u001b[0m  0.1339\n",
      "      7        \u001b[36m0.6151\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m0.7352\u001b[0m  0.1292\n",
      "      8        \u001b[36m0.6114\u001b[0m       0.6750        0.7443  0.1219\n",
      "      9        \u001b[36m0.6086\u001b[0m       0.6780        0.7535  0.1321\n",
      "     10        \u001b[36m0.6057\u001b[0m       \u001b[32m0.6830\u001b[0m        0.7447  0.1273\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7941\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m0.7586\u001b[0m  0.1410\n",
      "      2        \u001b[36m0.7049\u001b[0m       \u001b[32m0.6780\u001b[0m        \u001b[35m0.7006\u001b[0m  0.1419\n",
      "      3        \u001b[36m0.6677\u001b[0m       \u001b[32m0.6880\u001b[0m        0.7018  0.1454\n",
      "      4        \u001b[36m0.6537\u001b[0m       \u001b[32m0.6980\u001b[0m        \u001b[35m0.6890\u001b[0m  0.1409\n",
      "      5        \u001b[36m0.6431\u001b[0m       \u001b[32m0.7030\u001b[0m        \u001b[35m0.6820\u001b[0m  0.1445\n",
      "      6        \u001b[36m0.6338\u001b[0m       0.6950        \u001b[35m0.6698\u001b[0m  0.1422\n",
      "      7        \u001b[36m0.6258\u001b[0m       0.6950        \u001b[35m0.6646\u001b[0m  0.1577\n",
      "      8        \u001b[36m0.6203\u001b[0m       0.7030        \u001b[35m0.6527\u001b[0m  0.1529\n",
      "      9        \u001b[36m0.6121\u001b[0m       0.6990        0.6619  0.1550\n",
      "     10        0.6127       0.6980        0.6527  0.1589\n",
      "     11        \u001b[36m0.6090\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6507\u001b[0m  0.1664\n",
      "     12        \u001b[36m0.6019\u001b[0m       0.7010        0.6510  0.1614\n",
      "     13        \u001b[36m0.5992\u001b[0m       0.7050        0.6513  0.1612\n",
      "     14        \u001b[36m0.5967\u001b[0m       \u001b[32m0.7060\u001b[0m        \u001b[35m0.6505\u001b[0m  0.1472\n",
      "     15        \u001b[36m0.5925\u001b[0m       0.7050        0.6661  0.1505\n",
      "     16        \u001b[36m0.5915\u001b[0m       \u001b[32m0.7140\u001b[0m        0.6625  0.1526\n",
      "     17        \u001b[36m0.5893\u001b[0m       0.7130        0.6612  0.1445\n",
      "     18        \u001b[36m0.5881\u001b[0m       \u001b[32m0.7160\u001b[0m        0.6669  0.1483\n",
      "     19        \u001b[36m0.5849\u001b[0m       0.7130        0.6681  0.1512\n",
      "     20        0.5884       \u001b[32m0.7200\u001b[0m        0.6832  0.1600\n",
      "     21        \u001b[36m0.5817\u001b[0m       0.7100        0.6694  0.1532\n",
      "     22        \u001b[36m0.5801\u001b[0m       0.7130        0.6654  0.1490\n",
      "     23        \u001b[36m0.5783\u001b[0m       0.7160        0.6819  0.1482\n",
      "     24        \u001b[36m0.5771\u001b[0m       0.7140        0.6691  0.1465\n",
      "     25        \u001b[36m0.5745\u001b[0m       0.7160        0.6714  0.1741\n",
      "     26        \u001b[36m0.5737\u001b[0m       0.7200        0.6658  0.1508\n",
      "     27        \u001b[36m0.5716\u001b[0m       0.7170        0.6518  0.1427\n",
      "     28        \u001b[36m0.5706\u001b[0m       0.7140        0.6611  0.1455\n",
      "     29        0.5739       0.7190        0.6535  0.1479\n",
      "     30        0.5720       \u001b[32m0.7210\u001b[0m        0.6567  0.1523\n",
      "     31        \u001b[36m0.5653\u001b[0m       0.7200        0.6634  0.1563\n",
      "     32        \u001b[36m0.5635\u001b[0m       0.7200        0.6625  0.1568\n",
      "     33        \u001b[36m0.5621\u001b[0m       0.7180        0.6593  0.1484\n",
      "     34        0.5623       0.7120        0.6620  0.1571\n",
      "     35        \u001b[36m0.5611\u001b[0m       0.7100        0.6749  0.1439\n",
      "     36        \u001b[36m0.5594\u001b[0m       0.7180        0.6800  0.1475\n",
      "     37        0.5608       0.7090        0.6844  0.1479\n",
      "     38        0.5606       0.7160        0.6834  0.1504\n",
      "     39        \u001b[36m0.5593\u001b[0m       0.7130        0.6876  0.1543\n",
      "     40        0.5605       \u001b[32m0.7270\u001b[0m        0.6889  0.1516\n",
      "     41        \u001b[36m0.5527\u001b[0m       0.7230        0.6950  0.1528\n",
      "     42        0.5531       0.7200        0.6860  0.1577\n",
      "     43        \u001b[36m0.5521\u001b[0m       0.7220        0.6891  0.1638\n",
      "     44        0.5522       0.7260        0.6902  0.1898\n",
      "     45        \u001b[36m0.5500\u001b[0m       0.7230        0.6967  0.1654\n",
      "     46        0.5532       \u001b[32m0.7320\u001b[0m        0.7237  0.1668\n",
      "     47        \u001b[36m0.5487\u001b[0m       0.7200        0.6895  0.1480\n",
      "     48        0.5493       0.7140        0.7253  0.1596\n",
      "     49        \u001b[36m0.5479\u001b[0m       0.7230        0.6922  0.1599\n",
      "     50        \u001b[36m0.5456\u001b[0m       0.7240        0.7076  0.1514\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7696\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.7140\u001b[0m  0.1409\n",
      "      2        \u001b[36m0.6623\u001b[0m       \u001b[32m0.7270\u001b[0m        \u001b[35m0.6627\u001b[0m  0.1465\n",
      "      3        \u001b[36m0.6381\u001b[0m       \u001b[32m0.7340\u001b[0m        \u001b[35m0.6402\u001b[0m  0.1445\n",
      "      4        \u001b[36m0.6267\u001b[0m       \u001b[32m0.7510\u001b[0m        \u001b[35m0.6195\u001b[0m  0.1611\n",
      "      5        \u001b[36m0.6176\u001b[0m       0.7490        0.6213  0.1398\n",
      "      6        \u001b[36m0.6135\u001b[0m       \u001b[32m0.7540\u001b[0m        \u001b[35m0.6188\u001b[0m  0.1698\n",
      "      7        \u001b[36m0.6132\u001b[0m       \u001b[32m0.7550\u001b[0m        \u001b[35m0.6169\u001b[0m  0.1495\n",
      "      8        \u001b[36m0.6095\u001b[0m       0.7460        0.6219  0.1621\n",
      "      9        0.6102       0.7550        0.6206  0.1558\n",
      "     10        \u001b[36m0.6062\u001b[0m       0.7480        \u001b[35m0.6157\u001b[0m  0.1654\n",
      "     11        \u001b[36m0.6027\u001b[0m       \u001b[32m0.7570\u001b[0m        \u001b[35m0.6110\u001b[0m  0.1384\n",
      "     12        \u001b[36m0.5991\u001b[0m       0.7570        \u001b[35m0.6062\u001b[0m  0.1670\n",
      "     13        0.6004       0.7550        \u001b[35m0.6047\u001b[0m  0.1478\n",
      "     14        \u001b[36m0.5956\u001b[0m       0.7570        \u001b[35m0.6022\u001b[0m  0.1694\n",
      "     15        0.5960       \u001b[32m0.7580\u001b[0m        \u001b[35m0.5977\u001b[0m  0.1559\n",
      "     16        \u001b[36m0.5926\u001b[0m       0.7570        \u001b[35m0.5936\u001b[0m  0.1746\n",
      "     17        \u001b[36m0.5903\u001b[0m       \u001b[32m0.7590\u001b[0m        0.6041  0.1644\n",
      "     18        \u001b[36m0.5883\u001b[0m       \u001b[32m0.7620\u001b[0m        \u001b[35m0.5924\u001b[0m  0.1693\n",
      "     19        \u001b[36m0.5869\u001b[0m       \u001b[32m0.7650\u001b[0m        \u001b[35m0.5895\u001b[0m  0.1615\n",
      "     20        0.5873       \u001b[32m0.7690\u001b[0m        0.5950  0.1603\n",
      "     21        \u001b[36m0.5833\u001b[0m       0.7650        0.5992  0.1739\n",
      "     22        \u001b[36m0.5812\u001b[0m       0.7610        \u001b[35m0.5822\u001b[0m  0.1604\n",
      "     23        \u001b[36m0.5805\u001b[0m       0.7590        0.5991  0.1553\n",
      "     24        \u001b[36m0.5797\u001b[0m       0.7590        0.6044  0.1696\n",
      "     25        \u001b[36m0.5761\u001b[0m       0.7630        0.6051  0.1472\n",
      "     26        \u001b[36m0.5745\u001b[0m       0.7630        0.5984  0.1574\n",
      "     27        0.5748       0.7610        0.5944  0.1704\n",
      "     28        \u001b[36m0.5686\u001b[0m       \u001b[32m0.7720\u001b[0m        0.6042  0.1457\n",
      "     29        \u001b[36m0.5665\u001b[0m       0.7640        0.5938  0.1569\n",
      "     30        0.5682       0.7680        0.6018  0.1578\n",
      "     31        \u001b[36m0.5649\u001b[0m       0.7700        0.6069  0.1467\n",
      "     32        \u001b[36m0.5609\u001b[0m       0.7630        0.6080  0.1541\n",
      "     33        0.5624       0.7590        0.6153  0.1907\n",
      "     34        \u001b[36m0.5596\u001b[0m       0.7580        0.6145  0.1616\n",
      "     35        \u001b[36m0.5543\u001b[0m       0.7560        0.6160  0.1604\n",
      "     36        0.5586       0.7550        0.6277  0.1570\n",
      "     37        0.5573       0.7650        0.6217  0.1641\n",
      "     38        \u001b[36m0.5532\u001b[0m       0.7570        0.6278  0.1587\n",
      "     39        \u001b[36m0.5501\u001b[0m       0.7490        0.6383  0.1604\n",
      "     40        \u001b[36m0.5485\u001b[0m       0.7530        0.6361  0.1483\n",
      "     41        \u001b[36m0.5465\u001b[0m       0.7550        0.6297  0.1510\n",
      "     42        0.5471       0.7570        0.6328  0.1473\n",
      "     43        0.5536       0.7300        0.6568  0.1538\n",
      "     44        0.5489       0.7470        0.6454  0.1545\n",
      "     45        0.5486       0.7250        0.6529  0.1621\n",
      "     46        \u001b[36m0.5431\u001b[0m       0.7380        0.6458  0.1630\n",
      "     47        \u001b[36m0.5392\u001b[0m       0.7440        0.6638  0.1559\n",
      "     48        0.5408       0.7420        0.6509  0.1603\n",
      "     49        0.5489       0.7330        0.6818  0.1621\n",
      "     50        0.5444       0.7280        0.6528  0.1634\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7998\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.6840\u001b[0m  0.1354\n",
      "      2        \u001b[36m0.6662\u001b[0m       0.7110        \u001b[35m0.6579\u001b[0m  0.1381\n",
      "      3        \u001b[36m0.6389\u001b[0m       \u001b[32m0.7240\u001b[0m        \u001b[35m0.6472\u001b[0m  0.1377\n",
      "      4        \u001b[36m0.6285\u001b[0m       0.7230        \u001b[35m0.6460\u001b[0m  0.1311\n",
      "      5        \u001b[36m0.6221\u001b[0m       0.7220        \u001b[35m0.6457\u001b[0m  0.1360\n",
      "      6        \u001b[36m0.6172\u001b[0m       0.7140        \u001b[35m0.6409\u001b[0m  0.1534\n",
      "      7        \u001b[36m0.6093\u001b[0m       \u001b[32m0.7260\u001b[0m        0.6438  0.1298\n",
      "      8        \u001b[36m0.6063\u001b[0m       0.7160        \u001b[35m0.6404\u001b[0m  0.1384\n",
      "      9        \u001b[36m0.6017\u001b[0m       0.7150        0.6449  0.1374\n",
      "     10        \u001b[36m0.5993\u001b[0m       0.7110        0.6432  0.1400\n",
      "     11        \u001b[36m0.5959\u001b[0m       0.7070        0.6483  0.1283\n",
      "     12        \u001b[36m0.5936\u001b[0m       0.7200        0.6458  0.1340\n",
      "     13        \u001b[36m0.5906\u001b[0m       0.7140        0.6558  0.1274\n",
      "     14        \u001b[36m0.5872\u001b[0m       0.7130        0.6494  0.1346\n",
      "     15        \u001b[36m0.5856\u001b[0m       0.7220        0.6606  0.1478\n",
      "     16        \u001b[36m0.5842\u001b[0m       0.7200        0.6599  0.1320\n",
      "     17        \u001b[36m0.5820\u001b[0m       0.7160        0.6568  0.1292\n",
      "     18        \u001b[36m0.5802\u001b[0m       0.7200        0.6690  0.1248\n",
      "     19        \u001b[36m0.5767\u001b[0m       0.7200        0.6616  0.1310\n",
      "     20        0.5789       0.7080        0.6691  0.1294\n",
      "     21        \u001b[36m0.5748\u001b[0m       0.7160        0.6614  0.1339\n",
      "     22        \u001b[36m0.5747\u001b[0m       0.7140        0.6684  0.1265\n",
      "     23        0.5754       0.7110        0.6762  0.1309\n",
      "     24        \u001b[36m0.5739\u001b[0m       0.7170        0.6772  0.1274\n",
      "     25        \u001b[36m0.5728\u001b[0m       0.7120        0.6740  0.1275\n",
      "     26        0.5728       0.7110        0.6732  0.1274\n",
      "     27        \u001b[36m0.5709\u001b[0m       0.7130        0.6728  0.1229\n",
      "     28        0.5732       0.7140        0.6778  0.1258\n",
      "     29        \u001b[36m0.5693\u001b[0m       0.7110        0.6951  0.1257\n",
      "     30        \u001b[36m0.5687\u001b[0m       0.7060        0.6890  0.1262\n",
      "     31        0.5726       0.7070        0.6851  0.1289\n",
      "     32        \u001b[36m0.5680\u001b[0m       0.7150        0.6805  0.1392\n",
      "     33        \u001b[36m0.5630\u001b[0m       0.7100        0.6979  0.1257\n",
      "     34        0.5653       0.7100        0.6947  0.1212\n",
      "     35        0.5665       0.7130        0.6833  0.1459\n",
      "     36        \u001b[36m0.5623\u001b[0m       0.6970        0.7216  0.1255\n",
      "     37        \u001b[36m0.5615\u001b[0m       0.6990        0.6857  0.1278\n",
      "     38        \u001b[36m0.5580\u001b[0m       0.7040        0.6766  0.1251\n",
      "     39        0.5600       0.7050        0.6797  0.1296\n",
      "     40        0.5582       0.7140        0.6835  0.1268\n",
      "     41        \u001b[36m0.5568\u001b[0m       0.7010        0.6883  0.1252\n",
      "     42        0.5586       0.7030        0.7006  0.1326\n",
      "     43        \u001b[36m0.5549\u001b[0m       0.7010        0.6992  0.1279\n",
      "     44        \u001b[36m0.5531\u001b[0m       0.6980        0.7040  0.1317\n",
      "     45        0.5535       0.7060        0.7120  0.1272\n",
      "     46        0.5545       0.7110        0.7311  0.1294\n",
      "     47        \u001b[36m0.5517\u001b[0m       0.7030        0.7179  0.1268\n",
      "     48        \u001b[36m0.5491\u001b[0m       0.7060        0.7340  0.1292\n",
      "     49        0.5512       0.7090        0.7253  0.1273\n",
      "     50        \u001b[36m0.5474\u001b[0m       0.7000        0.7252  0.1276\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8004\u001b[0m       \u001b[32m0.4950\u001b[0m        \u001b[35m1.3286\u001b[0m  0.1242\n",
      "      2        \u001b[36m0.6819\u001b[0m       \u001b[32m0.5510\u001b[0m        \u001b[35m0.9541\u001b[0m  0.1232\n",
      "      3        \u001b[36m0.6471\u001b[0m       \u001b[32m0.5800\u001b[0m        \u001b[35m0.8810\u001b[0m  0.1267\n",
      "      4        \u001b[36m0.6350\u001b[0m       \u001b[32m0.5990\u001b[0m        \u001b[35m0.8413\u001b[0m  0.1288\n",
      "      5        \u001b[36m0.6289\u001b[0m       \u001b[32m0.6350\u001b[0m        \u001b[35m0.7823\u001b[0m  0.1257\n",
      "      6        \u001b[36m0.6232\u001b[0m       \u001b[32m0.6460\u001b[0m        \u001b[35m0.7597\u001b[0m  0.1273\n",
      "      7        \u001b[36m0.6192\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.7390\u001b[0m  0.1293\n",
      "      8        \u001b[36m0.6178\u001b[0m       0.6730        0.7607  0.1314\n",
      "      9        \u001b[36m0.6132\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.7282\u001b[0m  0.1233\n",
      "     10        \u001b[36m0.6123\u001b[0m       0.6920        \u001b[35m0.7251\u001b[0m  0.1264\n",
      "     11        \u001b[36m0.6089\u001b[0m       0.6260        0.7901  0.1242\n",
      "     12        \u001b[36m0.6080\u001b[0m       0.6740        0.7292  0.1240\n",
      "     13        \u001b[36m0.6034\u001b[0m       0.6690        0.7308  0.1251\n",
      "     14        \u001b[36m0.6018\u001b[0m       0.6880        \u001b[35m0.7217\u001b[0m  0.1262\n",
      "     15        \u001b[36m0.5990\u001b[0m       0.6850        \u001b[35m0.7199\u001b[0m  0.1264\n",
      "     16        \u001b[36m0.5984\u001b[0m       0.6810        0.7311  0.1265\n",
      "     17        \u001b[36m0.5959\u001b[0m       0.6730        0.7368  0.1264\n",
      "     18        \u001b[36m0.5951\u001b[0m       0.6610        0.7477  0.1247\n",
      "     19        \u001b[36m0.5931\u001b[0m       0.6950        \u001b[35m0.7049\u001b[0m  0.1264\n",
      "     20        \u001b[36m0.5903\u001b[0m       0.6900        0.7061  0.1256\n",
      "     21        \u001b[36m0.5893\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.6902\u001b[0m  0.1375\n",
      "     22        \u001b[36m0.5871\u001b[0m       0.7050        0.7057  0.1222\n",
      "     23        0.5880       0.6900        0.7189  0.1265\n",
      "     24        \u001b[36m0.5853\u001b[0m       0.6910        0.7146  0.1271\n",
      "     25        \u001b[36m0.5832\u001b[0m       0.6990        0.6960  0.1265\n",
      "     26        \u001b[36m0.5810\u001b[0m       0.6930        0.7101  0.1272\n",
      "     27        \u001b[36m0.5788\u001b[0m       0.6870        0.7222  0.1256\n",
      "     28        \u001b[36m0.5766\u001b[0m       0.6840        0.7136  0.1217\n",
      "     29        \u001b[36m0.5730\u001b[0m       0.6990        0.6996  0.1244\n",
      "     30        \u001b[36m0.5728\u001b[0m       0.6860        0.7124  0.1392\n",
      "     31        \u001b[36m0.5695\u001b[0m       0.6860        0.7122  0.1271\n",
      "     32        0.5713       0.6800        0.7108  0.1267\n",
      "     33        \u001b[36m0.5657\u001b[0m       0.6540        0.7793  0.1286\n",
      "     34        0.5713       0.6800        0.7165  0.1314\n",
      "     35        \u001b[36m0.5646\u001b[0m       0.6870        0.7067  0.1328\n",
      "     36        0.5651       0.6940        \u001b[35m0.6859\u001b[0m  0.1293\n",
      "     37        \u001b[36m0.5618\u001b[0m       0.7140        0.6878  0.1359\n",
      "     38        0.5623       0.7080        0.6933  0.1483\n",
      "     39        \u001b[36m0.5599\u001b[0m       0.7100        0.6927  0.1287\n",
      "     40        \u001b[36m0.5580\u001b[0m       0.6950        0.7021  0.1356\n",
      "     41        \u001b[36m0.5566\u001b[0m       0.7060        0.7013  0.1330\n",
      "     42        \u001b[36m0.5559\u001b[0m       0.7040        0.6952  0.1379\n",
      "     43        0.5568       0.6740        0.7382  0.1319\n",
      "     44        0.5586       0.7040        0.6991  0.1337\n",
      "     45        0.5564       0.7000        0.7105  0.1343\n",
      "     46        \u001b[36m0.5513\u001b[0m       0.6890        0.7152  0.1385\n",
      "     47        0.5527       0.7090        0.7060  0.1321\n",
      "     48        0.5534       0.6950        0.7242  0.1376\n",
      "     49        \u001b[36m0.5493\u001b[0m       0.7080        0.7131  0.1398\n",
      "     50        0.5498       0.7030        0.7308  0.1391\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8294\u001b[0m       \u001b[32m0.6260\u001b[0m        \u001b[35m0.7595\u001b[0m  0.1338\n",
      "      2        \u001b[36m0.7237\u001b[0m       \u001b[32m0.6770\u001b[0m        \u001b[35m0.7030\u001b[0m  0.1412\n",
      "      3        \u001b[36m0.6748\u001b[0m       \u001b[32m0.6910\u001b[0m        \u001b[35m0.6932\u001b[0m  0.1434\n",
      "      4        \u001b[36m0.6546\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.6795\u001b[0m  0.1386\n",
      "      5        \u001b[36m0.6459\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6712\u001b[0m  0.1409\n",
      "      6        \u001b[36m0.6342\u001b[0m       0.7010        0.6737  0.1477\n",
      "      7        \u001b[36m0.6275\u001b[0m       \u001b[32m0.7190\u001b[0m        \u001b[35m0.6567\u001b[0m  0.1684\n",
      "      8        \u001b[36m0.6226\u001b[0m       0.7050        0.6595  0.1528\n",
      "      9        \u001b[36m0.6182\u001b[0m       0.7150        \u001b[35m0.6548\u001b[0m  0.1546\n",
      "     10        \u001b[36m0.6135\u001b[0m       0.7030        0.6608  0.1591\n",
      "     11        \u001b[36m0.6104\u001b[0m       0.7070        0.6575  0.1645\n",
      "     12        \u001b[36m0.6075\u001b[0m       0.7150        0.6656  0.1584\n",
      "     13        \u001b[36m0.6048\u001b[0m       0.7110        0.6640  0.1672\n",
      "     14        \u001b[36m0.6021\u001b[0m       0.7070        0.6681  0.1463\n",
      "     15        \u001b[36m0.5978\u001b[0m       0.7090        0.6684  0.1549\n",
      "     16        \u001b[36m0.5958\u001b[0m       0.6980        0.6830  0.1610\n",
      "     17        0.5977       0.7110        0.6780  0.1598\n",
      "     18        \u001b[36m0.5952\u001b[0m       0.7070        0.6773  0.1615\n",
      "     19        \u001b[36m0.5933\u001b[0m       0.7100        0.6698  0.1637\n",
      "     20        \u001b[36m0.5879\u001b[0m       0.6990        0.6773  0.1738\n",
      "     21        0.5881       0.7020        0.6739  0.1586\n",
      "     22        \u001b[36m0.5856\u001b[0m       0.7040        0.6647  0.1573\n",
      "     23        \u001b[36m0.5819\u001b[0m       0.7060        0.6696  0.1659\n",
      "     24        \u001b[36m0.5800\u001b[0m       0.7050        0.6611  0.1602\n",
      "     25        \u001b[36m0.5796\u001b[0m       0.7120        0.6733  0.1590\n",
      "     26        0.5806       0.7000        0.6679  0.1563\n",
      "     27        \u001b[36m0.5765\u001b[0m       0.7070        0.6695  0.1759\n",
      "     28        \u001b[36m0.5734\u001b[0m       0.7140        0.6733  0.1566\n",
      "     29        \u001b[36m0.5725\u001b[0m       0.7080        0.6683  0.1650\n",
      "     30        \u001b[36m0.5717\u001b[0m       0.7050        0.6603  0.1619\n",
      "     31        0.5783       0.7060        \u001b[35m0.6526\u001b[0m  0.1588\n",
      "     32        \u001b[36m0.5669\u001b[0m       0.7070        0.6710  0.1525\n",
      "     33        0.5707       0.7060        0.6581  0.1630\n",
      "     34        0.5685       0.7070        0.6605  0.1680\n",
      "     35        0.5672       0.7140        0.6575  0.1619\n",
      "     36        \u001b[36m0.5645\u001b[0m       0.7180        0.6642  0.1584\n",
      "     37        \u001b[36m0.5643\u001b[0m       \u001b[32m0.7210\u001b[0m        0.6657  0.1628\n",
      "     38        \u001b[36m0.5630\u001b[0m       0.7210        0.6628  0.1571\n",
      "     39        0.5640       0.7190        0.6586  0.1524\n",
      "     40        \u001b[36m0.5621\u001b[0m       0.7190        0.6693  0.1489\n",
      "     41        0.5626       \u001b[32m0.7240\u001b[0m        0.6604  0.1583\n",
      "     42        \u001b[36m0.5583\u001b[0m       0.7200        0.6668  0.1654\n",
      "     43        \u001b[36m0.5577\u001b[0m       0.7130        0.6701  0.1566\n",
      "     44        0.5598       0.7110        0.6761  0.1573\n",
      "     45        0.5584       0.7230        0.6743  0.1638\n",
      "     46        0.5591       0.7160        0.6665  0.1529\n",
      "     47        0.5579       0.7140        0.6722  0.1585\n",
      "     48        \u001b[36m0.5573\u001b[0m       0.7160        0.6552  0.1651\n",
      "     49        \u001b[36m0.5533\u001b[0m       0.7160        0.6772  0.1663\n",
      "     50        0.5551       0.7120        0.6735  0.1585\n",
      "     51        \u001b[36m0.5498\u001b[0m       0.7210        0.6671  0.1587\n",
      "     52        0.5506       0.7180        0.6860  0.1656\n",
      "     53        \u001b[36m0.5496\u001b[0m       0.7140        0.6762  0.1582\n",
      "     54        \u001b[36m0.5480\u001b[0m       0.7150        0.6662  0.1656\n",
      "     55        0.5481       0.7140        0.6797  0.1659\n",
      "     56        0.5481       0.7200        0.6809  0.1614\n",
      "     57        \u001b[36m0.5475\u001b[0m       0.7100        0.6890  0.1654\n",
      "     58        \u001b[36m0.5439\u001b[0m       0.7210        0.6818  0.1531\n",
      "     59        \u001b[36m0.5410\u001b[0m       0.7110        0.6829  0.1632\n",
      "     60        0.5446       0.7050        0.7029  0.1551\n",
      "     61        0.5420       0.7170        0.6837  0.1644\n",
      "     62        \u001b[36m0.5400\u001b[0m       0.7150        0.6767  0.1669\n",
      "     63        0.5422       0.7240        0.6761  0.1437\n",
      "     64        0.5419       0.7180        0.6874  0.1478\n",
      "     65        \u001b[36m0.5391\u001b[0m       0.7180        0.6892  0.1479\n",
      "     66        \u001b[36m0.5383\u001b[0m       0.7220        0.6824  0.1551\n",
      "     67        \u001b[36m0.5355\u001b[0m       0.7190        0.6822  0.1529\n",
      "     68        \u001b[36m0.5327\u001b[0m       0.7150        0.6989  0.1504\n",
      "     69        0.5371       0.7110        0.6894  0.1503\n",
      "     70        0.5341       0.7070        0.7005  0.1529\n",
      "     71        0.5339       0.7030        0.6959  0.1513\n",
      "     72        \u001b[36m0.5319\u001b[0m       0.7040        0.7021  0.1553\n",
      "     73        0.5363       0.7170        0.7107  0.1518\n",
      "     74        0.5321       0.7030        0.7085  0.1519\n",
      "     75        \u001b[36m0.5309\u001b[0m       0.7060        0.7030  0.1502\n",
      "     76        \u001b[36m0.5295\u001b[0m       0.7010        0.7198  0.1522\n",
      "     77        \u001b[36m0.5287\u001b[0m       0.7070        0.7163  0.1502\n",
      "     78        \u001b[36m0.5255\u001b[0m       0.6970        0.7358  0.1505\n",
      "     79        0.5286       0.6930        0.7345  0.1602\n",
      "     80        \u001b[36m0.5240\u001b[0m       0.6880        0.7358  0.1534\n",
      "     81        0.5275       0.7090        0.7282  0.1525\n",
      "     82        0.5253       0.6980        0.7262  0.1501\n",
      "     83        0.5250       0.7090        0.7387  0.1523\n",
      "     84        0.5265       0.7020        0.7400  0.1497\n",
      "     85        \u001b[36m0.5205\u001b[0m       0.7000        0.7349  0.1552\n",
      "     86        0.5224       0.7010        0.7386  0.1553\n",
      "     87        0.5211       0.7010        0.7384  0.1495\n",
      "     88        \u001b[36m0.5158\u001b[0m       0.6920        0.7548  0.1481\n",
      "     89        0.5202       0.6940        0.7565  0.1610\n",
      "     90        0.5168       0.6950        0.7501  0.1737\n",
      "     91        0.5185       0.6960        0.7616  0.1578\n",
      "     92        0.5205       0.6840        0.7972  0.1654\n",
      "     93        0.5189       0.6940        0.7651  0.1612\n",
      "     94        0.5213       0.6900        0.7700  0.1627\n",
      "     95        0.5227       0.6950        0.7614  0.1521\n",
      "     96        0.5313       0.6810        0.7730  0.1627\n",
      "     97        0.5400       0.6920        0.7469  0.1571\n",
      "     98        0.5234       0.6810        0.7801  0.1545\n",
      "     99        0.5265       0.6750        0.7835  0.1602\n",
      "    100        0.5224       0.7060        0.7615  0.1580\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7590\u001b[0m       \u001b[32m0.6910\u001b[0m        \u001b[35m0.7078\u001b[0m  0.1567\n",
      "      2        \u001b[36m0.6662\u001b[0m       \u001b[32m0.7280\u001b[0m        \u001b[35m0.6563\u001b[0m  0.1390\n",
      "      3        \u001b[36m0.6352\u001b[0m       \u001b[32m0.7400\u001b[0m        \u001b[35m0.6398\u001b[0m  0.1376\n",
      "      4        \u001b[36m0.6279\u001b[0m       \u001b[32m0.7420\u001b[0m        \u001b[35m0.6259\u001b[0m  0.1448\n",
      "      5        \u001b[36m0.6206\u001b[0m       \u001b[32m0.7520\u001b[0m        \u001b[35m0.6112\u001b[0m  0.1426\n",
      "      6        \u001b[36m0.6135\u001b[0m       0.7470        0.6189  0.1424\n",
      "      7        \u001b[36m0.6103\u001b[0m       0.7510        \u001b[35m0.6094\u001b[0m  0.1488\n",
      "      8        \u001b[36m0.6073\u001b[0m       0.7470        0.6134  0.1475\n",
      "      9        \u001b[36m0.6056\u001b[0m       0.7510        0.6137  0.1417\n",
      "     10        \u001b[36m0.6009\u001b[0m       \u001b[32m0.7540\u001b[0m        0.6160  0.1461\n",
      "     11        0.6044       0.7510        0.6187  0.1489\n",
      "     12        \u001b[36m0.5982\u001b[0m       0.7540        0.6175  0.1469\n",
      "     13        0.5985       \u001b[32m0.7580\u001b[0m        0.6157  0.1464\n",
      "     14        \u001b[36m0.5958\u001b[0m       0.7480        0.6183  0.1379\n",
      "     15        \u001b[36m0.5953\u001b[0m       0.7520        0.6123  0.1481\n",
      "     16        \u001b[36m0.5935\u001b[0m       \u001b[32m0.7640\u001b[0m        \u001b[35m0.5998\u001b[0m  0.1472\n",
      "     17        \u001b[36m0.5873\u001b[0m       0.7640        0.6116  0.1462\n",
      "     18        0.5876       0.7630        \u001b[35m0.5978\u001b[0m  0.1467\n",
      "     19        \u001b[36m0.5831\u001b[0m       \u001b[32m0.7690\u001b[0m        0.5993  0.1444\n",
      "     20        \u001b[36m0.5821\u001b[0m       0.7660        0.5985  0.1483\n",
      "     21        \u001b[36m0.5790\u001b[0m       \u001b[32m0.7710\u001b[0m        0.6015  0.1443\n",
      "     22        \u001b[36m0.5785\u001b[0m       \u001b[32m0.7750\u001b[0m        \u001b[35m0.5881\u001b[0m  0.1472\n",
      "     23        \u001b[36m0.5763\u001b[0m       0.7600        0.6052  0.1462\n",
      "     24        \u001b[36m0.5737\u001b[0m       0.7590        0.6081  0.1487\n",
      "     25        \u001b[36m0.5701\u001b[0m       0.7560        0.6042  0.1510\n",
      "     26        0.5733       0.7430        0.6257  0.1487\n",
      "     27        0.5769       0.7480        0.6295  0.1461\n",
      "     28        0.5726       0.7470        0.6354  0.1516\n",
      "     29        \u001b[36m0.5676\u001b[0m       0.7540        0.6380  0.1656\n",
      "     30        \u001b[36m0.5604\u001b[0m       0.7380        0.6468  0.1545\n",
      "     31        0.5636       0.7400        0.6386  0.1767\n",
      "     32        \u001b[36m0.5550\u001b[0m       0.7490        0.6386  0.1560\n",
      "     33        0.5591       0.7580        0.6314  0.1416\n",
      "     34        \u001b[36m0.5524\u001b[0m       0.7580        0.6408  0.1607\n",
      "     35        \u001b[36m0.5512\u001b[0m       0.7520        0.6419  0.1619\n",
      "     36        \u001b[36m0.5496\u001b[0m       0.7370        0.6813  0.1618\n",
      "     37        0.5506       0.7390        0.6499  0.1538\n",
      "     38        0.5526       0.7390        0.6582  0.1594\n",
      "     39        0.5589       0.7370        0.6462  0.1475\n",
      "     40        0.5563       0.7490        0.6261  0.1579\n",
      "     41        0.5499       0.7530        0.6332  0.1615\n",
      "     42        \u001b[36m0.5485\u001b[0m       0.7370        0.6536  0.1620\n",
      "     43        \u001b[36m0.5463\u001b[0m       0.7450        0.6491  0.1583\n",
      "     44        \u001b[36m0.5442\u001b[0m       0.7470        0.6363  0.1582\n",
      "     45        \u001b[36m0.5409\u001b[0m       0.7530        0.6342  0.1610\n",
      "     46        \u001b[36m0.5389\u001b[0m       0.7460        0.6524  0.1482\n",
      "     47        \u001b[36m0.5388\u001b[0m       0.7370        0.6561  0.1513\n",
      "     48        \u001b[36m0.5318\u001b[0m       0.7580        0.6369  0.1693\n",
      "     49        \u001b[36m0.5286\u001b[0m       0.7440        0.6675  0.1586\n",
      "     50        0.5304       0.7550        0.6681  0.1734\n",
      "     51        0.5304       0.7490        0.6710  0.1746\n",
      "     52        \u001b[36m0.5268\u001b[0m       0.7480        0.6622  0.1512\n",
      "     53        \u001b[36m0.5251\u001b[0m       0.7440        0.6659  0.1509\n",
      "     54        \u001b[36m0.5153\u001b[0m       0.7550        0.6706  0.1479\n",
      "     55        \u001b[36m0.5142\u001b[0m       0.7510        0.6756  0.1501\n",
      "     56        0.5212       0.7310        0.6828  0.1481\n",
      "     57        0.5265       0.7520        0.6665  0.1401\n",
      "     58        \u001b[36m0.5134\u001b[0m       0.7560        0.6658  0.1462\n",
      "     59        \u001b[36m0.5094\u001b[0m       0.7480        0.6602  0.1492\n",
      "     60        \u001b[36m0.5025\u001b[0m       0.7400        0.6874  0.1495\n",
      "     61        0.5065       0.7400        0.6830  0.1375\n",
      "     62        0.5121       0.7370        0.6907  0.1486\n",
      "     63        \u001b[36m0.4925\u001b[0m       0.7360        0.7112  0.1448\n",
      "     64        0.4994       0.7090        0.7653  0.1500\n",
      "     65        0.5002       0.7250        0.7366  0.1457\n",
      "     66        0.4989       0.7300        0.6972  0.1489\n",
      "     67        0.4955       0.7150        0.7347  0.1538\n",
      "     68        0.5019       0.7200        0.7342  0.1468\n",
      "     69        0.4980       0.7300        0.7309  0.1595\n",
      "     70        \u001b[36m0.4910\u001b[0m       0.7310        0.7463  0.1404\n",
      "     71        0.4915       0.7190        0.7341  0.1451\n",
      "     72        \u001b[36m0.4898\u001b[0m       0.7280        0.7270  0.1480\n",
      "     73        0.4905       0.7350        0.7062  0.1483\n",
      "     74        0.4916       0.7160        0.7210  0.1491\n",
      "     75        0.4921       0.7330        0.7046  0.1478\n",
      "     76        \u001b[36m0.4895\u001b[0m       0.7160        0.7445  0.1524\n",
      "     77        0.4955       0.7190        0.7353  0.1523\n",
      "     78        0.4980       0.7300        0.7310  0.1504\n",
      "     79        \u001b[36m0.4862\u001b[0m       0.7290        0.7085  0.1371\n",
      "     80        0.4922       0.7300        0.7047  0.1554\n",
      "     81        0.4873       0.7260        0.7155  0.1451\n",
      "     82        0.4889       0.7290        0.7211  0.1438\n",
      "     83        \u001b[36m0.4844\u001b[0m       0.7320        0.7158  0.1599\n",
      "     84        0.4904       0.7320        0.7139  0.1404\n",
      "     85        0.4890       0.7360        0.6891  0.1490\n",
      "     86        \u001b[36m0.4837\u001b[0m       0.7350        0.7081  0.1455\n",
      "     87        \u001b[36m0.4824\u001b[0m       0.7350        0.7062  0.1500\n",
      "     88        0.4890       0.7360        0.7025  0.1497\n",
      "     89        0.4941       0.7340        0.7041  0.1498\n",
      "     90        0.4859       0.7360        0.6893  0.1588\n",
      "     91        0.4856       0.7330        0.7136  0.1586\n",
      "     92        0.4847       0.7210        0.7241  0.1482\n",
      "     93        0.4920       0.7330        0.7152  0.1452\n",
      "     94        0.4908       0.7500        0.7253  0.1428\n",
      "     95        0.4909       0.7340        0.7337  0.1488\n",
      "     96        0.4827       0.7350        0.7426  0.1472\n",
      "     97        \u001b[36m0.4803\u001b[0m       0.7410        0.7333  0.1500\n",
      "     98        0.4827       0.7270        0.7593  0.1568\n",
      "     99        \u001b[36m0.4772\u001b[0m       0.7410        0.7368  0.1469\n",
      "    100        \u001b[36m0.4759\u001b[0m       0.7350        0.7318  0.1489\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8267\u001b[0m       \u001b[32m0.7070\u001b[0m        \u001b[35m0.6947\u001b[0m  0.1230\n",
      "      2        \u001b[36m0.6801\u001b[0m       \u001b[32m0.7080\u001b[0m        \u001b[35m0.6531\u001b[0m  0.1256\n",
      "      3        \u001b[36m0.6489\u001b[0m       \u001b[32m0.7180\u001b[0m        \u001b[35m0.6422\u001b[0m  0.1287\n",
      "      4        \u001b[36m0.6352\u001b[0m       \u001b[32m0.7260\u001b[0m        \u001b[35m0.6398\u001b[0m  0.1295\n",
      "      5        \u001b[36m0.6252\u001b[0m       0.7250        \u001b[35m0.6369\u001b[0m  0.1273\n",
      "      6        \u001b[36m0.6188\u001b[0m       0.7170        \u001b[35m0.6361\u001b[0m  0.1242\n",
      "      7        \u001b[36m0.6147\u001b[0m       \u001b[32m0.7270\u001b[0m        0.6386  0.1232\n",
      "      8        \u001b[36m0.6083\u001b[0m       0.7250        0.6395  0.1242\n",
      "      9        \u001b[36m0.6048\u001b[0m       \u001b[32m0.7290\u001b[0m        0.6423  0.1305\n",
      "     10        \u001b[36m0.6026\u001b[0m       \u001b[32m0.7310\u001b[0m        0.6424  0.1283\n",
      "     11        \u001b[36m0.5975\u001b[0m       0.7280        0.6450  0.1209\n",
      "     12        \u001b[36m0.5956\u001b[0m       \u001b[32m0.7370\u001b[0m        0.6492  0.1227\n",
      "     13        \u001b[36m0.5937\u001b[0m       0.7290        0.6414  0.1261\n",
      "     14        \u001b[36m0.5921\u001b[0m       0.7300        0.6463  0.1232\n",
      "     15        \u001b[36m0.5918\u001b[0m       0.7350        0.6479  0.1252\n",
      "     16        \u001b[36m0.5856\u001b[0m       0.7360        0.6474  0.1247\n",
      "     17        \u001b[36m0.5832\u001b[0m       0.7330        0.6497  0.1272\n",
      "     18        \u001b[36m0.5798\u001b[0m       0.7190        0.6495  0.1235\n",
      "     19        \u001b[36m0.5773\u001b[0m       \u001b[32m0.7380\u001b[0m        0.6563  0.1243\n",
      "     20        \u001b[36m0.5759\u001b[0m       0.7310        0.6592  0.1206\n",
      "     21        \u001b[36m0.5750\u001b[0m       0.7340        0.6638  0.1176\n",
      "     22        \u001b[36m0.5742\u001b[0m       0.7280        0.6617  0.1232\n",
      "     23        \u001b[36m0.5719\u001b[0m       0.7250        0.6740  0.1217\n",
      "     24        \u001b[36m0.5693\u001b[0m       0.7240        0.6654  0.1256\n",
      "     25        \u001b[36m0.5661\u001b[0m       0.7190        0.6632  0.1272\n",
      "     26        \u001b[36m0.5655\u001b[0m       0.7080        0.6846  0.1257\n",
      "     27        \u001b[36m0.5652\u001b[0m       0.7280        0.6750  0.1270\n",
      "     28        \u001b[36m0.5593\u001b[0m       0.7160        0.6786  0.1234\n",
      "     29        0.5602       0.7170        0.6672  0.1272\n",
      "     30        0.5628       0.7090        0.6815  0.1281\n",
      "     31        \u001b[36m0.5553\u001b[0m       0.7220        0.6686  0.1337\n",
      "     32        \u001b[36m0.5520\u001b[0m       0.7110        0.6790  0.1329\n",
      "     33        \u001b[36m0.5515\u001b[0m       0.7140        0.6778  0.1252\n",
      "     34        \u001b[36m0.5508\u001b[0m       0.7080        0.6892  0.1207\n",
      "     35        0.5520       0.7020        0.6885  0.1267\n",
      "     36        \u001b[36m0.5492\u001b[0m       0.7230        0.6842  0.1369\n",
      "     37        0.5495       0.7120        0.6835  0.1282\n",
      "     38        0.5496       0.7220        0.6948  0.1244\n",
      "     39        \u001b[36m0.5485\u001b[0m       0.7060        0.6805  0.1257\n",
      "     40        \u001b[36m0.5413\u001b[0m       0.7230        0.6766  0.1283\n",
      "     41        \u001b[36m0.5413\u001b[0m       0.7120        0.6861  0.1287\n",
      "     42        0.5429       0.7140        0.6883  0.1260\n",
      "     43        0.5428       0.7060        0.6898  0.1362\n",
      "     44        \u001b[36m0.5388\u001b[0m       0.7210        0.6865  0.1258\n",
      "     45        \u001b[36m0.5341\u001b[0m       0.7140        0.7052  0.1258\n",
      "     46        0.5350       0.7140        0.6790  0.1214\n",
      "     47        \u001b[36m0.5323\u001b[0m       0.7120        0.7011  0.1316\n",
      "     48        \u001b[36m0.5309\u001b[0m       0.7170        0.6932  0.1296\n",
      "     49        0.5311       0.6990        0.7031  0.1284\n",
      "     50        0.5336       0.7180        0.7043  0.1301\n",
      "     51        \u001b[36m0.5276\u001b[0m       0.7050        0.7018  0.1308\n",
      "     52        0.5299       0.7010        0.7035  0.1321\n",
      "     53        0.5306       0.7020        0.7104  0.1316\n",
      "     54        0.5297       0.7130        0.7104  0.1254\n",
      "     55        0.5276       0.7060        0.7158  0.1319\n",
      "     56        0.5304       0.7070        0.7151  0.1311\n",
      "     57        \u001b[36m0.5238\u001b[0m       0.7030        0.7136  0.1355\n",
      "     58        0.5241       0.6920        0.7394  0.1415\n",
      "     59        0.5246       0.6970        0.7216  0.1504\n",
      "     60        0.5250       0.6910        0.7254  0.1487\n",
      "     61        0.5245       0.7020        0.7485  0.1441\n",
      "     62        \u001b[36m0.5218\u001b[0m       0.6970        0.7366  0.1496\n",
      "     63        \u001b[36m0.5176\u001b[0m       0.7030        0.7250  0.1514\n",
      "     64        0.5240       0.7000        0.7490  0.1434\n",
      "     65        0.5182       0.6960        0.7412  0.1489\n",
      "     66        0.5205       0.6940        0.7278  0.1463\n",
      "     67        \u001b[36m0.5165\u001b[0m       0.6980        0.7604  0.1395\n",
      "     68        \u001b[36m0.5152\u001b[0m       0.7000        0.7602  0.1528\n",
      "     69        0.5178       0.7030        0.7594  0.1514\n",
      "     70        0.5182       0.6820        0.7512  0.1348\n",
      "     71        0.5161       0.7160        0.8357  0.1520\n",
      "     72        \u001b[36m0.5137\u001b[0m       0.6970        0.7582  0.1506\n",
      "     73        0.5174       0.7010        0.7564  0.1495\n",
      "     74        0.5165       0.7080        0.7385  0.1464\n",
      "     75        0.5241       0.6960        0.7248  0.1623\n",
      "     76        \u001b[36m0.5124\u001b[0m       0.7120        0.7439  0.1401\n",
      "     77        0.5173       0.7040        0.7571  0.1374\n",
      "     78        0.5167       0.7050        0.7449  0.1304\n",
      "     79        0.5145       0.7030        0.7550  0.1326\n",
      "     80        0.5130       0.7000        0.7710  0.1343\n",
      "     81        0.5143       0.7130        0.7751  0.1336\n",
      "     82        \u001b[36m0.5114\u001b[0m       0.6990        0.7777  0.1327\n",
      "     83        \u001b[36m0.5068\u001b[0m       0.7140        0.7755  0.1387\n",
      "     84        0.5095       0.7120        0.7506  0.1420\n",
      "     85        \u001b[36m0.5061\u001b[0m       0.7140        0.7845  0.1705\n",
      "     86        0.5075       0.7080        0.7544  0.1354\n",
      "     87        0.5136       0.7180        0.7975  0.1303\n",
      "     88        0.5107       0.7160        0.7668  0.1462\n",
      "     89        0.5116       0.7160        0.7798  0.1407\n",
      "     90        0.5127       0.7040        0.7263  0.1343\n",
      "     91        0.5062       0.7000        0.7926  0.1347\n",
      "     92        \u001b[36m0.5060\u001b[0m       0.6960        0.7595  0.1402\n",
      "     93        \u001b[36m0.5022\u001b[0m       0.7150        0.7875  0.1471\n",
      "     94        0.5078       0.7110        0.7593  0.1435\n",
      "     95        0.5085       0.7140        0.7795  0.1419\n",
      "     96        0.5062       0.6960        0.7914  0.1327\n",
      "     97        \u001b[36m0.5001\u001b[0m       0.7110        0.7750  0.1397\n",
      "     98        0.5047       0.7120        0.7463  0.1367\n",
      "     99        0.5101       0.7120        0.8003  0.1352\n",
      "    100        0.5026       0.7040        0.7838  0.1378\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7993\u001b[0m       \u001b[32m0.5020\u001b[0m        \u001b[35m1.2439\u001b[0m  0.1241\n",
      "      2        \u001b[36m0.6727\u001b[0m       \u001b[32m0.5310\u001b[0m        \u001b[35m0.9865\u001b[0m  0.1249\n",
      "      3        \u001b[36m0.6452\u001b[0m       \u001b[32m0.5680\u001b[0m        \u001b[35m0.9102\u001b[0m  0.1267\n",
      "      4        \u001b[36m0.6339\u001b[0m       \u001b[32m0.6110\u001b[0m        \u001b[35m0.8527\u001b[0m  0.1246\n",
      "      5        \u001b[36m0.6271\u001b[0m       \u001b[32m0.6320\u001b[0m        \u001b[35m0.8219\u001b[0m  0.1253\n",
      "      6        \u001b[36m0.6232\u001b[0m       \u001b[32m0.6400\u001b[0m        \u001b[35m0.7981\u001b[0m  0.1197\n",
      "      7        \u001b[36m0.6177\u001b[0m       \u001b[32m0.6490\u001b[0m        \u001b[35m0.7911\u001b[0m  0.1252\n",
      "      8        \u001b[36m0.6150\u001b[0m       \u001b[32m0.6800\u001b[0m        \u001b[35m0.7655\u001b[0m  0.1237\n",
      "      9        \u001b[36m0.6133\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.7455\u001b[0m  0.1321\n",
      "     10        \u001b[36m0.6087\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.7370\u001b[0m  0.1276\n",
      "     11        \u001b[36m0.6055\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.7273\u001b[0m  0.1262\n",
      "     12        \u001b[36m0.6024\u001b[0m       \u001b[32m0.7200\u001b[0m        \u001b[35m0.7245\u001b[0m  0.1240\n",
      "     13        \u001b[36m0.6023\u001b[0m       \u001b[32m0.7210\u001b[0m        \u001b[35m0.7145\u001b[0m  0.1246\n",
      "     14        \u001b[36m0.6002\u001b[0m       \u001b[32m0.7270\u001b[0m        \u001b[35m0.7125\u001b[0m  0.1251\n",
      "     15        \u001b[36m0.5989\u001b[0m       0.7220        0.7156  0.1328\n",
      "     16        \u001b[36m0.5966\u001b[0m       0.7210        \u001b[35m0.7124\u001b[0m  0.1238\n",
      "     17        0.5967       0.7160        \u001b[35m0.7073\u001b[0m  0.1298\n",
      "     18        \u001b[36m0.5960\u001b[0m       \u001b[32m0.7410\u001b[0m        \u001b[35m0.6849\u001b[0m  0.1316\n",
      "     19        \u001b[36m0.5945\u001b[0m       0.7330        0.6883  0.1280\n",
      "     20        \u001b[36m0.5932\u001b[0m       0.7390        0.6874  0.1252\n",
      "     21        0.5942       0.7410        \u001b[35m0.6761\u001b[0m  0.1247\n",
      "     22        \u001b[36m0.5905\u001b[0m       \u001b[32m0.7420\u001b[0m        \u001b[35m0.6749\u001b[0m  0.1272\n",
      "     23        0.5921       0.7280        0.6870  0.1271\n",
      "     24        \u001b[36m0.5881\u001b[0m       0.7360        0.6790  0.1220\n",
      "     25        \u001b[36m0.5854\u001b[0m       0.7310        0.6851  0.1252\n",
      "     26        0.5860       0.7300        0.6894  0.1272\n",
      "     27        \u001b[36m0.5825\u001b[0m       0.7280        0.6888  0.1342\n",
      "     28        \u001b[36m0.5809\u001b[0m       0.7250        0.6868  0.1335\n",
      "     29        \u001b[36m0.5801\u001b[0m       0.7240        0.6866  0.1359\n",
      "     30        \u001b[36m0.5767\u001b[0m       0.7260        0.7134  0.1322\n",
      "     31        0.5795       0.7260        0.7042  0.1360\n",
      "     32        0.5783       0.7300        0.6891  0.1338\n",
      "     33        \u001b[36m0.5766\u001b[0m       0.7140        0.6985  0.1447\n",
      "     34        \u001b[36m0.5727\u001b[0m       0.7200        0.7018  0.1533\n",
      "     35        0.5753       0.7230        0.7042  0.1341\n",
      "     36        \u001b[36m0.5712\u001b[0m       0.7160        0.6989  0.1362\n",
      "     37        0.5718       0.7180        0.7307  0.1408\n",
      "     38        \u001b[36m0.5696\u001b[0m       0.7190        0.7000  0.1294\n",
      "     39        \u001b[36m0.5643\u001b[0m       0.7080        0.7293  0.1353\n",
      "     40        0.5665       0.7150        0.7244  0.1373\n",
      "     41        \u001b[36m0.5618\u001b[0m       0.7110        0.7700  0.1283\n",
      "     42        0.5618       0.7150        0.7258  0.1307\n",
      "     43        0.5632       0.7250        0.6837  0.1370\n",
      "     44        0.5638       0.7140        0.6980  0.1389\n",
      "     45        \u001b[36m0.5607\u001b[0m       0.7270        0.6817  0.1386\n",
      "     46        \u001b[36m0.5593\u001b[0m       0.7190        0.6922  0.1331\n",
      "     47        \u001b[36m0.5587\u001b[0m       0.7250        0.6816  0.1359\n",
      "     48        \u001b[36m0.5559\u001b[0m       0.7260        \u001b[35m0.6688\u001b[0m  0.1450\n",
      "     49        \u001b[36m0.5551\u001b[0m       0.7220        0.6770  0.1387\n",
      "     50        0.5561       0.7180        0.6847  0.1284\n",
      "     51        \u001b[36m0.5537\u001b[0m       0.7230        0.6929  0.1420\n",
      "     52        \u001b[36m0.5537\u001b[0m       0.7160        0.6839  0.1353\n",
      "     53        0.5540       0.7200        0.6910  0.1435\n",
      "     54        \u001b[36m0.5535\u001b[0m       0.7260        0.6883  0.1461\n",
      "     55        0.5557       0.7330        \u001b[35m0.6656\u001b[0m  0.1545\n",
      "     56        \u001b[36m0.5527\u001b[0m       0.7230        0.6830  0.1472\n",
      "     57        \u001b[36m0.5489\u001b[0m       0.7120        0.6909  0.1457\n",
      "     58        0.5520       0.7120        0.6887  0.1480\n",
      "     59        0.5493       0.7140        0.6979  0.1468\n",
      "     60        0.5531       0.6990        0.7135  0.1353\n",
      "     61        0.5508       0.7220        0.6827  0.1478\n",
      "     62        \u001b[36m0.5478\u001b[0m       0.7210        0.6823  0.1447\n",
      "     63        \u001b[36m0.5448\u001b[0m       0.7040        0.6967  0.1521\n",
      "     64        0.5472       0.7140        0.6890  0.1509\n",
      "     65        0.5468       0.7120        0.7027  0.1488\n",
      "     66        0.5457       0.7170        0.6846  0.1525\n",
      "     67        \u001b[36m0.5412\u001b[0m       0.7250        0.6849  0.1455\n",
      "     68        \u001b[36m0.5390\u001b[0m       0.7110        0.7059  0.1520\n",
      "     69        \u001b[36m0.5386\u001b[0m       0.7020        0.7031  0.1498\n",
      "     70        0.5457       0.7180        0.6913  0.1392\n",
      "     71        0.5430       0.6930        0.7070  0.1547\n",
      "     72        0.5396       0.7060        0.7065  0.1396\n",
      "     73        0.5389       0.6930        0.7179  0.1479\n",
      "     74        0.5409       0.7090        0.7074  0.1396\n",
      "     75        0.5423       0.7160        0.7103  0.1450\n",
      "     76        0.5406       0.7100        0.7020  0.1461\n",
      "     77        \u001b[36m0.5375\u001b[0m       0.7080        0.7066  0.1458\n",
      "     78        0.5399       0.7060        0.7213  0.1426\n",
      "     79        0.5432       0.7220        0.6875  0.1413\n",
      "     80        0.5378       0.7050        0.7160  0.1364\n",
      "     81        \u001b[36m0.5375\u001b[0m       0.7100        0.6958  0.1612\n",
      "     82        \u001b[36m0.5363\u001b[0m       0.7120        0.7198  0.1372\n",
      "     83        \u001b[36m0.5343\u001b[0m       0.7130        0.7020  0.1525\n",
      "     84        0.5374       0.7250        0.6908  0.1473\n",
      "     85        \u001b[36m0.5329\u001b[0m       0.7160        0.6914  0.1485\n",
      "     86        \u001b[36m0.5306\u001b[0m       0.7130        0.6946  0.1472\n",
      "     87        0.5307       0.7210        0.6799  0.1538\n",
      "     88        0.5347       0.7250        0.6986  0.1512\n",
      "     89        \u001b[36m0.5301\u001b[0m       0.7140        0.7066  0.1525\n",
      "     90        \u001b[36m0.5278\u001b[0m       0.7160        0.7123  0.1425\n",
      "     91        0.5322       0.7210        0.6977  0.1494\n",
      "     92        \u001b[36m0.5262\u001b[0m       0.7290        0.7017  0.1520\n",
      "     93        0.5277       0.7140        0.7029  0.1359\n",
      "     94        \u001b[36m0.5244\u001b[0m       0.7150        0.7054  0.1453\n",
      "     95        0.5272       0.7220        0.7028  0.1390\n",
      "     96        0.5263       0.7160        0.7081  0.1525\n",
      "     97        0.5247       0.7080        0.7055  0.1472\n",
      "     98        0.5262       0.7100        0.7043  0.1496\n",
      "     99        \u001b[36m0.5217\u001b[0m       0.7130        0.7070  0.1455\n",
      "    100        0.5228       0.7200        0.7120  0.1414\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0450\u001b[0m       \u001b[32m0.4890\u001b[0m        \u001b[35m1.0356\u001b[0m  0.1475\n",
      "      2        \u001b[36m1.0347\u001b[0m       0.4890        1.0360  0.1453\n",
      "      3        1.0348       0.4890        1.0361  0.1421\n",
      "      4        1.0348       0.4890        1.0361  0.1429\n",
      "      5        1.0348       0.4890        1.0361  0.1428\n",
      "      6        1.0348       0.4890        1.0361  0.1565\n",
      "      7        1.0348       0.4890        1.0361  0.1737\n",
      "      8        1.0348       0.4890        1.0361  0.1667\n",
      "      9        1.0348       0.4890        1.0361  0.1551\n",
      "     10        1.0348       0.4890        1.0361  0.1571\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8280\u001b[0m       \u001b[32m0.5610\u001b[0m        \u001b[35m0.8749\u001b[0m  0.1500\n",
      "      2        \u001b[36m0.7286\u001b[0m       \u001b[32m0.5700\u001b[0m        \u001b[35m0.7625\u001b[0m  0.1587\n",
      "      3        \u001b[36m0.7128\u001b[0m       \u001b[32m0.6230\u001b[0m        \u001b[35m0.7376\u001b[0m  0.1470\n",
      "      4        \u001b[36m0.7023\u001b[0m       \u001b[32m0.6800\u001b[0m        \u001b[35m0.7281\u001b[0m  0.1505\n",
      "      5        \u001b[36m0.6715\u001b[0m       0.6190        0.8210  0.1467\n",
      "      6        0.6773       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6815\u001b[0m  0.1583\n",
      "      7        \u001b[36m0.6569\u001b[0m       0.6550        0.7496  0.1639\n",
      "      8        \u001b[36m0.6559\u001b[0m       0.6890        0.7353  0.1675\n",
      "      9        0.6567       0.6470        0.7528  0.1670\n",
      "     10        0.6795       0.6530        0.7482  0.1613\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.6194\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1321\n",
      "      2       \u001b[36m10.6176\u001b[0m       0.3340       10.6176  0.1285\n",
      "      3       10.6176       0.3340       10.6176  0.1371\n",
      "      4       10.6176       0.3340       10.6176  0.1389\n",
      "      5       10.6176       0.3340       10.6176  0.1271\n",
      "      6       10.6176       0.3340       10.6176  0.1517\n",
      "      7       10.6176       0.3340       10.6176  0.1351\n",
      "      8       10.6176       0.3340       10.6176  0.1343\n",
      "      9       10.6176       0.3340       10.6176  0.1278\n",
      "     10       10.6176       0.3340       10.6176  0.1304\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5673\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1350\n",
      "      2       10.6176       0.3340       10.6176  0.1331\n",
      "      3       10.6176       0.3340       10.6176  0.1361\n",
      "      4       10.6176       0.3340       10.6176  0.1392\n",
      "      5       10.6176       0.3340       10.6176  0.1391\n",
      "      6       10.6176       0.3340       10.6176  0.1412\n",
      "      7       10.6176       0.3340       10.6176  0.1335\n",
      "      8       10.6176       0.3340       10.6176  0.1345\n",
      "      9       10.6176       0.3340       10.6176  0.1331\n",
      "     10       10.6176       0.3340       10.6176  0.1329\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9162\u001b[0m       \u001b[32m0.5910\u001b[0m        \u001b[35m0.8332\u001b[0m  0.1414\n",
      "      2        \u001b[36m0.8219\u001b[0m       \u001b[32m0.5940\u001b[0m        \u001b[35m0.8280\u001b[0m  0.1438\n",
      "      3        \u001b[36m0.8041\u001b[0m       \u001b[32m0.6050\u001b[0m        \u001b[35m0.8157\u001b[0m  0.1461\n",
      "      4        \u001b[36m0.7993\u001b[0m       \u001b[32m0.6330\u001b[0m        \u001b[35m0.7778\u001b[0m  0.1434\n",
      "      5        \u001b[36m0.7874\u001b[0m       \u001b[32m0.6440\u001b[0m        \u001b[35m0.7735\u001b[0m  0.1442\n",
      "      6        \u001b[36m0.7725\u001b[0m       0.6440        \u001b[35m0.7621\u001b[0m  0.1519\n",
      "      7        0.7770       \u001b[32m0.6450\u001b[0m        0.7703  0.1778\n",
      "      8        \u001b[36m0.7708\u001b[0m       \u001b[32m0.6490\u001b[0m        \u001b[35m0.7618\u001b[0m  0.1693\n",
      "      9        \u001b[36m0.7684\u001b[0m       0.6470        0.7699  0.1742\n",
      "     10        0.7703       0.6470        0.7684  0.1506\n",
      "     11        0.7698       0.6470        0.7767  0.1655\n",
      "     12        0.7694       0.6490        0.7817  0.1894\n",
      "     13        \u001b[36m0.7683\u001b[0m       0.6490        0.7784  0.1646\n",
      "     14        0.7699       0.6480        0.7918  0.1699\n",
      "     15        0.7701       \u001b[32m0.6780\u001b[0m        0.7691  0.1623\n",
      "     16        0.7705       0.6460        0.7895  0.1627\n",
      "     17        0.7689       0.6500        0.7742  0.1713\n",
      "     18        0.7769       0.6360        0.7910  0.1575\n",
      "     19        0.7695       0.6370        0.7949  0.1687\n",
      "     20        0.7713       0.6450        0.7689  0.1601\n",
      "     21        0.7739       0.6460        0.7778  0.1638\n",
      "     22        0.7688       0.6460        0.7837  0.1583\n",
      "     23        0.7696       0.6450        0.7760  0.1554\n",
      "     24        0.7748       0.6380        0.7907  0.1636\n",
      "     25        0.7698       0.6450        0.7833  0.1497\n",
      "     26        0.7774       0.6490        0.7762  0.1937\n",
      "     27        0.7723       0.6520        0.7774  0.1597\n",
      "     28        0.7775       0.6780        0.7759  0.1478\n",
      "     29        0.7705       0.6750        0.7850  0.1573\n",
      "     30        0.7766       0.6320        0.7931  0.1590\n",
      "     31        0.7691       0.6420        0.7830  0.1577\n",
      "     32        0.7714       0.6360        0.7916  0.1546\n",
      "     33        0.7721       0.6340        0.7957  0.1529\n",
      "     34        0.7711       0.6510        0.7705  0.1578\n",
      "     35        0.7748       0.6390        0.7843  0.1487\n",
      "     36        0.7758       0.6620        0.7870  0.1505\n",
      "     37        0.7735       0.6480        0.7838  0.1521\n",
      "     38        0.7783       0.6680        0.7796  0.1543\n",
      "     39        0.7700       0.6620        0.7911  0.1543\n",
      "     40        0.7728       0.6390        0.7774  0.1553\n",
      "     41        0.7711       0.6440        0.7861  0.1671\n",
      "     42        0.7773       0.6350        0.7905  0.1547\n",
      "     43        0.7707       0.6520        0.7813  0.1537\n",
      "     44        0.7848       0.6400        0.7768  0.1536\n",
      "     45        0.7691       0.6750        0.7810  0.1571\n",
      "     46        0.7774       0.6320        0.7857  0.1564\n",
      "     47        \u001b[36m0.7670\u001b[0m       0.6420        0.7897  0.1482\n",
      "     48        0.7711       0.6410        0.7850  0.1543\n",
      "     49        0.7694       0.6490        0.7773  0.1553\n",
      "     50        0.7725       0.6420        0.7817  0.1530\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8233\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m0.8896\u001b[0m  0.1385\n",
      "      2        \u001b[36m0.7462\u001b[0m       \u001b[32m0.5190\u001b[0m        \u001b[35m0.8838\u001b[0m  0.1527\n",
      "      3        \u001b[36m0.7317\u001b[0m       \u001b[32m0.6240\u001b[0m        0.9077  0.1538\n",
      "      4        \u001b[36m0.6832\u001b[0m       \u001b[32m0.6360\u001b[0m        \u001b[35m0.7834\u001b[0m  0.1538\n",
      "      5        \u001b[36m0.6737\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m0.7342\u001b[0m  0.1581\n",
      "      6        \u001b[36m0.6697\u001b[0m       0.6790        \u001b[35m0.7266\u001b[0m  0.1461\n",
      "      7        \u001b[36m0.6608\u001b[0m       \u001b[32m0.6870\u001b[0m        0.7468  0.1627\n",
      "      8        0.6819       \u001b[32m0.7190\u001b[0m        \u001b[35m0.6773\u001b[0m  0.1624\n",
      "      9        0.6623       \u001b[32m0.7290\u001b[0m        \u001b[35m0.6734\u001b[0m  0.1634\n",
      "     10        \u001b[36m0.6574\u001b[0m       0.6940        0.7119  0.1598\n",
      "     11        0.6647       0.6950        0.7184  0.1593\n",
      "     12        0.6656       0.7210        0.6935  0.1612\n",
      "     13        0.6602       0.6950        0.7429  0.1668\n",
      "     14        0.6619       0.7040        0.7146  0.1630\n",
      "     15        \u001b[36m0.6564\u001b[0m       0.7160        0.6753  0.1603\n",
      "     16        0.6608       0.7020        0.7106  0.1652\n",
      "     17        \u001b[36m0.6527\u001b[0m       0.5990        0.7924  0.1656\n",
      "     18        0.6677       0.5900        0.7679  0.1616\n",
      "     19        0.6700       0.7140        0.7002  0.1694\n",
      "     20        0.6763       0.7210        \u001b[35m0.6713\u001b[0m  0.1845\n",
      "     21        0.6558       0.7110        0.6907  0.1629\n",
      "     22        0.6532       0.7110        0.6904  0.1640\n",
      "     23        0.6533       0.7200        0.6876  0.1621\n",
      "     24        0.6554       0.7090        0.7273  0.1577\n",
      "     25        0.6593       0.6560        0.7429  0.1623\n",
      "     26        0.6583       0.7170        0.7019  0.1672\n",
      "     27        0.6571       0.7190        0.6870  0.1582\n",
      "     28        0.6571       0.6420        0.8374  0.1667\n",
      "     29        0.6751       0.7220        0.6991  0.1536\n",
      "     30        0.6711       0.6450        0.8943  0.1550\n",
      "     31        0.6758       0.6540        0.7455  0.1525\n",
      "     32        0.6635       0.7180        0.6775  0.1561\n",
      "     33        \u001b[36m0.6479\u001b[0m       0.7140        0.6953  0.1616\n",
      "     34        0.6513       0.7140        0.7168  0.1537\n",
      "     35        0.6543       0.7110        0.6929  0.1565\n",
      "     36        0.6607       0.5880        0.7551  0.1587\n",
      "     37        0.6605       0.7040        0.7217  0.1499\n",
      "     38        0.6722       0.6210        0.7544  0.1492\n",
      "     39        0.6637       0.6800        0.6959  0.1534\n",
      "     40        0.6600       0.7150        0.7043  0.1538\n",
      "     41        0.6565       0.7110        0.6997  0.1779\n",
      "     42        0.6846       0.6040        0.8556  0.1530\n",
      "     43        0.6841       0.7160        0.6746  0.1558\n",
      "     44        0.6542       0.7140        0.6956  0.1566\n",
      "     45        0.6510       0.7090        0.7078  0.1533\n",
      "     46        0.6500       0.7190        0.6898  0.1543\n",
      "     47        0.6562       0.6620        0.7040  0.1639\n",
      "     48        0.6593       0.7180        0.7007  0.1582\n",
      "     49        0.6869       0.5750        1.0049  0.1657\n",
      "     50        0.6729       0.6690        0.7720  0.1482\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.6183\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1257\n",
      "      2       \u001b[36m10.6176\u001b[0m       0.3340       10.6176  0.1255\n",
      "      3       10.6176       0.3340       10.6176  0.1241\n",
      "      4       10.6176       0.3340       10.6176  0.1303\n",
      "      5       10.6176       0.3340       10.6176  0.1261\n",
      "      6       10.6176       0.3340       10.6176  0.1319\n",
      "      7       10.6176       0.3340       10.6176  0.1318\n",
      "      8       10.6176       0.3340       10.6176  0.1256\n",
      "      9       10.6176       0.3340       10.6176  0.1251\n",
      "     10       10.6176       0.3340       10.6176  0.1288\n",
      "     11       10.6176       0.3340       10.6176  0.1459\n",
      "     12       10.6176       0.3340       10.6176  0.1262\n",
      "     13       10.6176       0.3340       10.6176  0.1301\n",
      "     14       10.6176       0.3340       10.6176  0.1242\n",
      "     15       10.6176       0.3340       10.6176  0.1251\n",
      "     16       10.6176       0.3340       10.6176  0.1270\n",
      "     17       10.6176       0.3340       10.6176  0.1283\n",
      "     18       10.6176       0.3340       10.6176  0.1262\n",
      "     19       10.6176       0.3340       10.6176  0.1315\n",
      "     20       10.6176       0.3340       10.6176  0.1252\n",
      "     21       10.6176       0.3340       10.6176  0.1287\n",
      "     22       10.6176       0.3340       10.6176  0.1237\n",
      "     23       10.6176       0.3340       10.6176  0.1256\n",
      "     24       10.6176       0.3340       10.6176  0.1257\n",
      "     25       10.6176       0.3340       10.6176  0.1222\n",
      "     26       10.6176       0.3340       10.6176  0.1323\n",
      "     27       10.6176       0.3340       10.6176  0.1398\n",
      "     28       10.6176       0.3340       10.6176  0.1385\n",
      "     29       10.6176       0.3340       10.6176  0.1348\n",
      "     30       10.6176       0.3340       10.6176  0.1360\n",
      "     31       10.6176       0.3340       10.6176  0.1303\n",
      "     32       10.6176       0.3340       10.6176  0.1387\n",
      "     33       10.6176       0.3340       10.6176  0.1384\n",
      "     34       10.6176       0.3340       10.6176  0.1314\n",
      "     35       10.6176       0.3340       10.6176  0.1300\n",
      "     36       10.6176       0.3340       10.6176  0.1384\n",
      "     37       10.6176       0.3340       10.6176  0.1303\n",
      "     38       10.6176       0.3340       10.6176  0.1333\n",
      "     39       10.6176       0.3340       10.6176  0.1367\n",
      "     40       10.6176       0.3340       10.6176  0.1350\n",
      "     41       10.6176       0.3340       10.6176  0.1365\n",
      "     42       10.6176       0.3340       10.6176  0.1385\n",
      "     43       10.6176       0.3340       10.6176  0.1550\n",
      "     44       10.6176       0.3340       10.6176  0.1383\n",
      "     45       10.6176       0.3340       10.6176  0.1456\n",
      "     46       10.6176       0.3340       10.6176  0.1360\n",
      "     47       10.6176       0.3340       10.6176  0.1417\n",
      "     48       10.6176       0.3340       10.6176  0.1350\n",
      "     49       10.6176       0.3340       10.6176  0.1340\n",
      "     50       10.6176       0.3340       10.6176  0.1404\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5672\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1303\n",
      "      2       10.6176       0.3340       10.6176  0.1256\n",
      "      3       10.6176       0.3340       10.6176  0.1488\n",
      "      4       10.6176       0.3340       10.6176  0.1302\n",
      "      5       10.6176       0.3340       10.6176  0.1271\n",
      "      6       10.6176       0.3340       10.6176  0.1322\n",
      "      7       10.6176       0.3340       10.6176  0.1347\n",
      "      8       10.6176       0.3340       10.6176  0.1204\n",
      "      9       10.6176       0.3340       10.6176  0.1312\n",
      "     10       10.6176       0.3340       10.6176  0.1284\n",
      "     11       10.6176       0.3340       10.6176  0.1302\n",
      "     12       10.6176       0.3340       10.6176  0.1302\n",
      "     13       10.6176       0.3340       10.6176  0.1218\n",
      "     14       10.6176       0.3340       10.6176  0.1220\n",
      "     15       10.6176       0.3340       10.6176  0.1240\n",
      "     16       10.6176       0.3340       10.6176  0.1181\n",
      "     17       10.6176       0.3340       10.6176  0.1283\n",
      "     18       10.6176       0.3340       10.6176  0.1337\n",
      "     19       10.6176       0.3340       10.6176  0.1237\n",
      "     20       10.6176       0.3340       10.6176  0.1246\n",
      "     21       10.6176       0.3340       10.6176  0.1238\n",
      "     22       10.6176       0.3340       10.6176  0.1210\n",
      "     23       10.6176       0.3340       10.6176  0.1298\n",
      "     24       10.6176       0.3340       10.6176  0.1292\n",
      "     25       10.6176       0.3340       10.6176  0.1360\n",
      "     26       10.6176       0.3340       10.6176  0.1621\n",
      "     27       10.6176       0.3340       10.6176  0.1270\n",
      "     28       10.6176       0.3340       10.6176  0.1329\n",
      "     29       10.6176       0.3340       10.6176  0.1311\n",
      "     30       10.6176       0.3340       10.6176  0.1287\n",
      "     31       10.6176       0.3340       10.6176  0.1307\n",
      "     32       10.6176       0.3340       10.6176  0.1305\n",
      "     33       10.6176       0.3340       10.6176  0.1315\n",
      "     34       10.6176       0.3340       10.6176  0.1405\n",
      "     35       10.6176       0.3340       10.6176  0.1369\n",
      "     36       10.6176       0.3340       10.6176  0.1336\n",
      "     37       10.6176       0.3340       10.6176  0.1388\n",
      "     38       10.6176       0.3340       10.6176  0.1278\n",
      "     39       10.6176       0.3340       10.6176  0.1480\n",
      "     40       10.6176       0.3340       10.6176  0.1330\n",
      "     41       10.6176       0.3340       10.6176  0.1354\n",
      "     42       10.6176       0.3340       10.6176  0.1345\n",
      "     43       10.6176       0.3340       10.6176  0.1329\n",
      "     44       10.6176       0.3340       10.6176  0.1496\n",
      "     45       10.6176       0.3340       10.6176  0.1317\n",
      "     46       10.6176       0.3340       10.6176  0.1356\n",
      "     47       10.6176       0.3340       10.6176  0.1429\n",
      "     48       10.6176       0.3340       10.6176  0.1361\n",
      "     49       10.6176       0.3340       10.6176  0.1289\n",
      "     50       10.6176       0.3340       10.6176  0.1325\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9016\u001b[0m       \u001b[32m0.6100\u001b[0m        \u001b[35m0.8294\u001b[0m  0.1412\n",
      "      2        \u001b[36m0.8301\u001b[0m       \u001b[32m0.6440\u001b[0m        \u001b[35m0.8004\u001b[0m  0.1400\n",
      "      3        \u001b[36m0.8130\u001b[0m       0.6430        0.8219  0.1577\n",
      "      4        \u001b[36m0.8095\u001b[0m       0.6390        0.8241  0.1519\n",
      "      5        0.8225       0.6270        0.8261  0.1428\n",
      "      6        0.8111       0.6180        0.8240  0.1519\n",
      "      7        0.8120       0.6290        0.8133  0.1570\n",
      "      8        0.8138       0.6190        0.8245  0.1549\n",
      "      9        0.8151       0.6420        0.8062  0.1573\n",
      "     10        0.8112       0.6420        0.8079  0.1561\n",
      "     11        0.8129       0.6280        0.8147  0.1521\n",
      "     12        0.8141       0.6440        0.8078  0.1633\n",
      "     13        \u001b[36m0.8062\u001b[0m       0.6330        0.8110  0.1886\n",
      "     14        \u001b[36m0.8051\u001b[0m       0.6330        0.8122  0.1599\n",
      "     15        0.8059       0.6170        0.8237  0.1467\n",
      "     16        0.8087       0.6190        0.8218  0.1520\n",
      "     17        0.8077       0.6230        0.8216  0.1530\n",
      "     18        \u001b[36m0.8028\u001b[0m       0.6290        0.8148  0.1542\n",
      "     19        0.8054       0.6260        0.8161  0.1679\n",
      "     20        0.8059       0.6250        0.8176  0.1547\n",
      "     21        0.8040       0.6250        0.8174  0.1723\n",
      "     22        0.8055       0.6230        0.8213  0.1517\n",
      "     23        0.8058       0.6250        0.8184  0.1542\n",
      "     24        0.8049       0.6200        0.8186  0.1472\n",
      "     25        0.8043       0.6200        0.8196  0.1574\n",
      "     26        0.8050       0.6240        0.8188  0.1528\n",
      "     27        0.8042       0.6180        0.8222  0.1552\n",
      "     28        0.8052       0.6180        0.8219  0.1488\n",
      "     29        0.8039       \u001b[32m0.6530\u001b[0m        0.8212  0.1610\n",
      "     30        \u001b[36m0.8023\u001b[0m       0.6220        0.8202  0.1502\n",
      "     31        0.8045       0.6190        0.8210  0.1523\n",
      "     32        0.8033       0.6210        0.8211  0.1513\n",
      "     33        0.8025       0.6230        0.8194  0.1522\n",
      "     34        0.8044       0.6200        0.8222  0.1556\n",
      "     35        0.8024       0.6210        0.8197  0.1525\n",
      "     36        0.8032       0.6200        0.8203  0.1545\n",
      "     37        0.8024       0.6230        0.8210  0.1529\n",
      "     38        0.8031       0.6200        0.8194  0.1661\n",
      "     39        0.8025       0.6200        0.8205  0.1669\n",
      "     40        \u001b[36m0.8022\u001b[0m       0.6210        0.8180  0.1610\n",
      "     41        0.8044       0.6260        0.8127  0.1500\n",
      "     42        \u001b[36m0.8011\u001b[0m       0.6210        0.8208  0.1565\n",
      "     43        0.8018       0.6210        0.8209  0.1508\n",
      "     44        0.8017       0.6210        0.8201  0.1511\n",
      "     45        0.8021       0.6230        0.8199  0.1581\n",
      "     46        0.8019       0.6220        0.8199  0.1553\n",
      "     47        0.8026       0.6210        0.8209  0.1538\n",
      "     48        0.8017       0.6220        0.8204  0.1562\n",
      "     49        0.8016       0.6230        0.8197  0.1623\n",
      "     50        0.8027       0.6190        0.8241  0.1529\n",
      "     51        0.8021       0.6210        0.8213  0.1532\n",
      "     52        0.8020       0.6220        0.8184  0.1500\n",
      "     53        0.8021       0.6190        0.8244  0.1891\n",
      "     54        0.8018       0.6220        0.8181  0.1534\n",
      "     55        0.8021       0.6190        0.8242  0.1539\n",
      "     56        0.8017       0.6220        0.8197  0.1622\n",
      "     57        \u001b[36m0.8010\u001b[0m       0.6220        0.8199  0.1540\n",
      "     58        0.8019       0.6210        0.8199  0.1664\n",
      "     59        0.8013       0.6210        0.8208  0.1549\n",
      "     60        0.8018       0.6220        0.8182  0.1603\n",
      "     61        0.8029       0.6180        0.8238  0.1547\n",
      "     62        0.8011       0.6210        0.8225  0.1576\n",
      "     63        0.8017       0.6220        0.8216  0.1557\n",
      "     64        0.8024       0.6210        0.8231  0.1625\n",
      "     65        0.8015       0.6220        0.8224  0.1629\n",
      "     66        \u001b[36m0.8005\u001b[0m       0.6210        0.8241  0.1589\n",
      "     67        0.8007       0.6190        0.8231  0.1529\n",
      "     68        0.8021       0.6190        0.8234  0.1576\n",
      "     69        0.8014       0.6220        0.8225  0.1622\n",
      "     70        0.8008       0.6210        0.8226  0.1814\n",
      "     71        0.8012       0.6210        0.8234  0.1624\n",
      "     72        0.8013       0.6210        0.8215  0.1572\n",
      "     73        0.8008       0.6200        0.8231  0.1591\n",
      "     74        0.8011       0.6220        0.8226  0.1620\n",
      "     75        0.8010       0.6210        0.8238  0.1645\n",
      "     76        0.8005       0.6200        0.8248  0.1488\n",
      "     77        0.8009       0.6200        0.8251  0.1708\n",
      "     78        0.8012       0.6190        0.8258  0.1571\n",
      "     79        0.8007       0.6210        0.8242  0.1650\n",
      "     80        0.8022       0.6180        0.8249  0.1679\n",
      "     81        0.8015       0.6170        0.8235  0.1604\n",
      "     82        0.8015       0.6200        0.8215  0.1508\n",
      "     83        \u001b[36m0.7997\u001b[0m       0.6210        0.8227  0.1722\n",
      "     84        0.8016       0.6190        0.8242  0.1687\n",
      "     85        0.8011       0.6200        0.8234  0.1544\n",
      "     86        0.8018       0.6190        0.8230  0.1736\n",
      "     87        0.8012       0.6200        0.8214  0.1593\n",
      "     88        0.8001       0.6220        0.8217  0.1574\n",
      "     89        0.8010       0.6240        0.8205  0.1506\n",
      "     90        0.8012       0.6220        0.8197  0.1639\n",
      "     91        0.8006       0.6210        0.8228  0.1630\n",
      "     92        0.8010       0.6180        0.8248  0.1628\n",
      "     93        \u001b[36m0.7995\u001b[0m       0.6250        0.8198  0.1657\n",
      "     94        0.8003       0.6250        0.8163  0.1690\n",
      "     95        0.8018       0.6220        0.8221  0.1937\n",
      "     96        0.8001       0.6180        0.8264  0.1652\n",
      "     97        0.8015       0.6190        0.8259  0.1661\n",
      "     98        0.8005       0.6190        0.8237  0.1531\n",
      "     99        0.8021       0.6180        0.8261  0.1567\n",
      "    100        0.8008       0.6180        0.8260  0.1619\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8365\u001b[0m       \u001b[32m0.5280\u001b[0m        \u001b[35m1.0088\u001b[0m  0.1430\n",
      "      2        \u001b[36m0.7290\u001b[0m       \u001b[32m0.7170\u001b[0m        \u001b[35m0.6843\u001b[0m  0.1469\n",
      "      3        \u001b[36m0.6879\u001b[0m       0.6790        0.7162  0.1557\n",
      "      4        \u001b[36m0.6716\u001b[0m       0.6480        0.7726  0.1546\n",
      "      5        \u001b[36m0.6666\u001b[0m       0.6920        0.7709  0.1518\n",
      "      6        0.6677       0.6770        0.7687  0.1621\n",
      "      7        0.6730       0.6750        0.7929  0.1647\n",
      "      8        0.6955       0.6930        0.7711  0.1623\n",
      "      9        0.6704       0.6700        0.7968  0.1615\n",
      "     10        0.6762       0.6600        0.8561  0.1815\n",
      "     11        0.6763       0.6700        0.7789  0.1552\n",
      "     12        0.6708       0.6550        0.8167  0.1490\n",
      "     13        0.6682       0.6770        0.7627  0.1558\n",
      "     14        0.6766       0.6240        0.9862  0.1501\n",
      "     15        0.7357       \u001b[32m0.7440\u001b[0m        \u001b[35m0.6559\u001b[0m  0.1507\n",
      "     16        0.6743       0.7090        0.7480  0.1527\n",
      "     17        0.6774       0.7360        0.6822  0.1519\n",
      "     18        0.6794       0.7110        0.7392  0.1542\n",
      "     19        \u001b[36m0.6634\u001b[0m       0.7360        0.6714  0.1520\n",
      "     20        0.6667       0.7120        0.7222  0.1537\n",
      "     21        \u001b[36m0.6564\u001b[0m       0.6950        0.7257  0.1510\n",
      "     22        0.6650       0.7400        0.6938  0.1571\n",
      "     23        0.6822       0.6260        1.0493  0.1529\n",
      "     24        0.6821       0.7230        0.6951  0.1758\n",
      "     25        0.7885       0.5020        0.9815  0.1446\n",
      "     26        0.8561       0.6020        0.8650  0.1576\n",
      "     27        0.7887       0.5730        0.8372  0.1493\n",
      "     28        0.7864       0.6840        0.8471  0.1536\n",
      "     29        0.7093       0.7400        0.7224  0.1536\n",
      "     30        0.7497       0.7070        0.8030  0.1550\n",
      "     31        0.7027       0.6960        0.8781  0.1565\n",
      "     32        0.8220       0.6410        0.8581  0.1689\n",
      "     33        0.7839       0.6180        0.9624  0.1498\n",
      "     34        0.7286       0.7360        0.6803  0.1499\n",
      "     35        0.6990       0.7290        0.7006  0.1528\n",
      "     36        0.7747       0.6800        0.8849  0.1578\n",
      "     37        0.7384       0.6340        0.8537  0.1569\n",
      "     38        0.6933       0.6360        0.8586  0.1565\n",
      "     39        0.6826       0.6830        0.7655  0.1533\n",
      "     40        0.6862       0.7290        0.7048  0.1538\n",
      "     41        0.6756       0.7090        0.7552  0.1535\n",
      "     42        0.7051       0.7200        0.7221  0.1535\n",
      "     43        0.6752       0.7130        0.7760  0.1522\n",
      "     44        0.6860       0.6260        0.9053  0.1527\n",
      "     45        0.6810       0.5690        0.9980  0.1521\n",
      "     46        0.7170       0.7290        0.7331  0.1550\n",
      "     47        0.6787       0.6750        0.7732  0.1525\n",
      "     48        0.6786       0.7310        0.6953  0.1698\n",
      "     49        0.6801       0.7070        0.7636  0.1571\n",
      "     50        0.6995       0.7400        0.6832  0.1580\n",
      "     51        0.6794       0.6780        0.8051  0.1577\n",
      "     52        0.6748       0.7340        0.7063  0.1506\n",
      "     53        0.6780       0.6750        0.7904  0.1503\n",
      "     54        0.7096       0.6760        0.7964  0.1559\n",
      "     55        0.6956       0.7250        0.7471  0.1511\n",
      "     56        0.7210       0.6650        0.8187  0.1570\n",
      "     57        0.6847       0.7390        0.6691  0.1565\n",
      "     58        0.6804       0.6780        0.7764  0.1564\n",
      "     59        0.6781       0.7120        0.7215  0.1507\n",
      "     60        0.6727       0.7320        0.7100  0.1615\n",
      "     61        0.6899       0.7380        0.6770  0.1611\n",
      "     62        0.6756       0.6440        0.8589  0.1485\n",
      "     63        0.6842       0.6790        0.7638  0.1574\n",
      "     64        0.7217       0.6490        0.7941  0.1567\n",
      "     65        0.6907       0.7410        0.7022  0.1783\n",
      "     66        0.6808       0.7390        0.6933  0.1582\n",
      "     67        0.6860       0.6640        0.7939  0.1572\n",
      "     68        0.6781       0.7410        0.6893  0.1601\n",
      "     69        0.6709       0.6780        0.7744  0.1555\n",
      "     70        0.6785       0.6430        0.9197  0.1484\n",
      "     71        0.7114       0.7240        0.7338  0.1614\n",
      "     72        0.6882       0.7420        0.6842  0.1605\n",
      "     73        0.6752       0.6640        0.7848  0.1601\n",
      "     74        0.6955       0.7300        0.7245  0.1562\n",
      "     75        0.6792       0.7350        0.6883  0.1577\n",
      "     76        0.7105       0.6520        0.8997  0.1553\n",
      "     77        0.7059       0.7240        0.7278  0.1613\n",
      "     78        0.6804       0.7440        0.7380  0.1543\n",
      "     79        0.6873       0.6430        0.7928  0.1632\n",
      "     80        0.6826       0.6260        0.7639  0.1615\n",
      "     81        0.6803       0.5920        0.8869  0.1623\n",
      "     82        0.6992       0.6490        0.8621  0.1686\n",
      "     83        0.7025       0.5990        1.0072  0.1728\n",
      "     84        0.7267       0.6840        0.8826  0.1589\n",
      "     85        0.7403       0.6610        0.8016  0.1596\n",
      "     86        0.7190       0.6540        0.9165  0.1479\n",
      "     87        0.6941       0.6880        0.7591  0.1655\n",
      "     88        0.6839       0.6650        0.8278  0.1515\n",
      "     89        0.7210       0.7060        0.7443  0.1556\n",
      "     90        0.6743       0.7300        0.7276  0.1655\n",
      "     91        0.6806       0.7370        0.7408  0.1646\n",
      "     92        0.6853       0.7060        0.7491  0.1558\n",
      "     93        0.6861       0.6790        0.7991  0.1553\n",
      "     94        0.6695       0.6000        0.9409  0.1568\n",
      "     95        0.6888       0.6760        0.8102  0.1660\n",
      "     96        0.7101       0.7380        0.7056  0.1631\n",
      "     97        0.6772       0.7230        0.7310  0.1829\n",
      "     98        0.7046       0.7330        0.6957  0.1661\n",
      "     99        0.6936       0.6470        0.8567  0.1602\n",
      "    100        0.6747       0.6540        0.7993  0.1572\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.6175\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1269\n",
      "      2       10.6176       0.3340       10.6176  0.1305\n",
      "      3       10.6176       0.3340       10.6176  0.1309\n",
      "      4       10.6176       0.3340       10.6176  0.1299\n",
      "      5       10.6176       0.3340       10.6176  0.1263\n",
      "      6       10.6176       0.3340       10.6176  0.1242\n",
      "      7       10.6176       0.3340       10.6176  0.1320\n",
      "      8       10.6176       0.3340       10.6176  0.1298\n",
      "      9       10.6176       0.3340       10.6176  0.1278\n",
      "     10       10.6176       0.3340       10.6176  0.1272\n",
      "     11       10.6176       0.3340       10.6176  0.1281\n",
      "     12       10.6176       0.3340       10.6176  0.1345\n",
      "     13       10.6176       0.3340       10.6176  0.1720\n",
      "     14       10.6176       0.3340       10.6176  0.1373\n",
      "     15       10.6176       0.3340       10.6176  0.1272\n",
      "     16       10.6176       0.3340       10.6176  0.1367\n",
      "     17       10.6176       0.3340       10.6176  0.1420\n",
      "     18       10.6176       0.3340       10.6176  0.1328\n",
      "     19       10.6176       0.3340       10.6176  0.1372\n",
      "     20       10.6176       0.3340       10.6176  0.1321\n",
      "     21       10.6176       0.3340       10.6176  0.1367\n",
      "     22       10.6176       0.3340       10.6176  0.1392\n",
      "     23       10.6176       0.3340       10.6176  0.1313\n",
      "     24       10.6176       0.3340       10.6176  0.1288\n",
      "     25       10.6176       0.3340       10.6176  0.1475\n",
      "     26       10.6176       0.3340       10.6176  0.1359\n",
      "     27       10.6176       0.3340       10.6176  0.1348\n",
      "     28       10.6176       0.3340       10.6176  0.1269\n",
      "     29       10.6176       0.3340       10.6176  0.1293\n",
      "     30       10.6176       0.3340       10.6176  0.1337\n",
      "     31       10.6176       0.3340       10.6176  0.1334\n",
      "     32       10.6176       0.3340       10.6176  0.1400\n",
      "     33       10.6176       0.3340       10.6176  0.1298\n",
      "     34       10.6176       0.3340       10.6176  0.1408\n",
      "     35       10.6176       0.3340       10.6176  0.1326\n",
      "     36       10.6176       0.3340       10.6176  0.1384\n",
      "     37       10.6176       0.3340       10.6176  0.1352\n",
      "     38       10.6176       0.3340       10.6176  0.1377\n",
      "     39       10.6176       0.3340       10.6176  0.1394\n",
      "     40       10.6176       0.3340       10.6176  0.1341\n",
      "     41       10.6176       0.3340       10.6176  0.1341\n",
      "     42       10.6176       0.3340       10.6176  0.1356\n",
      "     43       10.6176       0.3340       10.6176  0.1265\n",
      "     44       10.6176       0.3340       10.6176  0.1283\n",
      "     45       10.6176       0.3340       10.6176  0.1305\n",
      "     46       10.6176       0.3340       10.6176  0.1316\n",
      "     47       10.6176       0.3340       10.6176  0.1319\n",
      "     48       10.6176       0.3340       10.6176  0.1306\n",
      "     49       10.6176       0.3340       10.6176  0.1327\n",
      "     50       10.6176       0.3340       10.6176  0.1292\n",
      "     51       10.6176       0.3340       10.6176  0.1264\n",
      "     52       10.6176       0.3340       10.6176  0.1320\n",
      "     53       10.6176       0.3340       10.6176  0.1308\n",
      "     54       10.6176       0.3340       10.6176  0.1307\n",
      "     55       10.6176       0.3340       10.6176  0.1310\n",
      "     56       10.6176       0.3340       10.6176  0.1357\n",
      "     57       10.6176       0.3340       10.6176  0.1428\n",
      "     58       10.6176       0.3340       10.6176  0.1385\n",
      "     59       10.6176       0.3340       10.6176  0.1656\n",
      "     60       10.6176       0.3340       10.6176  0.1420\n",
      "     61       10.6176       0.3340       10.6176  0.1394\n",
      "     62       10.6176       0.3340       10.6176  0.1432\n",
      "     63       10.6176       0.3340       10.6176  0.1434\n",
      "     64       10.6176       0.3340       10.6176  0.1423\n",
      "     65       10.6176       0.3340       10.6176  0.1455\n",
      "     66       10.6176       0.3340       10.6176  0.1395\n",
      "     67       10.6176       0.3340       10.6176  0.1583\n",
      "     68       10.6176       0.3340       10.6176  0.1418\n",
      "     69       10.6176       0.3340       10.6176  0.1436\n",
      "     70       10.6176       0.3340       10.6176  0.1411\n",
      "     71       10.6176       0.3340       10.6176  0.1369\n",
      "     72       10.6176       0.3340       10.6176  0.1387\n",
      "     73       10.6176       0.3340       10.6176  0.1431\n",
      "     74       10.6176       0.3340       10.6176  0.1354\n",
      "     75       10.6176       0.3340       10.6176  0.1350\n",
      "     76       10.6176       0.3340       10.6176  0.1430\n",
      "     77       10.6176       0.3340       10.6176  0.1370\n",
      "     78       10.6176       0.3340       10.6176  0.1454\n",
      "     79       10.6176       0.3340       10.6176  0.1463\n",
      "     80       10.6176       0.3340       10.6176  0.1466\n",
      "     81       10.6176       0.3340       10.6176  0.1414\n",
      "     82       10.6176       0.3340       10.6176  0.1394\n",
      "     83       10.6176       0.3340       10.6176  0.1408\n",
      "     84       10.6176       0.3340       10.6176  0.1428\n",
      "     85       10.6176       0.3340       10.6176  0.1438\n",
      "     86       10.6176       0.3340       10.6176  0.1578\n",
      "     87       10.6176       0.3340       10.6176  0.1436\n",
      "     88       10.6176       0.3340       10.6176  0.1795\n",
      "     89       10.6176       0.3340       10.6176  0.1415\n",
      "     90       10.6176       0.3340       10.6176  0.1435\n",
      "     91       10.6176       0.3340       10.6176  0.1363\n",
      "     92       10.6176       0.3340       10.6176  0.1380\n",
      "     93       10.6176       0.3340       10.6176  0.1428\n",
      "     94       10.6176       0.3340       10.6176  0.1434\n",
      "     95       10.6176       0.3340       10.6176  0.1378\n",
      "     96       10.6176       0.3340       10.6176  0.1397\n",
      "     97       10.6176       0.3340       10.6176  0.1408\n",
      "     98       10.6176       0.3340       10.6176  0.1494\n",
      "     99       10.6176       0.3340       10.6176  0.1393\n",
      "    100       10.6176       0.3340       10.6176  0.1494\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5664\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1231\n",
      "      2       10.6176       0.3340       10.6176  0.1321\n",
      "      3       10.6176       0.3340       10.6176  0.1328\n",
      "      4       10.6176       0.3340       10.6176  0.1287\n",
      "      5       10.6176       0.3340       10.6176  0.1290\n",
      "      6       10.6176       0.3340       10.6176  0.1278\n",
      "      7       10.6176       0.3340       10.6176  0.1313\n",
      "      8       10.6176       0.3340       10.6176  0.1336\n",
      "      9       10.6176       0.3340       10.6176  0.1486\n",
      "     10       10.6176       0.3340       10.6176  0.1280\n",
      "     11       10.6176       0.3340       10.6176  0.1198\n",
      "     12       10.6176       0.3340       10.6176  0.1285\n",
      "     13       10.6176       0.3340       10.6176  0.1272\n",
      "     14       10.6176       0.3340       10.6176  0.1316\n",
      "     15       10.6176       0.3340       10.6176  0.1264\n",
      "     16       10.6176       0.3340       10.6176  0.1259\n",
      "     17       10.6176       0.3340       10.6176  0.1319\n",
      "     18       10.6176       0.3340       10.6176  0.1257\n",
      "     19       10.6176       0.3340       10.6176  0.1279\n",
      "     20       10.6176       0.3340       10.6176  0.1301\n",
      "     21       10.6176       0.3340       10.6176  0.1286\n",
      "     22       10.6176       0.3340       10.6176  0.1327\n",
      "     23       10.6176       0.3340       10.6176  0.1292\n",
      "     24       10.6176       0.3340       10.6176  0.1315\n",
      "     25       10.6176       0.3340       10.6176  0.1288\n",
      "     26       10.6176       0.3340       10.6176  0.1387\n",
      "     27       10.6176       0.3340       10.6176  0.1313\n",
      "     28       10.6176       0.3340       10.6176  0.1317\n",
      "     29       10.6176       0.3340       10.6176  0.1343\n",
      "     30       10.6176       0.3340       10.6176  0.1334\n",
      "     31       10.6176       0.3340       10.6176  0.1377\n",
      "     32       10.6176       0.3340       10.6176  0.1439\n",
      "     33       10.6176       0.3340       10.6176  0.1304\n",
      "     34       10.6176       0.3340       10.6176  0.1311\n",
      "     35       10.6176       0.3340       10.6176  0.1319\n",
      "     36       10.6176       0.3340       10.6176  0.1282\n",
      "     37       10.6176       0.3340       10.6176  0.1313\n",
      "     38       10.6176       0.3340       10.6176  0.1364\n",
      "     39       10.6176       0.3340       10.6176  0.1315\n",
      "     40       10.6176       0.3340       10.6176  0.1289\n",
      "     41       10.6176       0.3340       10.6176  0.1381\n",
      "     42       10.6176       0.3340       10.6176  0.1354\n",
      "     43       10.6176       0.3340       10.6176  0.1497\n",
      "     44       10.6176       0.3340       10.6176  0.1264\n",
      "     45       10.6176       0.3340       10.6176  0.1347\n",
      "     46       10.6176       0.3340       10.6176  0.1329\n",
      "     47       10.6176       0.3340       10.6176  0.1425\n",
      "     48       10.6176       0.3340       10.6176  0.1268\n",
      "     49       10.6176       0.3340       10.6176  0.1397\n",
      "     50       10.6176       0.3340       10.6176  0.1310\n",
      "     51       10.6176       0.3340       10.6176  0.1454\n",
      "     52       10.6176       0.3340       10.6176  0.1297\n",
      "     53       10.6176       0.3340       10.6176  0.1543\n",
      "     54       10.6176       0.3340       10.6176  0.1482\n",
      "     55       10.6176       0.3340       10.6176  0.1388\n",
      "     56       10.6176       0.3340       10.6176  0.1401\n",
      "     57       10.6176       0.3340       10.6176  0.1374\n",
      "     58       10.6176       0.3340       10.6176  0.1399\n",
      "     59       10.6176       0.3340       10.6176  0.1390\n",
      "     60       10.6176       0.3340       10.6176  0.1372\n",
      "     61       10.6176       0.3340       10.6176  0.1498\n",
      "     62       10.6176       0.3340       10.6176  0.1399\n",
      "     63       10.6176       0.3340       10.6176  0.1681\n",
      "     64       10.6176       0.3340       10.6176  0.1457\n",
      "     65       10.6176       0.3340       10.6176  0.1482\n",
      "     66       10.6176       0.3340       10.6176  0.1475\n",
      "     67       10.6176       0.3340       10.6176  0.1450\n",
      "     68       10.6176       0.3340       10.6176  0.1630\n",
      "     69       10.6176       0.3340       10.6176  0.1505\n",
      "     70       10.6176       0.3340       10.6176  0.1408\n",
      "     71       10.6176       0.3340       10.6176  0.1381\n",
      "     72       10.6176       0.3340       10.6176  0.1402\n",
      "     73       10.6176       0.3340       10.6176  0.1434\n",
      "     74       10.6176       0.3340       10.6176  0.1398\n",
      "     75       10.6176       0.3340       10.6176  0.1376\n",
      "     76       10.6176       0.3340       10.6176  0.1412\n",
      "     77       10.6176       0.3340       10.6176  0.1446\n",
      "     78       10.6176       0.3340       10.6176  0.1438\n",
      "     79       10.6176       0.3340       10.6176  0.1422\n",
      "     80       10.6176       0.3340       10.6176  0.1472\n",
      "     81       10.6176       0.3340       10.6176  0.1362\n",
      "     82       10.6176       0.3340       10.6176  0.1429\n",
      "     83       10.6176       0.3340       10.6176  0.1392\n",
      "     84       10.6176       0.3340       10.6176  0.1497\n",
      "     85       10.6176       0.3340       10.6176  0.1494\n",
      "     86       10.6176       0.3340       10.6176  0.1511\n",
      "     87       10.6176       0.3340       10.6176  0.1487\n",
      "     88       10.6176       0.3340       10.6176  0.1427\n",
      "     89       10.6176       0.3340       10.6176  0.1443\n",
      "     90       10.6176       0.3340       10.6176  0.1369\n",
      "     91       10.6176       0.3340       10.6176  0.1542\n",
      "     92       10.6176       0.3340       10.6176  0.1388\n",
      "     93       10.6176       0.3340       10.6176  0.1413\n",
      "     94       10.6176       0.3340       10.6176  0.1430\n",
      "     95       10.6176       0.3340       10.6176  0.1417\n",
      "     96       10.6176       0.3340       10.6176  0.1567\n",
      "     97       10.6176       0.3340       10.6176  0.1534\n",
      "     98       10.6176       0.3340       10.6176  0.1528\n",
      "     99       10.6176       0.3340       10.6176  0.1389\n",
      "    100       10.6176       0.3340       10.6176  0.1552\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8340\u001b[0m       \u001b[32m0.6510\u001b[0m        \u001b[35m0.7380\u001b[0m  0.1010\n",
      "      2        \u001b[36m0.7112\u001b[0m       \u001b[32m0.6760\u001b[0m        \u001b[35m0.6998\u001b[0m  0.1062\n",
      "      3        \u001b[36m0.6791\u001b[0m       \u001b[32m0.6920\u001b[0m        \u001b[35m0.6864\u001b[0m  0.1037\n",
      "      4        \u001b[36m0.6554\u001b[0m       \u001b[32m0.7040\u001b[0m        \u001b[35m0.6683\u001b[0m  0.1068\n",
      "      5        \u001b[36m0.6395\u001b[0m       \u001b[32m0.7070\u001b[0m        \u001b[35m0.6619\u001b[0m  0.1091\n",
      "      6        \u001b[36m0.6312\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6587\u001b[0m  0.0952\n",
      "      7        \u001b[36m0.6268\u001b[0m       0.7060        \u001b[35m0.6526\u001b[0m  0.0990\n",
      "      8        \u001b[36m0.6223\u001b[0m       0.7000        \u001b[35m0.6513\u001b[0m  0.1017\n",
      "      9        \u001b[36m0.6170\u001b[0m       0.7000        \u001b[35m0.6493\u001b[0m  0.0973\n",
      "     10        \u001b[36m0.6146\u001b[0m       0.7010        \u001b[35m0.6485\u001b[0m  0.1030\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8004\u001b[0m       \u001b[32m0.5430\u001b[0m        \u001b[35m0.8349\u001b[0m  0.1008\n",
      "      2        \u001b[36m0.7109\u001b[0m       \u001b[32m0.6630\u001b[0m        \u001b[35m0.7263\u001b[0m  0.1245\n",
      "      3        \u001b[36m0.6671\u001b[0m       \u001b[32m0.6930\u001b[0m        \u001b[35m0.6911\u001b[0m  0.1031\n",
      "      4        \u001b[36m0.6468\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.6560\u001b[0m  0.0968\n",
      "      5        \u001b[36m0.6337\u001b[0m       \u001b[32m0.7400\u001b[0m        \u001b[35m0.6337\u001b[0m  0.0905\n",
      "      6        \u001b[36m0.6265\u001b[0m       \u001b[32m0.7570\u001b[0m        \u001b[35m0.6135\u001b[0m  0.0986\n",
      "      7        \u001b[36m0.6175\u001b[0m       0.7570        \u001b[35m0.6033\u001b[0m  0.1002\n",
      "      8        \u001b[36m0.6127\u001b[0m       0.7540        \u001b[35m0.6030\u001b[0m  0.0996\n",
      "      9        \u001b[36m0.6101\u001b[0m       0.7560        \u001b[35m0.6007\u001b[0m  0.0996\n",
      "     10        \u001b[36m0.6082\u001b[0m       0.7540        0.6020  0.0976\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8947\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.7268\u001b[0m  0.0892\n",
      "      2        \u001b[36m0.7083\u001b[0m       \u001b[32m0.7070\u001b[0m        \u001b[35m0.6771\u001b[0m  0.0886\n",
      "      3        \u001b[36m0.6668\u001b[0m       \u001b[32m0.7080\u001b[0m        \u001b[35m0.6637\u001b[0m  0.0886\n",
      "      4        \u001b[36m0.6448\u001b[0m       \u001b[32m0.7180\u001b[0m        \u001b[35m0.6536\u001b[0m  0.0877\n",
      "      5        \u001b[36m0.6355\u001b[0m       0.7160        \u001b[35m0.6491\u001b[0m  0.0968\n",
      "      6        \u001b[36m0.6281\u001b[0m       0.7170        0.6496  0.0907\n",
      "      7        \u001b[36m0.6224\u001b[0m       0.7160        0.6492  0.0895\n",
      "      8        \u001b[36m0.6164\u001b[0m       \u001b[32m0.7280\u001b[0m        \u001b[35m0.6433\u001b[0m  0.0911\n",
      "      9        \u001b[36m0.6126\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.6386\u001b[0m  0.0907\n",
      "     10        \u001b[36m0.6070\u001b[0m       0.7300        0.6399  0.0925\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8922\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.0954\u001b[0m  0.0881\n",
      "      2        \u001b[36m0.7041\u001b[0m       \u001b[32m0.5050\u001b[0m        \u001b[35m0.9226\u001b[0m  0.0849\n",
      "      3        \u001b[36m0.6663\u001b[0m       \u001b[32m0.5450\u001b[0m        \u001b[35m0.9038\u001b[0m  0.0867\n",
      "      4        \u001b[36m0.6488\u001b[0m       \u001b[32m0.6000\u001b[0m        \u001b[35m0.8431\u001b[0m  0.0891\n",
      "      5        \u001b[36m0.6372\u001b[0m       \u001b[32m0.6200\u001b[0m        \u001b[35m0.8158\u001b[0m  0.0854\n",
      "      6        \u001b[36m0.6328\u001b[0m       \u001b[32m0.6480\u001b[0m        \u001b[35m0.7835\u001b[0m  0.0934\n",
      "      7        \u001b[36m0.6264\u001b[0m       \u001b[32m0.6690\u001b[0m        \u001b[35m0.7687\u001b[0m  0.0873\n",
      "      8        \u001b[36m0.6218\u001b[0m       \u001b[32m0.6780\u001b[0m        \u001b[35m0.7609\u001b[0m  0.0942\n",
      "      9        \u001b[36m0.6192\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m0.7584\u001b[0m  0.0881\n",
      "     10        \u001b[36m0.6145\u001b[0m       \u001b[32m0.6850\u001b[0m        \u001b[35m0.7517\u001b[0m  0.0892\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8315\u001b[0m       \u001b[32m0.6500\u001b[0m        \u001b[35m0.7215\u001b[0m  0.0961\n",
      "      2        \u001b[36m0.6926\u001b[0m       \u001b[32m0.6890\u001b[0m        \u001b[35m0.6841\u001b[0m  0.0971\n",
      "      3        \u001b[36m0.6615\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6658\u001b[0m  0.1188\n",
      "      4        \u001b[36m0.6429\u001b[0m       0.7060        \u001b[35m0.6524\u001b[0m  0.0957\n",
      "      5        \u001b[36m0.6307\u001b[0m       0.7070        \u001b[35m0.6480\u001b[0m  0.1005\n",
      "      6        \u001b[36m0.6251\u001b[0m       0.7050        0.6486  0.1008\n",
      "      7        \u001b[36m0.6214\u001b[0m       0.6920        0.6547  0.1137\n",
      "      8        \u001b[36m0.6191\u001b[0m       0.6990        0.6601  0.1024\n",
      "      9        \u001b[36m0.6178\u001b[0m       0.6950        0.6724  0.1045\n",
      "     10        \u001b[36m0.6158\u001b[0m       0.6940        0.6716  0.1047\n",
      "     11        \u001b[36m0.6112\u001b[0m       0.7080        0.6523  0.1018\n",
      "     12        \u001b[36m0.6081\u001b[0m       \u001b[32m0.7110\u001b[0m        0.6578  0.1165\n",
      "     13        \u001b[36m0.6062\u001b[0m       \u001b[32m0.7210\u001b[0m        0.6534  0.1072\n",
      "     14        \u001b[36m0.6003\u001b[0m       0.7160        \u001b[35m0.6448\u001b[0m  0.1057\n",
      "     15        \u001b[36m0.5969\u001b[0m       \u001b[32m0.7280\u001b[0m        \u001b[35m0.6418\u001b[0m  0.1055\n",
      "     16        \u001b[36m0.5931\u001b[0m       \u001b[32m0.7370\u001b[0m        0.6428  0.1026\n",
      "     17        \u001b[36m0.5899\u001b[0m       0.7290        \u001b[35m0.6416\u001b[0m  0.1011\n",
      "     18        \u001b[36m0.5889\u001b[0m       \u001b[32m0.7450\u001b[0m        \u001b[35m0.6411\u001b[0m  0.0992\n",
      "     19        \u001b[36m0.5843\u001b[0m       0.7320        0.6514  0.1026\n",
      "     20        0.5848       0.7320        0.6535  0.1009\n",
      "     21        \u001b[36m0.5813\u001b[0m       0.7330        0.6600  0.0994\n",
      "     22        0.5821       0.7300        0.6536  0.1006\n",
      "     23        \u001b[36m0.5805\u001b[0m       0.7270        0.6598  0.0992\n",
      "     24        \u001b[36m0.5787\u001b[0m       0.7310        0.6549  0.1016\n",
      "     25        \u001b[36m0.5749\u001b[0m       0.7200        0.6520  0.1112\n",
      "     26        0.5750       0.7390        0.6458  0.1007\n",
      "     27        0.5760       0.7270        \u001b[35m0.6389\u001b[0m  0.1027\n",
      "     28        0.5756       0.7320        0.6432  0.1003\n",
      "     29        \u001b[36m0.5668\u001b[0m       0.7190        0.6470  0.0997\n",
      "     30        0.5714       0.7260        0.6450  0.1022\n",
      "     31        \u001b[36m0.5651\u001b[0m       0.7250        0.6531  0.1006\n",
      "     32        0.5662       0.7150        0.6516  0.0997\n",
      "     33        \u001b[36m0.5616\u001b[0m       0.7220        0.6565  0.1013\n",
      "     34        0.5649       0.7310        0.6568  0.1041\n",
      "     35        0.5654       0.7300        0.6582  0.1057\n",
      "     36        0.5621       0.7300        0.6559  0.1129\n",
      "     37        \u001b[36m0.5587\u001b[0m       0.7260        0.6662  0.1049\n",
      "     38        0.5606       0.7260        0.6582  0.1073\n",
      "     39        \u001b[36m0.5543\u001b[0m       0.7220        0.6656  0.0988\n",
      "     40        \u001b[36m0.5497\u001b[0m       0.7260        0.6533  0.1007\n",
      "     41        \u001b[36m0.5466\u001b[0m       0.7280        0.6667  0.1060\n",
      "     42        0.5505       0.7200        0.6924  0.1047\n",
      "     43        0.5543       0.7140        0.6803  0.1071\n",
      "     44        0.5487       0.7210        0.6960  0.1053\n",
      "     45        \u001b[36m0.5439\u001b[0m       0.7190        0.6893  0.1049\n",
      "     46        \u001b[36m0.5392\u001b[0m       0.7190        0.6991  0.1112\n",
      "     47        \u001b[36m0.5381\u001b[0m       0.7200        0.7048  0.1119\n",
      "     48        0.5388       0.7040        0.7179  0.1053\n",
      "     49        \u001b[36m0.5361\u001b[0m       0.7090        0.7349  0.1241\n",
      "     50        \u001b[36m0.5327\u001b[0m       0.7100        0.7273  0.1121\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8129\u001b[0m       \u001b[32m0.5930\u001b[0m        \u001b[35m0.7756\u001b[0m  0.1079\n",
      "      2        \u001b[36m0.7169\u001b[0m       \u001b[32m0.7240\u001b[0m        \u001b[35m0.6732\u001b[0m  0.1079\n",
      "      3        \u001b[36m0.6686\u001b[0m       \u001b[32m0.7270\u001b[0m        \u001b[35m0.6576\u001b[0m  0.1024\n",
      "      4        \u001b[36m0.6460\u001b[0m       \u001b[32m0.7380\u001b[0m        \u001b[35m0.6339\u001b[0m  0.1028\n",
      "      5        \u001b[36m0.6324\u001b[0m       \u001b[32m0.7440\u001b[0m        \u001b[35m0.6201\u001b[0m  0.1027\n",
      "      6        \u001b[36m0.6206\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6150\u001b[0m  0.1034\n",
      "      7        \u001b[36m0.6131\u001b[0m       \u001b[32m0.7510\u001b[0m        \u001b[35m0.6114\u001b[0m  0.0988\n",
      "      8        \u001b[36m0.6081\u001b[0m       \u001b[32m0.7600\u001b[0m        \u001b[35m0.6064\u001b[0m  0.1072\n",
      "      9        \u001b[36m0.6049\u001b[0m       \u001b[32m0.7660\u001b[0m        \u001b[35m0.6026\u001b[0m  0.1102\n",
      "     10        \u001b[36m0.5996\u001b[0m       0.7590        0.6055  0.1054\n",
      "     11        \u001b[36m0.5954\u001b[0m       0.7620        0.6080  0.1015\n",
      "     12        \u001b[36m0.5918\u001b[0m       0.7620        0.6050  0.1093\n",
      "     13        \u001b[36m0.5898\u001b[0m       \u001b[32m0.7670\u001b[0m        0.6043  0.1069\n",
      "     14        \u001b[36m0.5860\u001b[0m       0.7600        0.6052  0.1152\n",
      "     15        \u001b[36m0.5845\u001b[0m       0.7610        \u001b[35m0.5990\u001b[0m  0.1167\n",
      "     16        \u001b[36m0.5788\u001b[0m       0.7620        0.6038  0.1050\n",
      "     17        0.5803       0.7600        0.6021  0.1088\n",
      "     18        \u001b[36m0.5786\u001b[0m       0.7540        0.6097  0.1072\n",
      "     19        \u001b[36m0.5751\u001b[0m       0.7560        0.6086  0.1032\n",
      "     20        \u001b[36m0.5728\u001b[0m       0.7490        0.6097  0.1291\n",
      "     21        \u001b[36m0.5697\u001b[0m       0.7460        0.6180  0.1048\n",
      "     22        0.5704       0.7580        0.6093  0.1079\n",
      "     23        0.5701       0.7600        0.6103  0.1007\n",
      "     24        \u001b[36m0.5693\u001b[0m       0.7510        0.6115  0.1062\n",
      "     25        \u001b[36m0.5636\u001b[0m       0.7500        0.6070  0.1126\n",
      "     26        \u001b[36m0.5624\u001b[0m       0.7560        0.6103  0.1101\n",
      "     27        \u001b[36m0.5587\u001b[0m       0.7510        0.6187  0.1091\n",
      "     28        \u001b[36m0.5583\u001b[0m       0.7520        0.6162  0.1035\n",
      "     29        0.5587       0.7520        0.6067  0.1062\n",
      "     30        \u001b[36m0.5536\u001b[0m       0.7580        0.6045  0.1020\n",
      "     31        \u001b[36m0.5491\u001b[0m       0.7620        0.6067  0.1110\n",
      "     32        0.5508       0.7620        0.6060  0.1155\n",
      "     33        \u001b[36m0.5478\u001b[0m       0.7490        0.6121  0.1036\n",
      "     34        0.5494       0.7460        0.6119  0.1069\n",
      "     35        0.5490       0.7430        0.6237  0.1067\n",
      "     36        \u001b[36m0.5469\u001b[0m       0.7440        0.6249  0.1027\n",
      "     37        \u001b[36m0.5464\u001b[0m       0.7430        0.6259  0.1010\n",
      "     38        \u001b[36m0.5419\u001b[0m       0.7380        0.6278  0.1002\n",
      "     39        0.5422       0.7320        0.6239  0.1004\n",
      "     40        0.5442       0.7420        0.6248  0.1021\n",
      "     41        \u001b[36m0.5386\u001b[0m       0.7340        0.6235  0.0986\n",
      "     42        \u001b[36m0.5345\u001b[0m       0.7510        0.6265  0.0984\n",
      "     43        0.5380       0.7440        0.6336  0.1001\n",
      "     44        0.5368       0.7340        0.6332  0.0967\n",
      "     45        0.5455       0.7440        0.6321  0.0948\n",
      "     46        0.5377       0.7470        0.6288  0.0976\n",
      "     47        \u001b[36m0.5329\u001b[0m       0.7540        0.6230  0.1225\n",
      "     48        \u001b[36m0.5246\u001b[0m       0.7450        0.6268  0.1183\n",
      "     49        0.5255       0.7480        0.6295  0.0987\n",
      "     50        \u001b[36m0.5220\u001b[0m       0.7310        0.6296  0.0982\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8969\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.7082\u001b[0m  0.0903\n",
      "      2        \u001b[36m0.6908\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m0.6663\u001b[0m  0.0882\n",
      "      3        \u001b[36m0.6558\u001b[0m       \u001b[32m0.7200\u001b[0m        \u001b[35m0.6443\u001b[0m  0.0951\n",
      "      4        \u001b[36m0.6368\u001b[0m       0.7200        \u001b[35m0.6389\u001b[0m  0.0908\n",
      "      5        \u001b[36m0.6272\u001b[0m       \u001b[32m0.7220\u001b[0m        \u001b[35m0.6338\u001b[0m  0.0881\n",
      "      6        \u001b[36m0.6221\u001b[0m       \u001b[32m0.7260\u001b[0m        \u001b[35m0.6318\u001b[0m  0.0868\n",
      "      7        \u001b[36m0.6152\u001b[0m       \u001b[32m0.7270\u001b[0m        0.6329  0.0850\n",
      "      8        \u001b[36m0.6106\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.6314\u001b[0m  0.0851\n",
      "      9        \u001b[36m0.6057\u001b[0m       0.7300        0.6319  0.0877\n",
      "     10        \u001b[36m0.6025\u001b[0m       0.7240        0.6327  0.0897\n",
      "     11        \u001b[36m0.5980\u001b[0m       0.7290        0.6322  0.0911\n",
      "     12        \u001b[36m0.5966\u001b[0m       0.7260        \u001b[35m0.6280\u001b[0m  0.0875\n",
      "     13        \u001b[36m0.5925\u001b[0m       0.7270        0.6293  0.0921\n",
      "     14        \u001b[36m0.5920\u001b[0m       0.7240        0.6295  0.0934\n",
      "     15        \u001b[36m0.5897\u001b[0m       0.7220        \u001b[35m0.6235\u001b[0m  0.0897\n",
      "     16        \u001b[36m0.5872\u001b[0m       0.7240        0.6272  0.0878\n",
      "     17        \u001b[36m0.5849\u001b[0m       0.7210        0.6273  0.0904\n",
      "     18        \u001b[36m0.5838\u001b[0m       0.7230        0.6284  0.0901\n",
      "     19        \u001b[36m0.5809\u001b[0m       0.7250        0.6244  0.0902\n",
      "     20        \u001b[36m0.5793\u001b[0m       0.7240        0.6283  0.0923\n",
      "     21        \u001b[36m0.5782\u001b[0m       0.7260        0.6332  0.0911\n",
      "     22        \u001b[36m0.5749\u001b[0m       0.7220        0.6353  0.0955\n",
      "     23        \u001b[36m0.5719\u001b[0m       0.7260        0.6351  0.0921\n",
      "     24        \u001b[36m0.5700\u001b[0m       0.7260        0.6341  0.0900\n",
      "     25        \u001b[36m0.5697\u001b[0m       0.7260        0.6322  0.1073\n",
      "     26        \u001b[36m0.5663\u001b[0m       \u001b[32m0.7340\u001b[0m        0.6597  0.0997\n",
      "     27        0.5698       0.7280        0.6297  0.0955\n",
      "     28        \u001b[36m0.5630\u001b[0m       0.7270        0.6381  0.0911\n",
      "     29        \u001b[36m0.5605\u001b[0m       0.7270        0.6509  0.0873\n",
      "     30        \u001b[36m0.5592\u001b[0m       0.7240        0.6372  0.1084\n",
      "     31        \u001b[36m0.5586\u001b[0m       0.7150        0.6620  0.0908\n",
      "     32        \u001b[36m0.5547\u001b[0m       0.7300        0.6560  0.0899\n",
      "     33        \u001b[36m0.5527\u001b[0m       0.7230        0.6578  0.0903\n",
      "     34        \u001b[36m0.5525\u001b[0m       0.7300        0.6658  0.0870\n",
      "     35        \u001b[36m0.5490\u001b[0m       0.7260        0.6633  0.0870\n",
      "     36        \u001b[36m0.5471\u001b[0m       0.7240        0.6593  0.0911\n",
      "     37        0.5493       0.7280        0.6736  0.1060\n",
      "     38        \u001b[36m0.5456\u001b[0m       0.7270        0.6606  0.0991\n",
      "     39        \u001b[36m0.5430\u001b[0m       0.7160        0.6684  0.0857\n",
      "     40        \u001b[36m0.5419\u001b[0m       0.7280        0.6734  0.0896\n",
      "     41        \u001b[36m0.5386\u001b[0m       0.7300        0.6850  0.0872\n",
      "     42        0.5411       0.7220        0.6824  0.1030\n",
      "     43        \u001b[36m0.5370\u001b[0m       0.7210        0.6663  0.0968\n",
      "     44        \u001b[36m0.5344\u001b[0m       0.7190        0.6824  0.0907\n",
      "     45        \u001b[36m0.5326\u001b[0m       0.7240        0.6876  0.0909\n",
      "     46        \u001b[36m0.5326\u001b[0m       0.7100        0.6851  0.1000\n",
      "     47        \u001b[36m0.5287\u001b[0m       0.7130        0.6951  0.0894\n",
      "     48        \u001b[36m0.5286\u001b[0m       0.7130        0.6914  0.0901\n",
      "     49        \u001b[36m0.5284\u001b[0m       0.7050        0.6996  0.0930\n",
      "     50        0.5296       0.7110        0.6897  0.0866\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8414\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.0561\u001b[0m  0.0901\n",
      "      2        \u001b[36m0.7024\u001b[0m       \u001b[32m0.5480\u001b[0m        \u001b[35m0.8346\u001b[0m  0.0955\n",
      "      3        \u001b[36m0.6680\u001b[0m       \u001b[32m0.5730\u001b[0m        \u001b[35m0.8107\u001b[0m  0.0931\n",
      "      4        \u001b[36m0.6470\u001b[0m       \u001b[32m0.6150\u001b[0m        \u001b[35m0.7812\u001b[0m  0.0874\n",
      "      5        \u001b[36m0.6332\u001b[0m       \u001b[32m0.6330\u001b[0m        \u001b[35m0.7667\u001b[0m  0.0911\n",
      "      6        \u001b[36m0.6257\u001b[0m       \u001b[32m0.6460\u001b[0m        \u001b[35m0.7604\u001b[0m  0.1026\n",
      "      7        \u001b[36m0.6213\u001b[0m       0.6440        0.7673  0.0979\n",
      "      8        \u001b[36m0.6182\u001b[0m       \u001b[32m0.6520\u001b[0m        \u001b[35m0.7554\u001b[0m  0.0914\n",
      "      9        \u001b[36m0.6147\u001b[0m       \u001b[32m0.6560\u001b[0m        \u001b[35m0.7516\u001b[0m  0.0893\n",
      "     10        \u001b[36m0.6127\u001b[0m       \u001b[32m0.6690\u001b[0m        \u001b[35m0.7400\u001b[0m  0.0996\n",
      "     11        \u001b[36m0.6097\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.7375\u001b[0m  0.0931\n",
      "     12        \u001b[36m0.6076\u001b[0m       0.6640        0.7432  0.0883\n",
      "     13        \u001b[36m0.6068\u001b[0m       0.6740        \u001b[35m0.7296\u001b[0m  0.0876\n",
      "     14        \u001b[36m0.6050\u001b[0m       0.6640        0.7373  0.0932\n",
      "     15        \u001b[36m0.6043\u001b[0m       0.6690        \u001b[35m0.7282\u001b[0m  0.0919\n",
      "     16        \u001b[36m0.6028\u001b[0m       0.6720        0.7288  0.1009\n",
      "     17        \u001b[36m0.6020\u001b[0m       0.6730        0.7295  0.0906\n",
      "     18        \u001b[36m0.6017\u001b[0m       \u001b[32m0.6760\u001b[0m        \u001b[35m0.7264\u001b[0m  0.0882\n",
      "     19        \u001b[36m0.6000\u001b[0m       0.6730        \u001b[35m0.7253\u001b[0m  0.0867\n",
      "     20        \u001b[36m0.5981\u001b[0m       0.6650        0.7358  0.0903\n",
      "     21        \u001b[36m0.5977\u001b[0m       \u001b[32m0.6870\u001b[0m        \u001b[35m0.7134\u001b[0m  0.0888\n",
      "     22        \u001b[36m0.5959\u001b[0m       \u001b[32m0.6880\u001b[0m        \u001b[35m0.7105\u001b[0m  0.0932\n",
      "     23        \u001b[36m0.5944\u001b[0m       0.6810        0.7168  0.1199\n",
      "     24        \u001b[36m0.5938\u001b[0m       0.6730        0.7224  0.0897\n",
      "     25        \u001b[36m0.5936\u001b[0m       \u001b[32m0.6930\u001b[0m        \u001b[35m0.7098\u001b[0m  0.0930\n",
      "     26        \u001b[36m0.5926\u001b[0m       0.6890        \u001b[35m0.7074\u001b[0m  0.0968\n",
      "     27        \u001b[36m0.5909\u001b[0m       0.6850        0.7098  0.1133\n",
      "     28        \u001b[36m0.5901\u001b[0m       0.6810        0.7096  0.1189\n",
      "     29        \u001b[36m0.5900\u001b[0m       0.6810        0.7097  0.1156\n",
      "     30        \u001b[36m0.5894\u001b[0m       0.6930        \u001b[35m0.7020\u001b[0m  0.1011\n",
      "     31        0.5900       0.6860        0.7052  0.0947\n",
      "     32        \u001b[36m0.5873\u001b[0m       0.6860        0.7131  0.0977\n",
      "     33        0.5881       \u001b[32m0.7010\u001b[0m        \u001b[35m0.7001\u001b[0m  0.0887\n",
      "     34        \u001b[36m0.5867\u001b[0m       \u001b[32m0.7060\u001b[0m        \u001b[35m0.6992\u001b[0m  0.0889\n",
      "     35        \u001b[36m0.5860\u001b[0m       0.7000        \u001b[35m0.6968\u001b[0m  0.0853\n",
      "     36        0.5861       0.7030        0.6977  0.0870\n",
      "     37        \u001b[36m0.5851\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6905\u001b[0m  0.0989\n",
      "     38        \u001b[36m0.5833\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.6852\u001b[0m  0.0931\n",
      "     39        \u001b[36m0.5833\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.6777\u001b[0m  0.0885\n",
      "     40        \u001b[36m0.5822\u001b[0m       0.7250        0.6807  0.0896\n",
      "     41        \u001b[36m0.5811\u001b[0m       0.7230        0.6815  0.0902\n",
      "     42        \u001b[36m0.5807\u001b[0m       0.7220        0.6842  0.0906\n",
      "     43        \u001b[36m0.5798\u001b[0m       0.7250        0.6811  0.0891\n",
      "     44        \u001b[36m0.5795\u001b[0m       0.7240        0.6780  0.0888\n",
      "     45        0.5798       0.7250        0.6810  0.0932\n",
      "     46        \u001b[36m0.5775\u001b[0m       0.7290        \u001b[35m0.6736\u001b[0m  0.0922\n",
      "     47        0.5780       \u001b[32m0.7370\u001b[0m        0.6740  0.0887\n",
      "     48        \u001b[36m0.5752\u001b[0m       0.7250        0.6923  0.0892\n",
      "     49        0.5755       0.7240        0.6867  0.0866\n",
      "     50        \u001b[36m0.5745\u001b[0m       0.7240        0.6797  0.0863\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8357\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.7323\u001b[0m  0.0974\n",
      "      2        \u001b[36m0.6986\u001b[0m       \u001b[32m0.6870\u001b[0m        \u001b[35m0.6811\u001b[0m  0.0996\n",
      "      3        \u001b[36m0.6633\u001b[0m       0.6860        \u001b[35m0.6673\u001b[0m  0.0958\n",
      "      4        \u001b[36m0.6432\u001b[0m       \u001b[32m0.6910\u001b[0m        \u001b[35m0.6662\u001b[0m  0.0966\n",
      "      5        \u001b[36m0.6326\u001b[0m       \u001b[32m0.6960\u001b[0m        \u001b[35m0.6612\u001b[0m  0.1052\n",
      "      6        \u001b[36m0.6256\u001b[0m       \u001b[32m0.6970\u001b[0m        0.6640  0.1061\n",
      "      7        \u001b[36m0.6205\u001b[0m       \u001b[32m0.6990\u001b[0m        \u001b[35m0.6570\u001b[0m  0.1448\n",
      "      8        \u001b[36m0.6176\u001b[0m       0.6980        0.6628  0.0987\n",
      "      9        \u001b[36m0.6161\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.6566\u001b[0m  0.1013\n",
      "     10        \u001b[36m0.6136\u001b[0m       0.7000        \u001b[35m0.6553\u001b[0m  0.0944\n",
      "     11        \u001b[36m0.6102\u001b[0m       0.6950        0.6700  0.0959\n",
      "     12        0.6113       0.6980        0.6598  0.1017\n",
      "     13        \u001b[36m0.6065\u001b[0m       0.6930        \u001b[35m0.6508\u001b[0m  0.1148\n",
      "     14        \u001b[36m0.6034\u001b[0m       0.6980        0.6580  0.1044\n",
      "     15        \u001b[36m0.6031\u001b[0m       0.6960        0.6614  0.1029\n",
      "     16        \u001b[36m0.6014\u001b[0m       0.7000        0.6618  0.1040\n",
      "     17        \u001b[36m0.5981\u001b[0m       0.6940        0.6541  0.1038\n",
      "     18        \u001b[36m0.5939\u001b[0m       0.6860        0.6622  0.1057\n",
      "     19        \u001b[36m0.5932\u001b[0m       0.6830        0.6586  0.1060\n",
      "     20        \u001b[36m0.5900\u001b[0m       0.6920        0.6702  0.1059\n",
      "     21        0.5920       0.6940        0.6746  0.1057\n",
      "     22        \u001b[36m0.5875\u001b[0m       0.6990        0.6800  0.1043\n",
      "     23        \u001b[36m0.5847\u001b[0m       0.7010        0.6946  0.1073\n",
      "     24        0.5868       0.6970        0.6792  0.1006\n",
      "     25        \u001b[36m0.5827\u001b[0m       0.6980        0.6692  0.1075\n",
      "     26        \u001b[36m0.5811\u001b[0m       \u001b[32m0.7060\u001b[0m        0.6652  0.1057\n",
      "     27        \u001b[36m0.5779\u001b[0m       0.7040        0.6754  0.1058\n",
      "     28        \u001b[36m0.5747\u001b[0m       0.7020        0.6763  0.1109\n",
      "     29        \u001b[36m0.5742\u001b[0m       0.7030        0.6730  0.1062\n",
      "     30        \u001b[36m0.5741\u001b[0m       0.7030        0.6763  0.1079\n",
      "     31        \u001b[36m0.5703\u001b[0m       0.7030        0.6758  0.1072\n",
      "     32        \u001b[36m0.5691\u001b[0m       0.7060        0.6833  0.0982\n",
      "     33        \u001b[36m0.5680\u001b[0m       0.7030        0.6801  0.1006\n",
      "     34        \u001b[36m0.5642\u001b[0m       \u001b[32m0.7080\u001b[0m        0.6788  0.1024\n",
      "     35        0.5642       0.7070        0.6879  0.1023\n",
      "     36        \u001b[36m0.5587\u001b[0m       0.7050        0.6837  0.1047\n",
      "     37        \u001b[36m0.5558\u001b[0m       \u001b[32m0.7180\u001b[0m        0.6833  0.1063\n",
      "     38        0.5572       0.7110        0.6972  0.1099\n",
      "     39        \u001b[36m0.5536\u001b[0m       0.7110        0.6983  0.1086\n",
      "     40        \u001b[36m0.5513\u001b[0m       0.7140        0.6977  0.1057\n",
      "     41        0.5525       0.7140        0.6785  0.1027\n",
      "     42        \u001b[36m0.5495\u001b[0m       0.7040        0.6853  0.1032\n",
      "     43        \u001b[36m0.5485\u001b[0m       0.7130        0.6791  0.1197\n",
      "     44        \u001b[36m0.5459\u001b[0m       0.7140        0.6877  0.1009\n",
      "     45        \u001b[36m0.5449\u001b[0m       0.7090        0.7020  0.1007\n",
      "     46        \u001b[36m0.5410\u001b[0m       0.7090        0.7094  0.1008\n",
      "     47        \u001b[36m0.5403\u001b[0m       0.7120        0.7150  0.1073\n",
      "     48        \u001b[36m0.5395\u001b[0m       0.7130        0.7203  0.1004\n",
      "     49        \u001b[36m0.5374\u001b[0m       0.7050        0.7110  0.1031\n",
      "     50        \u001b[36m0.5369\u001b[0m       0.7100        0.7445  0.1056\n",
      "     51        0.5390       0.7110        0.7362  0.1028\n",
      "     52        0.5438       0.7070        0.7182  0.1013\n",
      "     53        0.5426       \u001b[32m0.7240\u001b[0m        0.7396  0.1012\n",
      "     54        0.5405       0.7150        0.7290  0.1044\n",
      "     55        \u001b[36m0.5362\u001b[0m       0.7180        0.7539  0.1032\n",
      "     56        0.5384       0.7050        0.7407  0.1022\n",
      "     57        \u001b[36m0.5361\u001b[0m       0.7170        0.7489  0.0917\n",
      "     58        \u001b[36m0.5328\u001b[0m       0.7010        0.7389  0.1000\n",
      "     59        \u001b[36m0.5312\u001b[0m       0.6970        0.7707  0.1014\n",
      "     60        \u001b[36m0.5275\u001b[0m       0.6960        0.7550  0.1021\n",
      "     61        0.5291       0.7040        0.7957  0.1035\n",
      "     62        0.5292       0.7000        0.7926  0.1010\n",
      "     63        0.5299       0.7030        0.8152  0.1001\n",
      "     64        \u001b[36m0.5249\u001b[0m       0.7070        0.8201  0.1086\n",
      "     65        \u001b[36m0.5183\u001b[0m       0.7000        0.8062  0.1061\n",
      "     66        0.5229       0.6990        0.8294  0.1006\n",
      "     67        0.5246       0.7060        0.8183  0.1012\n",
      "     68        0.5210       0.6920        0.8329  0.0987\n",
      "     69        0.5241       0.7000        0.7842  0.1018\n",
      "     70        \u001b[36m0.5181\u001b[0m       0.7050        0.8360  0.0956\n",
      "     71        0.5218       0.7020        0.8301  0.1072\n",
      "     72        0.5292       0.6970        0.8229  0.1006\n",
      "     73        0.5318       0.7010        0.7667  0.1028\n",
      "     74        0.5214       0.6980        0.8135  0.1017\n",
      "     75        \u001b[36m0.5171\u001b[0m       0.7010        0.8242  0.1148\n",
      "     76        0.5192       0.6990        0.8522  0.1064\n",
      "     77        \u001b[36m0.5131\u001b[0m       0.7050        0.8635  0.0965\n",
      "     78        0.5153       0.6970        0.8683  0.1043\n",
      "     79        \u001b[36m0.5104\u001b[0m       0.7000        0.8430  0.1049\n",
      "     80        \u001b[36m0.5069\u001b[0m       0.7030        0.8649  0.1147\n",
      "     81        \u001b[36m0.5068\u001b[0m       0.6960        0.8715  0.1202\n",
      "     82        0.5098       0.7020        0.8702  0.1041\n",
      "     83        \u001b[36m0.5060\u001b[0m       0.7030        0.8709  0.1051\n",
      "     84        \u001b[36m0.5041\u001b[0m       0.6930        0.8726  0.1037\n",
      "     85        \u001b[36m0.4970\u001b[0m       0.6890        0.8869  0.1006\n",
      "     86        0.5000       0.6930        0.8777  0.1012\n",
      "     87        0.5059       0.7010        0.8978  0.1056\n",
      "     88        0.5145       0.6990        0.8607  0.1026\n",
      "     89        0.5155       0.7100        0.8853  0.1006\n",
      "     90        0.5105       0.6910        0.8688  0.1035\n",
      "     91        0.5141       0.6880        0.8747  0.1026\n",
      "     92        0.5072       0.7040        0.8464  0.1040\n",
      "     93        0.5069       0.6940        0.8955  0.1037\n",
      "     94        0.5129       0.6960        0.8512  0.1058\n",
      "     95        0.5125       0.6940        0.8555  0.1052\n",
      "     96        0.5165       0.6860        0.9045  0.1113\n",
      "     97        0.5120       0.6830        0.8781  0.1039\n",
      "     98        0.5179       0.6910        0.8074  0.1006\n",
      "     99        0.5114       0.6950        0.8500  0.1011\n",
      "    100        0.5087       0.6950        0.8512  0.1013\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8101\u001b[0m       \u001b[32m0.5780\u001b[0m        \u001b[35m0.8177\u001b[0m  0.0966\n",
      "      2        \u001b[36m0.7140\u001b[0m       \u001b[32m0.6770\u001b[0m        \u001b[35m0.7101\u001b[0m  0.0941\n",
      "      3        \u001b[36m0.6699\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.6646\u001b[0m  0.0992\n",
      "      4        \u001b[36m0.6466\u001b[0m       \u001b[32m0.7400\u001b[0m        \u001b[35m0.6487\u001b[0m  0.0968\n",
      "      5        \u001b[36m0.6339\u001b[0m       \u001b[32m0.7450\u001b[0m        \u001b[35m0.6307\u001b[0m  0.0981\n",
      "      6        \u001b[36m0.6275\u001b[0m       0.7400        0.6327  0.0962\n",
      "      7        \u001b[36m0.6191\u001b[0m       \u001b[32m0.7530\u001b[0m        \u001b[35m0.6179\u001b[0m  0.0972\n",
      "      8        \u001b[36m0.6130\u001b[0m       \u001b[32m0.7580\u001b[0m        0.6194  0.1054\n",
      "      9        \u001b[36m0.6078\u001b[0m       0.7560        \u001b[35m0.6157\u001b[0m  0.1032\n",
      "     10        \u001b[36m0.6037\u001b[0m       0.7560        \u001b[35m0.6090\u001b[0m  0.0980\n",
      "     11        \u001b[36m0.6023\u001b[0m       0.7550        0.6110  0.1022\n",
      "     12        \u001b[36m0.5991\u001b[0m       \u001b[32m0.7610\u001b[0m        0.6114  0.1053\n",
      "     13        \u001b[36m0.5990\u001b[0m       0.7590        \u001b[35m0.6082\u001b[0m  0.1006\n",
      "     14        \u001b[36m0.5956\u001b[0m       \u001b[32m0.7690\u001b[0m        0.6096  0.1013\n",
      "     15        \u001b[36m0.5935\u001b[0m       0.7660        0.6092  0.1048\n",
      "     16        \u001b[36m0.5920\u001b[0m       0.7620        0.6109  0.1026\n",
      "     17        0.5921       0.7570        0.6106  0.1077\n",
      "     18        \u001b[36m0.5897\u001b[0m       0.7640        0.6092  0.1028\n",
      "     19        \u001b[36m0.5875\u001b[0m       0.7580        0.6112  0.1077\n",
      "     20        0.5884       0.7530        \u001b[35m0.6081\u001b[0m  0.1213\n",
      "     21        \u001b[36m0.5865\u001b[0m       0.7480        0.6116  0.0968\n",
      "     22        \u001b[36m0.5825\u001b[0m       0.7450        0.6214  0.1132\n",
      "     23        0.5840       0.7460        0.6166  0.1210\n",
      "     24        \u001b[36m0.5811\u001b[0m       0.7430        0.6250  0.1081\n",
      "     25        \u001b[36m0.5803\u001b[0m       0.7460        0.6099  0.1011\n",
      "     26        \u001b[36m0.5747\u001b[0m       0.7390        0.6205  0.1060\n",
      "     27        \u001b[36m0.5743\u001b[0m       0.7410        0.6173  0.1067\n",
      "     28        \u001b[36m0.5720\u001b[0m       0.7360        0.6177  0.1096\n",
      "     29        \u001b[36m0.5706\u001b[0m       0.7350        0.6264  0.1002\n",
      "     30        \u001b[36m0.5673\u001b[0m       0.7350        0.6360  0.1083\n",
      "     31        \u001b[36m0.5662\u001b[0m       0.7330        0.6262  0.1041\n",
      "     32        \u001b[36m0.5646\u001b[0m       0.7350        0.6220  0.1020\n",
      "     33        \u001b[36m0.5628\u001b[0m       0.7440        \u001b[35m0.6070\u001b[0m  0.1032\n",
      "     34        \u001b[36m0.5599\u001b[0m       0.7410        0.6186  0.1047\n",
      "     35        \u001b[36m0.5586\u001b[0m       0.7400        0.6264  0.1132\n",
      "     36        0.5597       0.7520        0.6194  0.1094\n",
      "     37        \u001b[36m0.5572\u001b[0m       0.7610        0.6169  0.1034\n",
      "     38        \u001b[36m0.5555\u001b[0m       0.7500        0.6303  0.1292\n",
      "     39        0.5573       0.7530        0.6413  0.1060\n",
      "     40        \u001b[36m0.5549\u001b[0m       0.7440        0.6465  0.1131\n",
      "     41        0.5564       0.7430        0.6548  0.1097\n",
      "     42        \u001b[36m0.5527\u001b[0m       0.7520        0.6292  0.1045\n",
      "     43        0.5550       0.7500        0.6236  0.1144\n",
      "     44        \u001b[36m0.5438\u001b[0m       0.7520        0.6228  0.1207\n",
      "     45        \u001b[36m0.5432\u001b[0m       0.7500        0.6229  0.1122\n",
      "     46        \u001b[36m0.5398\u001b[0m       0.7430        0.6340  0.1101\n",
      "     47        0.5404       0.7540        0.6178  0.1098\n",
      "     48        0.5398       0.7550        0.6264  0.1033\n",
      "     49        \u001b[36m0.5383\u001b[0m       0.7570        0.6194  0.1150\n",
      "     50        \u001b[36m0.5380\u001b[0m       0.7540        0.6274  0.1027\n",
      "     51        \u001b[36m0.5302\u001b[0m       0.7590        0.6251  0.1029\n",
      "     52        0.5318       0.7640        0.6264  0.1022\n",
      "     53        \u001b[36m0.5296\u001b[0m       0.7650        0.6279  0.0990\n",
      "     54        0.5326       0.7540        0.6392  0.1016\n",
      "     55        \u001b[36m0.5284\u001b[0m       0.7560        0.6325  0.0982\n",
      "     56        0.5312       0.7550        0.6240  0.1017\n",
      "     57        \u001b[36m0.5261\u001b[0m       0.7480        0.6351  0.1003\n",
      "     58        \u001b[36m0.5260\u001b[0m       0.7570        0.6305  0.1026\n",
      "     59        \u001b[36m0.5195\u001b[0m       0.7470        0.6486  0.1095\n",
      "     60        \u001b[36m0.5177\u001b[0m       0.7470        0.6411  0.1052\n",
      "     61        0.5207       0.7460        0.6501  0.1138\n",
      "     62        \u001b[36m0.5152\u001b[0m       0.7670        0.6486  0.1136\n",
      "     63        \u001b[36m0.5129\u001b[0m       0.7550        0.6459  0.1117\n",
      "     64        0.5240       0.7430        0.6449  0.1111\n",
      "     65        0.5241       0.7420        0.6485  0.1189\n",
      "     66        0.5142       0.7440        0.6425  0.1062\n",
      "     67        \u001b[36m0.5108\u001b[0m       0.7410        0.6494  0.1069\n",
      "     68        0.5187       0.7370        0.6472  0.1111\n",
      "     69        0.5113       0.7500        0.6465  0.1312\n",
      "     70        0.5115       0.7430        0.6603  0.1015\n",
      "     71        0.5140       0.7440        0.6396  0.1040\n",
      "     72        \u001b[36m0.5102\u001b[0m       0.7380        0.6521  0.1244\n",
      "     73        \u001b[36m0.5099\u001b[0m       0.7450        0.6434  0.1038\n",
      "     74        0.5112       0.7370        0.6490  0.1081\n",
      "     75        0.5264       0.7560        0.6329  0.1081\n",
      "     76        0.5161       0.7520        0.6328  0.1067\n",
      "     77        \u001b[36m0.5073\u001b[0m       0.7390        0.6458  0.1080\n",
      "     78        0.5106       0.7490        0.6450  0.1071\n",
      "     79        \u001b[36m0.5050\u001b[0m       0.7520        0.6395  0.1049\n",
      "     80        \u001b[36m0.5024\u001b[0m       0.7490        0.6554  0.1107\n",
      "     81        \u001b[36m0.5001\u001b[0m       0.7420        0.6582  0.1151\n",
      "     82        \u001b[36m0.4954\u001b[0m       0.7510        0.6593  0.1153\n",
      "     83        0.4973       0.7400        0.6610  0.1061\n",
      "     84        0.4997       0.7460        0.6784  0.1360\n",
      "     85        0.4977       0.7460        0.6588  0.1016\n",
      "     86        \u001b[36m0.4929\u001b[0m       0.7460        0.6759  0.1069\n",
      "     87        0.4943       0.7470        0.6882  0.1081\n",
      "     88        \u001b[36m0.4863\u001b[0m       0.7460        0.6932  0.1037\n",
      "     89        \u001b[36m0.4826\u001b[0m       0.7500        0.6998  0.1191\n",
      "     90        \u001b[36m0.4791\u001b[0m       0.7460        0.6965  0.1003\n",
      "     91        0.4860       0.7420        0.6893  0.1092\n",
      "     92        0.4825       0.7440        0.6723  0.1022\n",
      "     93        0.4818       0.7410        0.6852  0.1022\n",
      "     94        \u001b[36m0.4759\u001b[0m       0.7500        0.6962  0.0973\n",
      "     95        \u001b[36m0.4711\u001b[0m       0.7420        0.6895  0.0996\n",
      "     96        \u001b[36m0.4654\u001b[0m       0.7450        0.7012  0.0976\n",
      "     97        0.4669       0.7400        0.7149  0.1034\n",
      "     98        0.4788       0.7480        0.7067  0.1052\n",
      "     99        0.4796       0.7440        0.7093  0.1018\n",
      "    100        0.4746       0.7420        0.7322  0.1042\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8929\u001b[0m       \u001b[32m0.6740\u001b[0m        \u001b[35m0.7319\u001b[0m  0.0848\n",
      "      2        \u001b[36m0.7085\u001b[0m       \u001b[32m0.7060\u001b[0m        \u001b[35m0.6883\u001b[0m  0.0912\n",
      "      3        \u001b[36m0.6697\u001b[0m       \u001b[32m0.7110\u001b[0m        \u001b[35m0.6719\u001b[0m  0.0880\n",
      "      4        \u001b[36m0.6470\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m0.6499\u001b[0m  0.0887\n",
      "      5        \u001b[36m0.6330\u001b[0m       \u001b[32m0.7230\u001b[0m        \u001b[35m0.6459\u001b[0m  0.0906\n",
      "      6        \u001b[36m0.6239\u001b[0m       \u001b[32m0.7280\u001b[0m        \u001b[35m0.6415\u001b[0m  0.0966\n",
      "      7        \u001b[36m0.6186\u001b[0m       \u001b[32m0.7310\u001b[0m        \u001b[35m0.6391\u001b[0m  0.0872\n",
      "      8        \u001b[36m0.6131\u001b[0m       \u001b[32m0.7330\u001b[0m        \u001b[35m0.6379\u001b[0m  0.0891\n",
      "      9        \u001b[36m0.6098\u001b[0m       0.7260        \u001b[35m0.6365\u001b[0m  0.0857\n",
      "     10        \u001b[36m0.6060\u001b[0m       0.7310        \u001b[35m0.6348\u001b[0m  0.0887\n",
      "     11        \u001b[36m0.6028\u001b[0m       0.7310        0.6355  0.0837\n",
      "     12        \u001b[36m0.5999\u001b[0m       0.7250        \u001b[35m0.6345\u001b[0m  0.0862\n",
      "     13        \u001b[36m0.5975\u001b[0m       0.7280        \u001b[35m0.6341\u001b[0m  0.0926\n",
      "     14        \u001b[36m0.5949\u001b[0m       0.7330        \u001b[35m0.6286\u001b[0m  0.0916\n",
      "     15        \u001b[36m0.5927\u001b[0m       0.7330        0.6289  0.0876\n",
      "     16        \u001b[36m0.5889\u001b[0m       0.7290        0.6331  0.1012\n",
      "     17        \u001b[36m0.5885\u001b[0m       0.7290        \u001b[35m0.6276\u001b[0m  0.0912\n",
      "     18        \u001b[36m0.5862\u001b[0m       0.7270        \u001b[35m0.6255\u001b[0m  0.0868\n",
      "     19        \u001b[36m0.5850\u001b[0m       0.7320        0.6300  0.0883\n",
      "     20        \u001b[36m0.5834\u001b[0m       \u001b[32m0.7340\u001b[0m        0.6283  0.0885\n",
      "     21        \u001b[36m0.5828\u001b[0m       0.7290        0.6326  0.0981\n",
      "     22        \u001b[36m0.5801\u001b[0m       0.7260        0.6355  0.0876\n",
      "     23        \u001b[36m0.5770\u001b[0m       0.7240        0.6326  0.0886\n",
      "     24        \u001b[36m0.5762\u001b[0m       0.7190        0.6336  0.0907\n",
      "     25        \u001b[36m0.5752\u001b[0m       \u001b[32m0.7420\u001b[0m        \u001b[35m0.6250\u001b[0m  0.0897\n",
      "     26        \u001b[36m0.5751\u001b[0m       0.7400        \u001b[35m0.6242\u001b[0m  0.0856\n",
      "     27        \u001b[36m0.5726\u001b[0m       0.7420        \u001b[35m0.6214\u001b[0m  0.0909\n",
      "     28        \u001b[36m0.5711\u001b[0m       0.7380        0.6234  0.0861\n",
      "     29        \u001b[36m0.5699\u001b[0m       0.7360        0.6325  0.0932\n",
      "     30        \u001b[36m0.5681\u001b[0m       0.7400        0.6280  0.0926\n",
      "     31        \u001b[36m0.5669\u001b[0m       0.7320        0.6325  0.0876\n",
      "     32        \u001b[36m0.5650\u001b[0m       0.7350        0.6376  0.0854\n",
      "     33        0.5654       0.7390        0.6344  0.0891\n",
      "     34        0.5654       0.7420        0.6334  0.0883\n",
      "     35        \u001b[36m0.5643\u001b[0m       0.7360        0.6469  0.0917\n",
      "     36        \u001b[36m0.5618\u001b[0m       0.7390        0.6487  0.0907\n",
      "     37        \u001b[36m0.5616\u001b[0m       0.7390        0.6450  0.0945\n",
      "     38        0.5620       0.7300        0.6551  0.0879\n",
      "     39        \u001b[36m0.5567\u001b[0m       0.7320        0.6530  0.0957\n",
      "     40        \u001b[36m0.5556\u001b[0m       0.7280        0.6558  0.0906\n",
      "     41        0.5587       0.7320        0.6556  0.0881\n",
      "     42        \u001b[36m0.5556\u001b[0m       0.7230        0.6700  0.0893\n",
      "     43        \u001b[36m0.5524\u001b[0m       0.7240        0.6605  0.0891\n",
      "     44        \u001b[36m0.5521\u001b[0m       0.7260        0.6564  0.0902\n",
      "     45        \u001b[36m0.5515\u001b[0m       0.7300        0.6640  0.0871\n",
      "     46        \u001b[36m0.5476\u001b[0m       0.7280        0.6657  0.0891\n",
      "     47        0.5492       0.7250        0.6655  0.0906\n",
      "     48        \u001b[36m0.5451\u001b[0m       0.7320        0.6719  0.0872\n",
      "     49        \u001b[36m0.5440\u001b[0m       0.7240        0.6654  0.0866\n",
      "     50        \u001b[36m0.5427\u001b[0m       0.7220        0.6629  0.0920\n",
      "     51        \u001b[36m0.5425\u001b[0m       0.7230        0.6672  0.0925\n",
      "     52        \u001b[36m0.5392\u001b[0m       0.7280        0.6755  0.1036\n",
      "     53        \u001b[36m0.5363\u001b[0m       0.7240        0.6727  0.0867\n",
      "     54        \u001b[36m0.5344\u001b[0m       0.7240        0.6609  0.0891\n",
      "     55        0.5356       0.7220        0.6800  0.0878\n",
      "     56        \u001b[36m0.5331\u001b[0m       0.7200        0.6695  0.0858\n",
      "     57        \u001b[36m0.5329\u001b[0m       0.7310        0.6737  0.0930\n",
      "     58        \u001b[36m0.5320\u001b[0m       0.7300        0.6746  0.1123\n",
      "     59        0.5326       0.7250        0.6785  0.0867\n",
      "     60        \u001b[36m0.5316\u001b[0m       0.7240        0.6706  0.0866\n",
      "     61        \u001b[36m0.5293\u001b[0m       0.7360        0.6726  0.0915\n",
      "     62        \u001b[36m0.5285\u001b[0m       0.7190        0.6808  0.0921\n",
      "     63        \u001b[36m0.5269\u001b[0m       0.7260        0.6732  0.0899\n",
      "     64        \u001b[36m0.5242\u001b[0m       0.7300        0.6678  0.0853\n",
      "     65        \u001b[36m0.5210\u001b[0m       0.7250        0.6745  0.0887\n",
      "     66        \u001b[36m0.5166\u001b[0m       0.7260        0.6871  0.0922\n",
      "     67        0.5191       0.7330        0.6803  0.0881\n",
      "     68        \u001b[36m0.5164\u001b[0m       0.7330        0.6758  0.0959\n",
      "     69        0.5191       0.7330        0.6848  0.0894\n",
      "     70        \u001b[36m0.5156\u001b[0m       0.7300        0.6870  0.0901\n",
      "     71        0.5198       0.7280        0.6761  0.0883\n",
      "     72        0.5161       0.7390        0.6864  0.0882\n",
      "     73        \u001b[36m0.5108\u001b[0m       0.7260        0.6894  0.0852\n",
      "     74        0.5124       0.7210        0.6940  0.0876\n",
      "     75        \u001b[36m0.5075\u001b[0m       0.7300        0.6916  0.0892\n",
      "     76        0.5109       0.7240        0.6807  0.0902\n",
      "     77        \u001b[36m0.5032\u001b[0m       0.7240        0.7168  0.0859\n",
      "     78        0.5083       0.7180        0.7194  0.0912\n",
      "     79        0.5084       0.7180        0.6971  0.1037\n",
      "     80        0.5080       0.7250        0.7052  0.0910\n",
      "     81        0.5052       0.7250        0.6964  0.0908\n",
      "     82        0.5057       0.7310        0.7061  0.0891\n",
      "     83        \u001b[36m0.5013\u001b[0m       0.7220        0.7205  0.0911\n",
      "     84        \u001b[36m0.5001\u001b[0m       0.7200        0.7322  0.0950\n",
      "     85        \u001b[36m0.4964\u001b[0m       0.7200        0.7357  0.0901\n",
      "     86        0.5000       0.7210        0.7222  0.0887\n",
      "     87        0.5001       0.7160        0.7518  0.0906\n",
      "     88        \u001b[36m0.4955\u001b[0m       0.7180        0.7720  0.0896\n",
      "     89        0.4995       0.7180        0.7866  0.0889\n",
      "     90        \u001b[36m0.4917\u001b[0m       0.7220        0.7866  0.0886\n",
      "     91        0.4930       0.7270        0.7577  0.1163\n",
      "     92        \u001b[36m0.4881\u001b[0m       0.7230        0.7667  0.0891\n",
      "     93        \u001b[36m0.4876\u001b[0m       0.7210        0.7614  0.0876\n",
      "     94        \u001b[36m0.4850\u001b[0m       0.7240        0.7762  0.0891\n",
      "     95        0.4862       0.7230        0.7784  0.0880\n",
      "     96        0.4894       0.7230        0.7468  0.0892\n",
      "     97        \u001b[36m0.4839\u001b[0m       0.7220        0.7902  0.0891\n",
      "     98        0.4842       0.7190        0.7810  0.0942\n",
      "     99        \u001b[36m0.4829\u001b[0m       0.7190        0.8060  0.0872\n",
      "    100        \u001b[36m0.4812\u001b[0m       0.7210        0.7782  0.0881\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8677\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.2738\u001b[0m  0.0848\n",
      "      2        \u001b[36m0.7138\u001b[0m       0.4900        \u001b[35m0.9375\u001b[0m  0.0839\n",
      "      3        \u001b[36m0.6723\u001b[0m       \u001b[32m0.5030\u001b[0m        \u001b[35m0.8808\u001b[0m  0.0871\n",
      "      4        \u001b[36m0.6504\u001b[0m       \u001b[32m0.5460\u001b[0m        \u001b[35m0.8620\u001b[0m  0.0887\n",
      "      5        \u001b[36m0.6399\u001b[0m       \u001b[32m0.5860\u001b[0m        \u001b[35m0.8302\u001b[0m  0.0856\n",
      "      6        \u001b[36m0.6329\u001b[0m       0.5760        0.8358  0.0901\n",
      "      7        \u001b[36m0.6288\u001b[0m       \u001b[32m0.5910\u001b[0m        \u001b[35m0.8104\u001b[0m  0.0871\n",
      "      8        \u001b[36m0.6233\u001b[0m       \u001b[32m0.6320\u001b[0m        \u001b[35m0.7767\u001b[0m  0.0866\n",
      "      9        \u001b[36m0.6183\u001b[0m       \u001b[32m0.6470\u001b[0m        \u001b[35m0.7630\u001b[0m  0.0851\n",
      "     10        \u001b[36m0.6154\u001b[0m       0.6460        \u001b[35m0.7620\u001b[0m  0.0886\n",
      "     11        \u001b[36m0.6118\u001b[0m       \u001b[32m0.6630\u001b[0m        \u001b[35m0.7505\u001b[0m  0.0856\n",
      "     12        \u001b[36m0.6078\u001b[0m       \u001b[32m0.6660\u001b[0m        \u001b[35m0.7496\u001b[0m  0.0864\n",
      "     13        \u001b[36m0.6052\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.7409\u001b[0m  0.0891\n",
      "     14        \u001b[36m0.6043\u001b[0m       \u001b[32m0.6740\u001b[0m        \u001b[35m0.7299\u001b[0m  0.0876\n",
      "     15        \u001b[36m0.6011\u001b[0m       \u001b[32m0.6780\u001b[0m        \u001b[35m0.7265\u001b[0m  0.0851\n",
      "     16        \u001b[36m0.6001\u001b[0m       0.6750        0.7275  0.0854\n",
      "     17        \u001b[36m0.5990\u001b[0m       0.6760        \u001b[35m0.7209\u001b[0m  0.0911\n",
      "     18        \u001b[36m0.5982\u001b[0m       0.6740        0.7243  0.0880\n",
      "     19        \u001b[36m0.5960\u001b[0m       0.6730        0.7245  0.0891\n",
      "     20        \u001b[36m0.5956\u001b[0m       0.6770        \u001b[35m0.7164\u001b[0m  0.0901\n",
      "     21        \u001b[36m0.5943\u001b[0m       \u001b[32m0.6790\u001b[0m        0.7170  0.0896\n",
      "     22        0.5949       \u001b[32m0.6800\u001b[0m        \u001b[35m0.7120\u001b[0m  0.0892\n",
      "     23        \u001b[36m0.5923\u001b[0m       0.6800        0.7124  0.0907\n",
      "     24        \u001b[36m0.5914\u001b[0m       \u001b[32m0.6830\u001b[0m        0.7146  0.0885\n",
      "     25        \u001b[36m0.5907\u001b[0m       0.6810        0.7149  0.0883\n",
      "     26        \u001b[36m0.5897\u001b[0m       0.6830        0.7150  0.0886\n",
      "     27        \u001b[36m0.5888\u001b[0m       0.6820        0.7166  0.0967\n",
      "     28        \u001b[36m0.5886\u001b[0m       \u001b[32m0.6850\u001b[0m        0.7124  0.0909\n",
      "     29        \u001b[36m0.5879\u001b[0m       \u001b[32m0.6920\u001b[0m        \u001b[35m0.7080\u001b[0m  0.0893\n",
      "     30        \u001b[36m0.5863\u001b[0m       0.6830        0.7128  0.0893\n",
      "     31        \u001b[36m0.5860\u001b[0m       0.6910        \u001b[35m0.7066\u001b[0m  0.1073\n",
      "     32        \u001b[36m0.5853\u001b[0m       0.6830        0.7075  0.0896\n",
      "     33        \u001b[36m0.5844\u001b[0m       0.6910        \u001b[35m0.7053\u001b[0m  0.0881\n",
      "     34        \u001b[36m0.5837\u001b[0m       \u001b[32m0.6950\u001b[0m        0.7056  0.0907\n",
      "     35        \u001b[36m0.5821\u001b[0m       0.6840        0.7203  0.0859\n",
      "     36        \u001b[36m0.5817\u001b[0m       0.6890        \u001b[35m0.7039\u001b[0m  0.0891\n",
      "     37        \u001b[36m0.5814\u001b[0m       0.6880        0.7154  0.0844\n",
      "     38        \u001b[36m0.5797\u001b[0m       0.6870        0.7146  0.0861\n",
      "     39        0.5804       \u001b[32m0.6960\u001b[0m        0.7084  0.0882\n",
      "     40        \u001b[36m0.5779\u001b[0m       \u001b[32m0.6990\u001b[0m        \u001b[35m0.7024\u001b[0m  0.0886\n",
      "     41        0.5788       0.6890        0.7134  0.0981\n",
      "     42        0.5781       \u001b[32m0.7070\u001b[0m        0.7076  0.0887\n",
      "     43        \u001b[36m0.5773\u001b[0m       0.6920        0.7189  0.0916\n",
      "     44        \u001b[36m0.5758\u001b[0m       0.7070        0.7077  0.0891\n",
      "     45        0.5759       0.7010        0.7115  0.0906\n",
      "     46        \u001b[36m0.5745\u001b[0m       0.6970        0.7132  0.0907\n",
      "     47        \u001b[36m0.5741\u001b[0m       0.7040        0.7101  0.0876\n",
      "     48        \u001b[36m0.5738\u001b[0m       0.6990        0.7080  0.0879\n",
      "     49        0.5741       0.7000        0.7104  0.0936\n",
      "     50        \u001b[36m0.5730\u001b[0m       0.7040        0.7072  0.1023\n",
      "     51        \u001b[36m0.5722\u001b[0m       0.6970        0.7157  0.0942\n",
      "     52        \u001b[36m0.5722\u001b[0m       \u001b[32m0.7110\u001b[0m        0.7050  0.0918\n",
      "     53        0.5732       0.7100        0.7041  0.0891\n",
      "     54        \u001b[36m0.5706\u001b[0m       0.7010        0.7103  0.0867\n",
      "     55        \u001b[36m0.5698\u001b[0m       0.7100        \u001b[35m0.7007\u001b[0m  0.0917\n",
      "     56        \u001b[36m0.5692\u001b[0m       0.7020        0.7085  0.0835\n",
      "     57        0.5692       0.7030        0.7088  0.0878\n",
      "     58        \u001b[36m0.5673\u001b[0m       0.7070        0.7022  0.0891\n",
      "     59        0.5701       0.7050        \u001b[35m0.7007\u001b[0m  0.0856\n",
      "     60        0.5678       0.7090        0.7032  0.0871\n",
      "     61        0.5674       0.7060        0.7043  0.0851\n",
      "     62        \u001b[36m0.5672\u001b[0m       0.7040        0.7068  0.0888\n",
      "     63        \u001b[36m0.5667\u001b[0m       0.7110        0.7045  0.0876\n",
      "     64        \u001b[36m0.5660\u001b[0m       0.7040        0.7062  0.0876\n",
      "     65        0.5666       0.7040        0.7064  0.1067\n",
      "     66        \u001b[36m0.5632\u001b[0m       0.7030        0.7055  0.0856\n",
      "     67        0.5639       0.7100        \u001b[35m0.6956\u001b[0m  0.0866\n",
      "     68        \u001b[36m0.5632\u001b[0m       0.7090        0.6990  0.0887\n",
      "     69        0.5639       \u001b[32m0.7130\u001b[0m        0.7056  0.0861\n",
      "     70        \u001b[36m0.5615\u001b[0m       0.7090        0.7094  0.0942\n",
      "     71        \u001b[36m0.5597\u001b[0m       0.7030        0.7138  0.0868\n",
      "     72        0.5602       0.7110        0.7115  0.0877\n",
      "     73        0.5602       0.7090        0.7055  0.0866\n",
      "     74        \u001b[36m0.5584\u001b[0m       0.7130        0.7070  0.0861\n",
      "     75        0.5596       \u001b[32m0.7160\u001b[0m        0.7029  0.0897\n",
      "     76        \u001b[36m0.5575\u001b[0m       0.7100        0.7157  0.0861\n",
      "     77        0.5575       0.7120        0.7030  0.0855\n",
      "     78        0.5585       \u001b[32m0.7210\u001b[0m        0.7038  0.0882\n",
      "     79        0.5584       0.7110        0.7081  0.0822\n",
      "     80        \u001b[36m0.5573\u001b[0m       0.7190        0.6969  0.0936\n",
      "     81        \u001b[36m0.5557\u001b[0m       0.7150        0.7142  0.0908\n",
      "     82        0.5584       \u001b[32m0.7240\u001b[0m        0.7007  0.0899\n",
      "     83        0.5569       0.7150        0.7066  0.0896\n",
      "     84        \u001b[36m0.5553\u001b[0m       0.7040        0.7153  0.0947\n",
      "     85        0.5568       \u001b[32m0.7250\u001b[0m        \u001b[35m0.6947\u001b[0m  0.0863\n",
      "     86        0.5569       \u001b[32m0.7270\u001b[0m        0.7002  0.0901\n",
      "     87        0.5571       0.7210        0.7046  0.0925\n",
      "     88        \u001b[36m0.5543\u001b[0m       0.7200        0.7103  0.0911\n",
      "     89        \u001b[36m0.5539\u001b[0m       0.7220        0.7047  0.0901\n",
      "     90        0.5547       0.7220        0.7013  0.0922\n",
      "     91        0.5545       0.7170        0.7071  0.0953\n",
      "     92        0.5543       0.7110        0.7079  0.0894\n",
      "     93        \u001b[36m0.5525\u001b[0m       0.7130        0.7128  0.0881\n",
      "     94        \u001b[36m0.5502\u001b[0m       0.7140        0.7072  0.0891\n",
      "     95        0.5507       0.7180        0.7027  0.0921\n",
      "     96        0.5512       0.7210        0.7081  0.0905\n",
      "     97        \u001b[36m0.5494\u001b[0m       0.7060        0.7147  0.0907\n",
      "     98        0.5497       0.7210        0.7129  0.0981\n",
      "     99        0.5497       0.7270        0.7111  0.0908\n",
      "    100        0.5505       0.7200        0.7118  0.0889\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0004\u001b[0m       \u001b[32m0.6540\u001b[0m        \u001b[35m0.7754\u001b[0m  0.0932\n",
      "      2        \u001b[36m0.7580\u001b[0m       \u001b[32m0.6920\u001b[0m        \u001b[35m0.6942\u001b[0m  0.0958\n",
      "      3        \u001b[36m0.7050\u001b[0m       0.6900        0.7223  0.0901\n",
      "      4        0.7128       0.6770        0.7615  0.0999\n",
      "      5        0.7068       \u001b[32m0.7010\u001b[0m        0.7164  0.0972\n",
      "      6        \u001b[36m0.6911\u001b[0m       0.6920        0.7094  0.0946\n",
      "      7        0.6988       0.6920        0.6969  0.0951\n",
      "      8        0.6920       0.6850        0.7003  0.0908\n",
      "      9        0.6974       0.6950        0.6963  0.0911\n",
      "     10        \u001b[36m0.6891\u001b[0m       \u001b[32m0.7040\u001b[0m        0.6991  0.0926\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8208\u001b[0m       \u001b[32m0.5480\u001b[0m        \u001b[35m0.9236\u001b[0m  0.0921\n",
      "      2        \u001b[36m0.7132\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.6879\u001b[0m  0.0966\n",
      "      3        \u001b[36m0.6899\u001b[0m       \u001b[32m0.7370\u001b[0m        \u001b[35m0.6843\u001b[0m  0.0936\n",
      "      4        0.7065       0.6110        0.7687  0.0972\n",
      "      5        0.6950       0.7350        \u001b[35m0.6554\u001b[0m  0.0926\n",
      "      6        \u001b[36m0.6691\u001b[0m       0.7170        0.6741  0.0935\n",
      "      7        0.6756       0.6770        0.7217  0.0928\n",
      "      8        0.6945       0.6470        0.7402  0.0922\n",
      "      9        0.6906       0.6880        0.7087  0.0961\n",
      "     10        0.6935       0.7250        0.6798  0.0921\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5746\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0891\n",
      "      2       10.6176       0.3340       10.6176  0.0877\n",
      "      3       10.6176       0.3340       10.6176  0.0884\n",
      "      4       10.6176       0.3340       10.6176  0.0964\n",
      "      5       10.6176       0.3340       10.6176  0.0906\n",
      "      6       10.6176       0.3340       10.6176  0.0936\n",
      "      7       10.6176       0.3340       10.6176  0.0907\n",
      "      8       10.6176       0.3340       10.6176  0.0896\n",
      "      9       10.6176       0.3340       10.6176  0.0932\n",
      "     10       10.6176       0.3340       10.6176  0.0878\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5160\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0927\n",
      "      2       10.6176       0.3340       10.6176  0.0867\n",
      "      3       10.6176       0.3340       10.6176  0.0918\n",
      "      4       10.6176       0.3340       10.6176  0.0892\n",
      "      5       10.6176       0.3340       10.6176  0.0891\n",
      "      6       10.6176       0.3340       10.6176  0.1020\n",
      "      7       10.6176       0.3340       10.6176  0.0998\n",
      "      8       10.6176       0.3340       10.6176  0.0886\n",
      "      9       10.6176       0.3340       10.6176  0.0891\n",
      "     10       10.6176       0.3340       10.6176  0.0921\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9525\u001b[0m       \u001b[32m0.6330\u001b[0m        \u001b[35m0.8662\u001b[0m  0.0967\n",
      "      2        \u001b[36m0.8731\u001b[0m       \u001b[32m0.6370\u001b[0m        \u001b[35m0.8426\u001b[0m  0.0945\n",
      "      3        \u001b[36m0.8489\u001b[0m       0.6320        0.8556  0.0976\n",
      "      4        \u001b[36m0.8411\u001b[0m       \u001b[32m0.6480\u001b[0m        \u001b[35m0.8179\u001b[0m  0.0971\n",
      "      5        \u001b[36m0.8268\u001b[0m       \u001b[32m0.6580\u001b[0m        \u001b[35m0.8167\u001b[0m  0.0947\n",
      "      6        \u001b[36m0.8099\u001b[0m       \u001b[32m0.6720\u001b[0m        \u001b[35m0.7890\u001b[0m  0.0901\n",
      "      7        \u001b[36m0.7731\u001b[0m       0.6530        \u001b[35m0.7580\u001b[0m  0.0973\n",
      "      8        \u001b[36m0.7628\u001b[0m       0.6440        \u001b[35m0.7348\u001b[0m  0.0975\n",
      "      9        \u001b[36m0.7481\u001b[0m       0.6150        0.7498  0.0972\n",
      "     10        0.7653       0.5930        0.8054  0.1082\n",
      "     11        0.7718       0.5940        0.7583  0.0956\n",
      "     12        \u001b[36m0.7456\u001b[0m       0.6380        \u001b[35m0.7265\u001b[0m  0.0985\n",
      "     13        \u001b[36m0.7412\u001b[0m       0.6590        0.7386  0.1026\n",
      "     14        \u001b[36m0.7355\u001b[0m       0.6620        0.7383  0.1026\n",
      "     15        0.7357       0.6650        0.7359  0.1062\n",
      "     16        0.7383       \u001b[32m0.6880\u001b[0m        \u001b[35m0.7150\u001b[0m  0.1044\n",
      "     17        0.7431       \u001b[32m0.6920\u001b[0m        0.7365  0.1016\n",
      "     18        0.7400       0.6880        0.7333  0.1026\n",
      "     19        \u001b[36m0.7302\u001b[0m       0.6860        0.7151  0.1052\n",
      "     20        \u001b[36m0.7296\u001b[0m       0.6860        0.7174  0.1032\n",
      "     21        0.7332       0.6910        0.7157  0.1042\n",
      "     22        0.7299       0.6460        0.7175  0.1035\n",
      "     23        0.7379       0.6880        0.7292  0.1052\n",
      "     24        \u001b[36m0.7283\u001b[0m       0.6880        0.7180  0.1044\n",
      "     25        \u001b[36m0.7281\u001b[0m       0.6800        \u001b[35m0.7150\u001b[0m  0.1053\n",
      "     26        0.7294       0.6860        0.7151  0.0991\n",
      "     27        0.7385       0.6830        0.7191  0.1022\n",
      "     28        0.7288       0.6850        0.7151  0.1046\n",
      "     29        0.7307       \u001b[32m0.6930\u001b[0m        0.7164  0.1048\n",
      "     30        0.7329       0.6840        0.7157  0.1039\n",
      "     31        \u001b[36m0.7275\u001b[0m       0.6840        0.7151  0.1298\n",
      "     32        \u001b[36m0.7275\u001b[0m       0.6840        0.7160  0.1038\n",
      "     33        \u001b[36m0.7260\u001b[0m       0.6870        \u001b[35m0.7136\u001b[0m  0.1002\n",
      "     34        0.7274       0.6900        0.7146  0.1034\n",
      "     35        0.7346       0.6860        0.7185  0.1013\n",
      "     36        0.7298       0.6910        0.7151  0.1101\n",
      "     37        0.7297       0.6900        0.7148  0.1028\n",
      "     38        0.7291       0.6920        0.7164  0.1042\n",
      "     39        0.7293       0.6880        0.7168  0.1037\n",
      "     40        0.7292       0.6880        0.7169  0.1017\n",
      "     41        0.7314       0.6450        0.7209  0.1038\n",
      "     42        0.7324       0.6870        0.7218  0.1027\n",
      "     43        0.7333       0.6880        0.7253  0.0981\n",
      "     44        0.7330       0.6450        0.7291  0.1005\n",
      "     45        0.7329       0.6460        0.7289  0.1047\n",
      "     46        0.7319       0.6440        0.7291  0.1041\n",
      "     47        0.7305       0.6880        0.7251  0.1061\n",
      "     48        0.7324       0.6450        0.7277  0.1021\n",
      "     49        0.7326       0.6450        0.7291  0.1098\n",
      "     50        0.7332       0.6460        0.7294  0.1115\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9271\u001b[0m       \u001b[32m0.4960\u001b[0m        \u001b[35m1.5705\u001b[0m  0.1061\n",
      "      2        \u001b[36m0.7971\u001b[0m       \u001b[32m0.6080\u001b[0m        \u001b[35m0.8256\u001b[0m  0.1046\n",
      "      3        \u001b[36m0.7331\u001b[0m       0.5780        \u001b[35m0.7388\u001b[0m  0.1001\n",
      "      4        \u001b[36m0.6940\u001b[0m       \u001b[32m0.6110\u001b[0m        0.7413  0.1007\n",
      "      5        0.6978       0.5710        0.8031  0.0983\n",
      "      6        0.7163       \u001b[32m0.6740\u001b[0m        0.7726  0.1038\n",
      "      7        0.7056       \u001b[32m0.7200\u001b[0m        \u001b[35m0.7102\u001b[0m  0.0980\n",
      "      8        \u001b[36m0.6796\u001b[0m       0.7040        \u001b[35m0.7040\u001b[0m  0.1002\n",
      "      9        0.7071       \u001b[32m0.7330\u001b[0m        \u001b[35m0.6621\u001b[0m  0.1085\n",
      "     10        \u001b[36m0.6739\u001b[0m       0.7270        0.6776  0.1162\n",
      "     11        0.6798       0.7210        0.6946  0.1033\n",
      "     12        0.6857       0.7250        0.6930  0.1338\n",
      "     13        0.6880       0.7040        0.7167  0.1052\n",
      "     14        0.6933       0.7310        0.6790  0.1035\n",
      "     15        0.6844       \u001b[32m0.7390\u001b[0m        0.6806  0.1120\n",
      "     16        0.6933       0.7330        0.6665  0.1118\n",
      "     17        0.6928       0.7330        0.6738  0.0988\n",
      "     18        0.6945       0.6430        0.7189  0.1047\n",
      "     19        0.6910       0.7210        0.6875  0.1022\n",
      "     20        0.6825       0.7320        0.6797  0.1063\n",
      "     21        0.6928       0.7370        0.6672  0.1040\n",
      "     22        0.6801       \u001b[32m0.7460\u001b[0m        0.6745  0.1061\n",
      "     23        0.6848       0.7320        0.6679  0.1050\n",
      "     24        0.6829       0.7360        0.6735  0.1005\n",
      "     25        0.6849       0.6940        0.7109  0.1073\n",
      "     26        0.6833       0.7220        0.6823  0.1012\n",
      "     27        0.6877       0.7270        0.6769  0.1103\n",
      "     28        0.6836       0.7320        0.6722  0.1056\n",
      "     29        0.6770       0.7160        0.6924  0.1026\n",
      "     30        0.6751       0.7250        0.6771  0.1006\n",
      "     31        0.6848       \u001b[32m0.7470\u001b[0m        \u001b[35m0.6529\u001b[0m  0.1032\n",
      "     32        0.6838       0.6930        0.7058  0.1014\n",
      "     33        0.6842       0.7270        0.6874  0.1031\n",
      "     34        0.6783       0.7180        0.6885  0.1016\n",
      "     35        0.6846       0.6800        0.7270  0.1014\n",
      "     36        0.6850       0.7200        0.6996  0.1030\n",
      "     37        0.6867       0.7330        0.7003  0.1072\n",
      "     38        0.6875       0.7440        0.6575  0.1122\n",
      "     39        0.6913       0.7120        0.6830  0.1108\n",
      "     40        0.6771       0.7220        0.6800  0.1165\n",
      "     41        \u001b[36m0.6703\u001b[0m       0.7230        0.7063  0.1030\n",
      "     42        0.6778       0.7440        0.6580  0.1098\n",
      "     43        \u001b[36m0.6699\u001b[0m       0.7320        0.6657  0.1073\n",
      "     44        0.6751       0.7360        0.6716  0.1047\n",
      "     45        0.6722       0.6840        0.7155  0.1042\n",
      "     46        0.6807       0.7170        0.7109  0.1031\n",
      "     47        0.6822       0.7420        0.6792  0.1073\n",
      "     48        0.6761       0.6960        0.7040  0.1077\n",
      "     49        0.6831       0.7350        0.6831  0.1068\n",
      "     50        0.6747       0.7020        0.7007  0.1052\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5765\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0901\n",
      "      2       10.6176       0.3340       10.6176  0.0939\n",
      "      3       10.6176       0.3340       10.6176  0.0885\n",
      "      4       10.6176       0.3340       10.6176  0.1039\n",
      "      5       10.6176       0.3340       10.6176  0.0965\n",
      "      6       10.6176       0.3340       10.6176  0.0880\n",
      "      7       10.6176       0.3340       10.6176  0.0965\n",
      "      8       10.6176       0.3340       10.6176  0.0942\n",
      "      9       10.6176       0.3340       10.6176  0.0941\n",
      "     10       10.6176       0.3340       10.6176  0.1106\n",
      "     11       10.6176       0.3340       10.6176  0.0898\n",
      "     12       10.6176       0.3340       10.6176  0.0892\n",
      "     13       10.6176       0.3340       10.6176  0.0934\n",
      "     14       10.6176       0.3340       10.6176  0.1000\n",
      "     15       10.6176       0.3340       10.6176  0.0928\n",
      "     16       10.6176       0.3340       10.6176  0.0903\n",
      "     17       10.6176       0.3340       10.6176  0.0896\n",
      "     18       10.6176       0.3340       10.6176  0.0899\n",
      "     19       10.6176       0.3340       10.6176  0.0941\n",
      "     20       10.6176       0.3340       10.6176  0.0967\n",
      "     21       10.6176       0.3340       10.6176  0.0939\n",
      "     22       10.6176       0.3340       10.6176  0.0947\n",
      "     23       10.6176       0.3340       10.6176  0.0953\n",
      "     24       10.6176       0.3340       10.6176  0.0867\n",
      "     25       10.6176       0.3340       10.6176  0.0993\n",
      "     26       10.6176       0.3340       10.6176  0.0956\n",
      "     27       10.6176       0.3340       10.6176  0.0998\n",
      "     28       10.6176       0.3340       10.6176  0.0951\n",
      "     29       10.6176       0.3340       10.6176  0.0977\n",
      "     30       10.6176       0.3340       10.6176  0.0971\n",
      "     31       10.6176       0.3340       10.6176  0.0936\n",
      "     32       10.6176       0.3340       10.6176  0.0971\n",
      "     33       10.6176       0.3340       10.6176  0.0943\n",
      "     34       10.6176       0.3340       10.6176  0.0900\n",
      "     35       10.6176       0.3340       10.6176  0.1274\n",
      "     36       10.6176       0.3340       10.6176  0.1257\n",
      "     37       10.6176       0.3340       10.6176  0.0907\n",
      "     38       10.6176       0.3340       10.6176  0.0935\n",
      "     39       10.6176       0.3340       10.6176  0.0917\n",
      "     40       10.6176       0.3340       10.6176  0.0966\n",
      "     41       10.6176       0.3340       10.6176  0.0894\n",
      "     42       10.6176       0.3340       10.6176  0.0919\n",
      "     43       10.6176       0.3340       10.6176  0.0933\n",
      "     44       10.6176       0.3340       10.6176  0.0957\n",
      "     45       10.6176       0.3340       10.6176  0.0938\n",
      "     46       10.6176       0.3340       10.6176  0.0970\n",
      "     47       10.6176       0.3340       10.6176  0.1033\n",
      "     48       10.6176       0.3340       10.6176  0.0984\n",
      "     49       10.6176       0.3340       10.6176  0.1181\n",
      "     50       10.6176       0.3340       10.6176  0.0937\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5157\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0940\n",
      "      2       10.6176       0.3340       10.6176  0.0904\n",
      "      3       10.6176       0.3340       10.6176  0.0926\n",
      "      4       10.6176       0.3340       10.6176  0.0892\n",
      "      5       10.6176       0.3340       10.6176  0.0903\n",
      "      6       10.6176       0.3340       10.6176  0.0928\n",
      "      7       10.6176       0.3340       10.6176  0.0982\n",
      "      8       10.6176       0.3340       10.6176  0.0900\n",
      "      9       10.6176       0.3340       10.6176  0.1526\n",
      "     10       10.6176       0.3340       10.6176  0.0903\n",
      "     11       10.6176       0.3340       10.6176  0.0890\n",
      "     12       10.6176       0.3340       10.6176  0.0873\n",
      "     13       10.6176       0.3340       10.6176  0.0941\n",
      "     14       10.6176       0.3340       10.6176  0.0906\n",
      "     15       10.6176       0.3340       10.6176  0.0937\n",
      "     16       10.6176       0.3340       10.6176  0.1002\n",
      "     17       10.6176       0.3340       10.6176  0.1010\n",
      "     18       10.6176       0.3340       10.6176  0.0953\n",
      "     19       10.6176       0.3340       10.6176  0.0901\n",
      "     20       10.6176       0.3340       10.6176  0.0920\n",
      "     21       10.6176       0.3340       10.6176  0.0922\n",
      "     22       10.6176       0.3340       10.6176  0.1019\n",
      "     23       10.6176       0.3340       10.6176  0.0913\n",
      "     24       10.6176       0.3340       10.6176  0.0916\n",
      "     25       10.6176       0.3340       10.6176  0.0985\n",
      "     26       10.6176       0.3340       10.6176  0.0988\n",
      "     27       10.6176       0.3340       10.6176  0.0892\n",
      "     28       10.6176       0.3340       10.6176  0.0927\n",
      "     29       10.6176       0.3340       10.6176  0.1022\n",
      "     30       10.6176       0.3340       10.6176  0.0828\n",
      "     31       10.6176       0.3340       10.6176  0.0962\n",
      "     32       10.6176       0.3340       10.6176  0.1000\n",
      "     33       10.6176       0.3340       10.6176  0.1087\n",
      "     34       10.6176       0.3340       10.6176  0.0877\n",
      "     35       10.6176       0.3340       10.6176  0.0922\n",
      "     36       10.6176       0.3340       10.6176  0.1023\n",
      "     37       10.6176       0.3340       10.6176  0.0941\n",
      "     38       10.6176       0.3340       10.6176  0.0995\n",
      "     39       10.6176       0.3340       10.6176  0.0975\n",
      "     40       10.6176       0.3340       10.6176  0.1024\n",
      "     41       10.6176       0.3340       10.6176  0.1043\n",
      "     42       10.6176       0.3340       10.6176  0.0936\n",
      "     43       10.6176       0.3340       10.6176  0.1004\n",
      "     44       10.6176       0.3340       10.6176  0.0960\n",
      "     45       10.6176       0.3340       10.6176  0.0971\n",
      "     46       10.6176       0.3340       10.6176  0.0910\n",
      "     47       10.6176       0.3340       10.6176  0.0912\n",
      "     48       10.6176       0.3340       10.6176  0.0912\n",
      "     49       10.6176       0.3340       10.6176  0.0867\n",
      "     50       10.6176       0.3340       10.6176  0.0901\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0961\u001b[0m       \u001b[32m0.4890\u001b[0m        \u001b[35m1.0264\u001b[0m  0.0947\n",
      "      2        \u001b[36m1.0292\u001b[0m       0.4890        1.0267  0.0967\n",
      "      3        1.0296       0.4890        1.0265  0.0977\n",
      "      4        1.0299       0.4890        \u001b[35m1.0264\u001b[0m  0.0994\n",
      "      5        1.0301       0.4890        \u001b[35m1.0263\u001b[0m  0.1027\n",
      "      6        1.0302       0.4890        \u001b[35m1.0263\u001b[0m  0.1006\n",
      "      7        1.0302       0.4890        \u001b[35m1.0263\u001b[0m  0.1006\n",
      "      8        1.0303       0.4890        \u001b[35m1.0263\u001b[0m  0.0957\n",
      "      9        1.0303       0.4890        \u001b[35m1.0262\u001b[0m  0.0902\n",
      "     10        1.0303       0.4890        \u001b[35m1.0262\u001b[0m  0.0946\n",
      "     11        1.0303       0.4890        \u001b[35m1.0262\u001b[0m  0.0975\n",
      "     12        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1063\n",
      "     13        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1066\n",
      "     14        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1191\n",
      "     15        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1153\n",
      "     16        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1037\n",
      "     17        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1026\n",
      "     18        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1016\n",
      "     19        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1047\n",
      "     20        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1141\n",
      "     21        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1007\n",
      "     22        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1023\n",
      "     23        1.0304       0.4890        \u001b[35m1.0262\u001b[0m  0.1042\n",
      "     24        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1039\n",
      "     25        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1066\n",
      "     26        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1026\n",
      "     27        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1161\n",
      "     28        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1077\n",
      "     29        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1001\n",
      "     30        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1047\n",
      "     31        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1076\n",
      "     32        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1066\n",
      "     33        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1016\n",
      "     34        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1053\n",
      "     35        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1071\n",
      "     36        1.0305       0.4890        1.0262  0.1066\n",
      "     37        1.0305       0.4890        1.0262  0.1001\n",
      "     38        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1049\n",
      "     39        1.0305       0.4890        1.0262  0.1084\n",
      "     40        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1063\n",
      "     41        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1115\n",
      "     42        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1028\n",
      "     43        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1013\n",
      "     44        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1006\n",
      "     45        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1036\n",
      "     46        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1043\n",
      "     47        1.0305       0.4890        1.0262  0.1031\n",
      "     48        1.0305       0.4890        1.0262  0.1044\n",
      "     49        1.0305       0.4890        1.0262  0.1029\n",
      "     50        1.0305       0.4890        1.0262  0.1021\n",
      "     51        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1057\n",
      "     52        1.0305       0.4890        1.0262  0.1023\n",
      "     53        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1232\n",
      "     54        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1032\n",
      "     55        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1002\n",
      "     56        1.0305       0.4890        1.0262  0.1090\n",
      "     57        1.0305       0.4890        1.0262  0.1135\n",
      "     58        1.0305       0.4890        1.0262  0.1038\n",
      "     59        1.0305       0.4890        1.0262  0.1062\n",
      "     60        1.0305       0.4890        1.0262  0.1068\n",
      "     61        1.0305       0.4890        1.0262  0.1016\n",
      "     62        1.0305       0.4890        1.0262  0.1072\n",
      "     63        1.0305       0.4890        1.0262  0.1057\n",
      "     64        1.0305       0.4890        1.0262  0.0961\n",
      "     65        1.0305       0.4890        1.0262  0.0999\n",
      "     66        1.0305       0.4890        1.0262  0.1005\n",
      "     67        1.0305       0.4890        1.0262  0.0992\n",
      "     68        1.0305       0.4890        1.0262  0.1036\n",
      "     69        1.0305       0.4890        1.0262  0.1012\n",
      "     70        1.0305       0.4890        1.0262  0.1020\n",
      "     71        1.0305       0.4890        1.0262  0.1032\n",
      "     72        1.0305       0.4890        1.0262  0.1022\n",
      "     73        1.0305       0.4890        1.0262  0.1018\n",
      "     74        1.0305       0.4890        1.0262  0.1033\n",
      "     75        1.0305       0.4890        1.0262  0.1064\n",
      "     76        1.0305       0.4890        1.0262  0.1111\n",
      "     77        1.0305       0.4890        1.0262  0.1041\n",
      "     78        1.0305       0.4890        1.0262  0.1069\n",
      "     79        1.0305       0.4890        1.0262  0.1033\n",
      "     80        1.0305       0.4890        1.0262  0.1018\n",
      "     81        1.0305       0.4890        \u001b[35m1.0262\u001b[0m  0.1024\n",
      "     82        1.0305       0.4890        1.0262  0.1028\n",
      "     83        1.0305       0.4890        1.0262  0.1016\n",
      "     84        1.0305       0.4890        1.0262  0.1026\n",
      "     85        1.0305       0.4890        1.0262  0.1162\n",
      "     86        1.0305       0.4890        1.0262  0.1070\n",
      "     87        1.0305       0.4890        1.0262  0.1001\n",
      "     88        1.0305       0.4890        1.0262  0.1121\n",
      "     89        1.0305       0.4890        1.0262  0.1037\n",
      "     90        1.0305       0.4890        1.0262  0.1040\n",
      "     91        1.0305       0.4890        1.0262  0.1024\n",
      "     92        1.0305       0.4890        1.0262  0.1053\n",
      "     93        1.0305       0.4890        1.0262  0.1023\n",
      "     94        1.0305       0.4890        1.0262  0.1099\n",
      "     95        1.0305       0.4890        1.0262  0.1166\n",
      "     96        1.0305       0.4890        1.0262  0.1151\n",
      "     97        1.0305       0.4890        1.0262  0.1013\n",
      "     98        1.0305       0.4890        1.0262  0.1012\n",
      "     99        1.0305       0.4890        1.0262  0.1147\n",
      "    100        1.0305       0.4890        1.0262  0.1036\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8931\u001b[0m       \u001b[32m0.4920\u001b[0m        \u001b[35m1.0132\u001b[0m  0.0997\n",
      "      2        \u001b[36m0.7743\u001b[0m       \u001b[32m0.5660\u001b[0m        \u001b[35m0.8079\u001b[0m  0.0967\n",
      "      3        \u001b[36m0.7262\u001b[0m       0.5630        \u001b[35m0.7515\u001b[0m  0.0957\n",
      "      4        \u001b[36m0.7227\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.7289\u001b[0m  0.0964\n",
      "      5        \u001b[36m0.7055\u001b[0m       \u001b[32m0.7350\u001b[0m        \u001b[35m0.6760\u001b[0m  0.0986\n",
      "      6        \u001b[36m0.6849\u001b[0m       \u001b[32m0.7360\u001b[0m        \u001b[35m0.6540\u001b[0m  0.0992\n",
      "      7        \u001b[36m0.6644\u001b[0m       0.7310        \u001b[35m0.6495\u001b[0m  0.0961\n",
      "      8        \u001b[36m0.6583\u001b[0m       0.7340        0.6672  0.0976\n",
      "      9        \u001b[36m0.6570\u001b[0m       0.7300        \u001b[35m0.6426\u001b[0m  0.0947\n",
      "     10        0.6581       0.7330        0.6459  0.0977\n",
      "     11        0.6779       0.7310        0.6555  0.0982\n",
      "     12        0.6759       0.7230        0.6552  0.1057\n",
      "     13        \u001b[36m0.6480\u001b[0m       0.7360        0.6508  0.1046\n",
      "     14        0.6562       0.7330        0.6613  0.1208\n",
      "     15        0.6616       0.7340        0.6457  0.1053\n",
      "     16        0.6487       0.7310        0.6476  0.1099\n",
      "     17        \u001b[36m0.6453\u001b[0m       0.7340        0.6592  0.1389\n",
      "     18        0.6465       \u001b[32m0.7370\u001b[0m        0.6553  0.1084\n",
      "     19        0.6637       0.7270        0.6494  0.1144\n",
      "     20        0.6587       0.7320        0.6575  0.1241\n",
      "     21        0.6572       0.7350        0.6456  0.1132\n",
      "     22        0.6469       \u001b[32m0.7380\u001b[0m        0.6549  0.1038\n",
      "     23        0.6509       0.7320        0.6603  0.1021\n",
      "     24        0.6512       0.7350        0.6563  0.1152\n",
      "     25        0.6565       0.7300        0.6486  0.1117\n",
      "     26        0.6481       0.7300        0.6572  0.1037\n",
      "     27        0.6772       0.7310        0.6619  0.1056\n",
      "     28        0.6505       0.7300        0.6592  0.1070\n",
      "     29        0.6545       0.7290        0.6550  0.1070\n",
      "     30        0.6495       0.7280        0.6711  0.1024\n",
      "     31        0.6503       0.7320        0.6614  0.1076\n",
      "     32        0.6517       0.7340        0.6484  0.1114\n",
      "     33        0.6487       0.7330        0.6530  0.1135\n",
      "     34        0.6477       0.7250        0.6628  0.1395\n",
      "     35        0.6524       0.7370        0.6585  0.1072\n",
      "     36        \u001b[36m0.6443\u001b[0m       0.7350        0.6432  0.1126\n",
      "     37        0.6466       0.7250        0.6593  0.1038\n",
      "     38        0.6539       0.7240        0.6624  0.1046\n",
      "     39        0.6547       0.7310        0.6516  0.1067\n",
      "     40        0.6544       0.7250        0.6606  0.1047\n",
      "     41        0.6671       0.7320        0.6696  0.1037\n",
      "     42        0.6515       0.7340        0.6567  0.1124\n",
      "     43        0.6498       0.7360        0.6579  0.1062\n",
      "     44        0.6470       0.7280        0.6612  0.1115\n",
      "     45        0.6457       0.7330        0.6509  0.1267\n",
      "     46        0.6449       0.7260        0.6520  0.1096\n",
      "     47        0.6497       0.7370        0.6464  0.1094\n",
      "     48        0.6493       0.7360        0.6461  0.1093\n",
      "     49        0.6495       0.7290        0.6553  0.1081\n",
      "     50        0.6480       0.7360        0.6530  0.1117\n",
      "     51        0.6557       \u001b[32m0.7400\u001b[0m        \u001b[35m0.6393\u001b[0m  0.1065\n",
      "     52        0.6523       0.7150        0.6711  0.1084\n",
      "     53        0.6531       0.7330        0.6623  0.1054\n",
      "     54        0.6457       0.7250        0.6619  0.1037\n",
      "     55        0.6488       0.7270        0.6507  0.1014\n",
      "     56        0.6515       0.7330        0.6533  0.1063\n",
      "     57        0.6555       0.7310        0.6549  0.1062\n",
      "     58        0.6459       0.7280        0.6559  0.1007\n",
      "     59        0.6450       0.7300        0.6537  0.1062\n",
      "     60        0.6484       0.7180        0.6532  0.1026\n",
      "     61        0.6527       0.7310        0.6593  0.1036\n",
      "     62        0.6512       0.7320        0.6583  0.1048\n",
      "     63        0.6472       0.7320        0.6595  0.0985\n",
      "     64        0.6505       0.7350        0.6454  0.1021\n",
      "     65        0.6485       0.7330        0.6561  0.1011\n",
      "     66        0.6497       0.7360        \u001b[35m0.6378\u001b[0m  0.1072\n",
      "     67        0.6484       0.7290        0.6465  0.1027\n",
      "     68        0.6494       0.7340        0.6445  0.1025\n",
      "     69        0.6590       0.7280        0.6827  0.1062\n",
      "     70        0.6797       0.7290        0.6798  0.1085\n",
      "     71        0.6628       0.7010        0.6631  0.1020\n",
      "     72        0.6514       0.7330        0.6486  0.1051\n",
      "     73        0.6499       0.7270        0.6470  0.1007\n",
      "     74        0.6488       0.7310        0.6553  0.1132\n",
      "     75        0.6452       0.7360        0.6449  0.1043\n",
      "     76        \u001b[36m0.6398\u001b[0m       0.7350        0.6475  0.1027\n",
      "     77        0.6482       0.7340        0.6429  0.1024\n",
      "     78        0.6493       0.7230        0.6610  0.1041\n",
      "     79        0.6467       0.7350        0.6526  0.1055\n",
      "     80        0.6523       0.7330        0.6471  0.1046\n",
      "     81        0.6520       0.7190        0.6495  0.1032\n",
      "     82        0.6532       0.7270        0.6486  0.1112\n",
      "     83        0.6418       0.7210        0.6708  0.1059\n",
      "     84        0.6538       0.7360        0.6400  0.1045\n",
      "     85        0.6456       0.7220        0.6564  0.1055\n",
      "     86        0.6567       0.7210        0.6618  0.1039\n",
      "     87        0.6565       0.7290        0.6508  0.1042\n",
      "     88        0.6470       0.7240        0.6616  0.1061\n",
      "     89        0.6447       0.7300        0.6479  0.1053\n",
      "     90        0.6497       0.7290        0.6590  0.1111\n",
      "     91        0.6510       0.7310        0.6507  0.1058\n",
      "     92        0.6543       0.7310        0.6526  0.1134\n",
      "     93        0.6463       0.7250        0.6685  0.1133\n",
      "     94        0.6575       0.7360        0.6533  0.1026\n",
      "     95        0.6502       0.7340        0.6415  0.1102\n",
      "     96        0.6460       0.7250        0.6604  0.1054\n",
      "     97        0.6496       0.7230        0.6618  0.0988\n",
      "     98        0.6493       0.7300        0.6567  0.1096\n",
      "     99        0.6439       0.7320        0.6534  0.1054\n",
      "    100        0.6507       0.7290        0.6588  0.1027\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5758\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1052\n",
      "      2       10.6176       0.3340       10.6176  0.0931\n",
      "      3       10.6176       0.3340       10.6176  0.0900\n",
      "      4       10.6176       0.3340       10.6176  0.1168\n",
      "      5       10.6176       0.3340       10.6176  0.0981\n",
      "      6       10.6176       0.3340       10.6176  0.0868\n",
      "      7       10.6176       0.3340       10.6176  0.0916\n",
      "      8       10.6176       0.3340       10.6176  0.0926\n",
      "      9       10.6176       0.3340       10.6176  0.0942\n",
      "     10       10.6176       0.3340       10.6176  0.1169\n",
      "     11       10.6176       0.3340       10.6176  0.0907\n",
      "     12       10.6176       0.3340       10.6176  0.0913\n",
      "     13       10.6176       0.3340       10.6176  0.0892\n",
      "     14       10.6176       0.3340       10.6176  0.0899\n",
      "     15       10.6176       0.3340       10.6176  0.0861\n",
      "     16       10.6176       0.3340       10.6176  0.0999\n",
      "     17       10.6176       0.3340       10.6176  0.1069\n",
      "     18       10.6176       0.3340       10.6176  0.1023\n",
      "     19       10.6176       0.3340       10.6176  0.0959\n",
      "     20       10.6176       0.3340       10.6176  0.0899\n",
      "     21       10.6176       0.3340       10.6176  0.0919\n",
      "     22       10.6176       0.3340       10.6176  0.0911\n",
      "     23       10.6176       0.3340       10.6176  0.0906\n",
      "     24       10.6176       0.3340       10.6176  0.0896\n",
      "     25       10.6176       0.3340       10.6176  0.0908\n",
      "     26       10.6176       0.3340       10.6176  0.0922\n",
      "     27       10.6176       0.3340       10.6176  0.0886\n",
      "     28       10.6176       0.3340       10.6176  0.0942\n",
      "     29       10.6176       0.3340       10.6176  0.0942\n",
      "     30       10.6176       0.3340       10.6176  0.0884\n",
      "     31       10.6176       0.3340       10.6176  0.0902\n",
      "     32       10.6176       0.3340       10.6176  0.0972\n",
      "     33       10.6176       0.3340       10.6176  0.0841\n",
      "     34       10.6176       0.3340       10.6176  0.0885\n",
      "     35       10.6176       0.3340       10.6176  0.1027\n",
      "     36       10.6176       0.3340       10.6176  0.0947\n",
      "     37       10.6176       0.3340       10.6176  0.0930\n",
      "     38       10.6176       0.3340       10.6176  0.0913\n",
      "     39       10.6176       0.3340       10.6176  0.0912\n",
      "     40       10.6176       0.3340       10.6176  0.0885\n",
      "     41       10.6176       0.3340       10.6176  0.0901\n",
      "     42       10.6176       0.3340       10.6176  0.0872\n",
      "     43       10.6176       0.3340       10.6176  0.0903\n",
      "     44       10.6176       0.3340       10.6176  0.0911\n",
      "     45       10.6176       0.3340       10.6176  0.0888\n",
      "     46       10.6176       0.3340       10.6176  0.0911\n",
      "     47       10.6176       0.3340       10.6176  0.0939\n",
      "     48       10.6176       0.3340       10.6176  0.0887\n",
      "     49       10.6176       0.3340       10.6176  0.0861\n",
      "     50       10.6176       0.3340       10.6176  0.0921\n",
      "     51       10.6176       0.3340       10.6176  0.0881\n",
      "     52       10.6176       0.3340       10.6176  0.0881\n",
      "     53       10.6176       0.3340       10.6176  0.0901\n",
      "     54       10.6176       0.3340       10.6176  0.0884\n",
      "     55       10.6176       0.3340       10.6176  0.0898\n",
      "     56       10.6176       0.3340       10.6176  0.0899\n",
      "     57       10.6176       0.3340       10.6176  0.0921\n",
      "     58       10.6176       0.3340       10.6176  0.0908\n",
      "     59       10.6176       0.3340       10.6176  0.1020\n",
      "     60       10.6176       0.3340       10.6176  0.0878\n",
      "     61       10.6176       0.3340       10.6176  0.0980\n",
      "     62       10.6176       0.3340       10.6176  0.0903\n",
      "     63       10.6176       0.3340       10.6176  0.0911\n",
      "     64       10.6176       0.3340       10.6176  0.1031\n",
      "     65       10.6176       0.3340       10.6176  0.0883\n",
      "     66       10.6176       0.3340       10.6176  0.0891\n",
      "     67       10.6176       0.3340       10.6176  0.0928\n",
      "     68       10.6176       0.3340       10.6176  0.0901\n",
      "     69       10.6176       0.3340       10.6176  0.0876\n",
      "     70       10.6176       0.3340       10.6176  0.0946\n",
      "     71       10.6176       0.3340       10.6176  0.0909\n",
      "     72       10.6176       0.3340       10.6176  0.0934\n",
      "     73       10.6176       0.3340       10.6176  0.0970\n",
      "     74       10.6176       0.3340       10.6176  0.0892\n",
      "     75       10.6176       0.3340       10.6176  0.0891\n",
      "     76       10.6176       0.3340       10.6176  0.0907\n",
      "     77       10.6176       0.3340       10.6176  0.0879\n",
      "     78       10.6176       0.3340       10.6176  0.0869\n",
      "     79       10.6176       0.3340       10.6176  0.0872\n",
      "     80       10.6176       0.3340       10.6176  0.0893\n",
      "     81       10.6176       0.3340       10.6176  0.0931\n",
      "     82       10.6176       0.3340       10.6176  0.0938\n",
      "     83       10.6176       0.3340       10.6176  0.0945\n",
      "     84       10.6176       0.3340       10.6176  0.0958\n",
      "     85       10.6176       0.3340       10.6176  0.0987\n",
      "     86       10.6176       0.3340       10.6176  0.0935\n",
      "     87       10.6176       0.3340       10.6176  0.0978\n",
      "     88       10.6176       0.3340       10.6176  0.0947\n",
      "     89       10.6176       0.3340       10.6176  0.0901\n",
      "     90       10.6176       0.3340       10.6176  0.0914\n",
      "     91       10.6176       0.3340       10.6176  0.0922\n",
      "     92       10.6176       0.3340       10.6176  0.0911\n",
      "     93       10.6176       0.3340       10.6176  0.0974\n",
      "     94       10.6176       0.3340       10.6176  0.1181\n",
      "     95       10.6176       0.3340       10.6176  0.0937\n",
      "     96       10.6176       0.3340       10.6176  0.1007\n",
      "     97       10.6176       0.3340       10.6176  0.0941\n",
      "     98       10.6176       0.3340       10.6176  0.0962\n",
      "     99       10.6176       0.3340       10.6176  0.0990\n",
      "    100       10.6176       0.3340       10.6176  0.0982\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5162\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0909\n",
      "      2       10.6176       0.3340       10.6176  0.0911\n",
      "      3       10.6176       0.3340       10.6176  0.0926\n",
      "      4       10.6176       0.3340       10.6176  0.0945\n",
      "      5       10.6176       0.3340       10.6176  0.0913\n",
      "      6       10.6176       0.3340       10.6176  0.0940\n",
      "      7       10.6176       0.3340       10.6176  0.0995\n",
      "      8       10.6176       0.3340       10.6176  0.0915\n",
      "      9       10.6176       0.3340       10.6176  0.0906\n",
      "     10       10.6176       0.3340       10.6176  0.0912\n",
      "     11       10.6176       0.3340       10.6176  0.1025\n",
      "     12       10.6176       0.3340       10.6176  0.0977\n",
      "     13       10.6176       0.3340       10.6176  0.0987\n",
      "     14       10.6176       0.3340       10.6176  0.0931\n",
      "     15       10.6176       0.3340       10.6176  0.0876\n",
      "     16       10.6176       0.3340       10.6176  0.0947\n",
      "     17       10.6176       0.3340       10.6176  0.1159\n",
      "     18       10.6176       0.3340       10.6176  0.0976\n",
      "     19       10.6176       0.3340       10.6176  0.0856\n",
      "     20       10.6176       0.3340       10.6176  0.0912\n",
      "     21       10.6176       0.3340       10.6176  0.0946\n",
      "     22       10.6176       0.3340       10.6176  0.0882\n",
      "     23       10.6176       0.3340       10.6176  0.0900\n",
      "     24       10.6176       0.3340       10.6176  0.0921\n",
      "     25       10.6176       0.3340       10.6176  0.1092\n",
      "     26       10.6176       0.3340       10.6176  0.0902\n",
      "     27       10.6176       0.3340       10.6176  0.0915\n",
      "     28       10.6176       0.3340       10.6176  0.0937\n",
      "     29       10.6176       0.3340       10.6176  0.0982\n",
      "     30       10.6176       0.3340       10.6176  0.0922\n",
      "     31       10.6176       0.3340       10.6176  0.0874\n",
      "     32       10.6176       0.3340       10.6176  0.0892\n",
      "     33       10.6176       0.3340       10.6176  0.0878\n",
      "     34       10.6176       0.3340       10.6176  0.0852\n",
      "     35       10.6176       0.3340       10.6176  0.0937\n",
      "     36       10.6176       0.3340       10.6176  0.0973\n",
      "     37       10.6176       0.3340       10.6176  0.0922\n",
      "     38       10.6176       0.3340       10.6176  0.0891\n",
      "     39       10.6176       0.3340       10.6176  0.0941\n",
      "     40       10.6176       0.3340       10.6176  0.0908\n",
      "     41       10.6176       0.3340       10.6176  0.1008\n",
      "     42       10.6176       0.3340       10.6176  0.0903\n",
      "     43       10.6176       0.3340       10.6176  0.0895\n",
      "     44       10.6176       0.3340       10.6176  0.0905\n",
      "     45       10.6176       0.3340       10.6176  0.0895\n",
      "     46       10.6176       0.3340       10.6176  0.0904\n",
      "     47       10.6176       0.3340       10.6176  0.0964\n",
      "     48       10.6176       0.3340       10.6176  0.0927\n",
      "     49       10.6176       0.3340       10.6176  0.0936\n",
      "     50       10.6176       0.3340       10.6176  0.1021\n",
      "     51       10.6176       0.3340       10.6176  0.0917\n",
      "     52       10.6176       0.3340       10.6176  0.0979\n",
      "     53       10.6176       0.3340       10.6176  0.0936\n",
      "     54       10.6176       0.3340       10.6176  0.0921\n",
      "     55       10.6176       0.3340       10.6176  0.1060\n",
      "     56       10.6176       0.3340       10.6176  0.0878\n",
      "     57       10.6176       0.3340       10.6176  0.0909\n",
      "     58       10.6176       0.3340       10.6176  0.0929\n",
      "     59       10.6176       0.3340       10.6176  0.0916\n",
      "     60       10.6176       0.3340       10.6176  0.0903\n",
      "     61       10.6176       0.3340       10.6176  0.0922\n",
      "     62       10.6176       0.3340       10.6176  0.0916\n",
      "     63       10.6176       0.3340       10.6176  0.0892\n",
      "     64       10.6176       0.3340       10.6176  0.0984\n",
      "     65       10.6176       0.3340       10.6176  0.0941\n",
      "     66       10.6176       0.3340       10.6176  0.1226\n",
      "     67       10.6176       0.3340       10.6176  0.0938\n",
      "     68       10.6176       0.3340       10.6176  0.0927\n",
      "     69       10.6176       0.3340       10.6176  0.0985\n",
      "     70       10.6176       0.3340       10.6176  0.0958\n",
      "     71       10.6176       0.3340       10.6176  0.0954\n",
      "     72       10.6176       0.3340       10.6176  0.1399\n",
      "     73       10.6176       0.3340       10.6176  0.1081\n",
      "     74       10.6176       0.3340       10.6176  0.0927\n",
      "     75       10.6176       0.3340       10.6176  0.0922\n",
      "     76       10.6176       0.3340       10.6176  0.0932\n",
      "     77       10.6176       0.3340       10.6176  0.0866\n",
      "     78       10.6176       0.3340       10.6176  0.0915\n",
      "     79       10.6176       0.3340       10.6176  0.0892\n",
      "     80       10.6176       0.3340       10.6176  0.0921\n",
      "     81       10.6176       0.3340       10.6176  0.0951\n",
      "     82       10.6176       0.3340       10.6176  0.0937\n",
      "     83       10.6176       0.3340       10.6176  0.0938\n",
      "     84       10.6176       0.3340       10.6176  0.0911\n",
      "     85       10.6176       0.3340       10.6176  0.0927\n",
      "     86       10.6176       0.3340       10.6176  0.0907\n",
      "     87       10.6176       0.3340       10.6176  0.0999\n",
      "     88       10.6176       0.3340       10.6176  0.0948\n",
      "     89       10.6176       0.3340       10.6176  0.1277\n",
      "     90       10.6176       0.3340       10.6176  0.0983\n",
      "     91       10.6176       0.3340       10.6176  0.0990\n",
      "     92       10.6176       0.3340       10.6176  0.0941\n",
      "     93       10.6176       0.3340       10.6176  0.0953\n",
      "     94       10.6176       0.3340       10.6176  0.0870\n",
      "     95       10.6176       0.3340       10.6176  0.0898\n",
      "     96       10.6176       0.3340       10.6176  0.0924\n",
      "     97       10.6176       0.3340       10.6176  0.0916\n",
      "     98       10.6176       0.3340       10.6176  0.0955\n",
      "     99       10.6176       0.3340       10.6176  0.0926\n",
      "    100       10.6176       0.3340       10.6176  0.0989\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7351\u001b[0m       \u001b[32m0.6850\u001b[0m        \u001b[35m0.6979\u001b[0m  0.2928\n",
      "      2        \u001b[36m0.6492\u001b[0m       0.6820        0.6983  0.2727\n",
      "      3        \u001b[36m0.6316\u001b[0m       \u001b[32m0.6890\u001b[0m        \u001b[35m0.6918\u001b[0m  0.3011\n",
      "      4        \u001b[36m0.6229\u001b[0m       \u001b[32m0.6980\u001b[0m        \u001b[35m0.6766\u001b[0m  0.3029\n",
      "      5        \u001b[36m0.6192\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6638\u001b[0m  0.2953\n",
      "      6        \u001b[36m0.6154\u001b[0m       \u001b[32m0.7160\u001b[0m        0.6654  0.3022\n",
      "      7        \u001b[36m0.6120\u001b[0m       \u001b[32m0.7260\u001b[0m        \u001b[35m0.6596\u001b[0m  0.3340\n",
      "      8        \u001b[36m0.6076\u001b[0m       0.7240        \u001b[35m0.6456\u001b[0m  0.2949\n",
      "      9        \u001b[36m0.6062\u001b[0m       \u001b[32m0.7270\u001b[0m        \u001b[35m0.6451\u001b[0m  0.3000\n",
      "     10        \u001b[36m0.6040\u001b[0m       \u001b[32m0.7330\u001b[0m        \u001b[35m0.6325\u001b[0m  0.3053\n",
      "     11        \u001b[36m0.6009\u001b[0m       0.7235        0.6379  0.3036\n",
      "     12        \u001b[36m0.5972\u001b[0m       0.7275        0.6476  0.3015\n",
      "     13        \u001b[36m0.5958\u001b[0m       0.7290        0.6385  0.3025\n",
      "     14        \u001b[36m0.5931\u001b[0m       0.7300        0.6376  0.3040\n",
      "     15        \u001b[36m0.5899\u001b[0m       0.7295        0.6403  0.3060\n",
      "     16        0.5902       \u001b[32m0.7340\u001b[0m        0.6357  0.3084\n",
      "     17        \u001b[36m0.5873\u001b[0m       0.7250        0.6394  0.3131\n",
      "     18        \u001b[36m0.5870\u001b[0m       0.7315        0.6403  0.3119\n",
      "     19        0.5878       0.7285        \u001b[35m0.6275\u001b[0m  0.3173\n",
      "     20        0.5873       0.7325        \u001b[35m0.6220\u001b[0m  0.2994\n",
      "     21        \u001b[36m0.5858\u001b[0m       0.7320        0.6315  0.3062\n",
      "     22        \u001b[36m0.5834\u001b[0m       0.7335        0.6228  0.3059\n",
      "     23        \u001b[36m0.5818\u001b[0m       0.7340        0.6400  0.3072\n",
      "     24        \u001b[36m0.5805\u001b[0m       0.7315        0.6326  0.3043\n",
      "     25        \u001b[36m0.5788\u001b[0m       0.7290        0.6383  0.3487\n",
      "     26        \u001b[36m0.5781\u001b[0m       0.7320        0.6421  0.3026\n",
      "     27        \u001b[36m0.5766\u001b[0m       0.7315        0.6268  0.2989\n",
      "     28        \u001b[36m0.5748\u001b[0m       0.7300        0.6376  0.3073\n",
      "     29        \u001b[36m0.5740\u001b[0m       0.7305        0.6460  0.3015\n",
      "     30        \u001b[36m0.5732\u001b[0m       0.7250        0.6359  0.3053\n",
      "     31        \u001b[36m0.5727\u001b[0m       0.7340        0.6530  0.3290\n",
      "     32        \u001b[36m0.5713\u001b[0m       0.7325        0.6408  0.3148\n",
      "     33        0.5726       0.7340        0.6346  0.3099\n",
      "     34        \u001b[36m0.5686\u001b[0m       0.7305        0.6394  0.3037\n",
      "     35        \u001b[36m0.5683\u001b[0m       0.7245        0.6619  0.3062\n",
      "     36        0.5692       \u001b[32m0.7345\u001b[0m        0.6457  0.3036\n",
      "     37        \u001b[36m0.5674\u001b[0m       \u001b[32m0.7365\u001b[0m        0.6490  0.3361\n",
      "     38        \u001b[36m0.5648\u001b[0m       0.7345        0.6390  0.3254\n",
      "     39        \u001b[36m0.5640\u001b[0m       0.7350        0.6417  0.3045\n",
      "     40        0.5641       0.7345        0.6426  0.3085\n",
      "     41        \u001b[36m0.5619\u001b[0m       0.7280        0.6373  0.3174\n",
      "     42        \u001b[36m0.5609\u001b[0m       0.7340        0.6348  0.3151\n",
      "     43        0.5619       0.7325        0.6315  0.3138\n",
      "     44        0.5634       \u001b[32m0.7385\u001b[0m        0.6317  0.3090\n",
      "     45        0.5616       0.7350        0.6478  0.3076\n",
      "     46        \u001b[36m0.5595\u001b[0m       0.7375        0.6350  0.3074\n",
      "     47        0.5596       0.7235        0.6517  0.3094\n",
      "     48        0.5596       0.7335        0.6431  0.3061\n",
      "     49        \u001b[36m0.5580\u001b[0m       0.7350        0.6371  0.3113\n",
      "     50        \u001b[36m0.5572\u001b[0m       0.7375        0.6431  0.3095\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;dtf&#x27;,\n",
       "                                        &lt;__main__.Data_Transformer object at 0x000001B639D04350&gt;),\n",
       "                                       (&#x27;rescale&#x27;,\n",
       "                                        &lt;__main__.CustomScaler object at 0x000001B639774390&gt;),\n",
       "                                       (&#x27;nn_model&#x27;,\n",
       "                                        &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       "))]),\n",
       "             param_grid={&#x27;nn_model__batch_size&#x27;: [32, 64],\n",
       "                         &#x27;nn_model__lr&#x27;: [0.01, 0.1],\n",
       "                         &#x27;nn_model__max_epochs&#x27;: [10, 50, 100],\n",
       "                         &#x27;nn_model__optimizer&#x27;: [&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;,\n",
       "                                                 &lt;class &#x27;torch.optim.rmsprop.RMSprop&#x27;&gt;]},\n",
       "             scoring=make_scorer(recall_score, average=micro))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;dtf&#x27;,\n",
       "                                        &lt;__main__.Data_Transformer object at 0x000001B639D04350&gt;),\n",
       "                                       (&#x27;rescale&#x27;,\n",
       "                                        &lt;__main__.CustomScaler object at 0x000001B639774390&gt;),\n",
       "                                       (&#x27;nn_model&#x27;,\n",
       "                                        &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       "))]),\n",
       "             param_grid={&#x27;nn_model__batch_size&#x27;: [32, 64],\n",
       "                         &#x27;nn_model__lr&#x27;: [0.01, 0.1],\n",
       "                         &#x27;nn_model__max_epochs&#x27;: [10, 50, 100],\n",
       "                         &#x27;nn_model__optimizer&#x27;: [&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;,\n",
       "                                                 &lt;class &#x27;torch.optim.rmsprop.RMSprop&#x27;&gt;]},\n",
       "             scoring=make_scorer(recall_score, average=micro))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;dtf&#x27;,\n",
       "                 &lt;__main__.Data_Transformer object at 0x000001B639D04350&gt;),\n",
       "                (&#x27;rescale&#x27;,\n",
       "                 &lt;__main__.CustomScaler object at 0x000001B639774390&gt;),\n",
       "                (&#x27;nn_model&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Data_Transformer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.Data_Transformer object at 0x000001B639D04350&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomScaler</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.CustomScaler object at 0x000001B639774390&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('dtf',\n",
       "                                        <__main__.Data_Transformer object at 0x000001B639D04350>),\n",
       "                                       ('rescale',\n",
       "                                        <__main__.CustomScaler object at 0x000001B639774390>),\n",
       "                                       ('nn_model',\n",
       "                                        <class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=<class '__main__.NeuralNetwork'>,\n",
       "))]),\n",
       "             param_grid={'nn_model__batch_size': [32, 64],\n",
       "                         'nn_model__lr': [0.01, 0.1],\n",
       "                         'nn_model__max_epochs': [10, 50, 100],\n",
       "                         'nn_model__optimizer': [<class 'torch.optim.adam.Adam'>,\n",
       "                                                 <class 'torch.optim.rmsprop.RMSprop'>]},\n",
       "             scoring=make_scorer(recall_score, average=micro))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gsv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn_model__batch_size': 32,\n",
       " 'nn_model__lr': 0.01,\n",
       " 'nn_model__max_epochs': 50,\n",
       " 'nn_model__optimizer': torch.optim.adam.Adam}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gsv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_nn_model__batch_size</th>\n",
       "      <th>param_nn_model__max_epochs</th>\n",
       "      <th>param_nn_model__optimizer</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.7224</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.7288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.7017</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.5683</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.7035</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.7078</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.7098</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.6651</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_nn_model__batch_size param_nn_model__max_epochs  \\\n",
       "0                          32                         10   \n",
       "1                          32                         10   \n",
       "2                          32                         50   \n",
       "3                          32                         50   \n",
       "4                          32                        100   \n",
       "5                          32                        100   \n",
       "6                          32                         10   \n",
       "7                          32                         10   \n",
       "8                          32                         50   \n",
       "9                          32                         50   \n",
       "10                         32                        100   \n",
       "11                         32                        100   \n",
       "12                         64                         10   \n",
       "13                         64                         10   \n",
       "14                         64                         50   \n",
       "15                         64                         50   \n",
       "16                         64                        100   \n",
       "17                         64                        100   \n",
       "18                         64                         10   \n",
       "19                         64                         10   \n",
       "20                         64                         50   \n",
       "21                         64                         50   \n",
       "22                         64                        100   \n",
       "23                         64                        100   \n",
       "\n",
       "                param_nn_model__optimizer  mean_test_score  rank_test_score  \n",
       "0         <class 'torch.optim.adam.Adam'>           0.7224                3  \n",
       "1   <class 'torch.optim.rmsprop.RMSprop'>           0.6990               12  \n",
       "2         <class 'torch.optim.adam.Adam'>           0.7288                1  \n",
       "3   <class 'torch.optim.rmsprop.RMSprop'>           0.6954               13  \n",
       "4         <class 'torch.optim.adam.Adam'>           0.7067                9  \n",
       "5   <class 'torch.optim.rmsprop.RMSprop'>           0.7017               11  \n",
       "6         <class 'torch.optim.adam.Adam'>           0.5683               18  \n",
       "7   <class 'torch.optim.rmsprop.RMSprop'>           0.3340               19  \n",
       "8         <class 'torch.optim.adam.Adam'>           0.6399               15  \n",
       "9   <class 'torch.optim.rmsprop.RMSprop'>           0.3340               19  \n",
       "10        <class 'torch.optim.adam.Adam'>           0.6196               16  \n",
       "11  <class 'torch.optim.rmsprop.RMSprop'>           0.3340               19  \n",
       "12        <class 'torch.optim.adam.Adam'>           0.7287                2  \n",
       "13  <class 'torch.optim.rmsprop.RMSprop'>           0.7035               10  \n",
       "14        <class 'torch.optim.adam.Adam'>           0.7133                5  \n",
       "15  <class 'torch.optim.rmsprop.RMSprop'>           0.7078                8  \n",
       "16        <class 'torch.optim.adam.Adam'>           0.7153                4  \n",
       "17  <class 'torch.optim.rmsprop.RMSprop'>           0.7098                6  \n",
       "18        <class 'torch.optim.adam.Adam'>           0.7085                7  \n",
       "19  <class 'torch.optim.rmsprop.RMSprop'>           0.3340               19  \n",
       "20        <class 'torch.optim.adam.Adam'>           0.6651               14  \n",
       "21  <class 'torch.optim.rmsprop.RMSprop'>           0.3340               19  \n",
       "22        <class 'torch.optim.adam.Adam'>           0.6016               17  \n",
       "23  <class 'torch.optim.rmsprop.RMSprop'>           0.3340               19  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model_gsv.cv_results_\n",
    "result = pd.DataFrame(result)[['param_nn_model__batch_size', 'param_nn_model__max_epochs', 'param_nn_model__optimizer', 'mean_test_score', 'rank_test_score']]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_gsv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       822\n",
      "           1       0.74      0.82      0.78      1217\n",
      "           2       0.69      0.59      0.63       461\n",
      "\n",
      "    accuracy                           0.75      2500\n",
      "   macro avg       0.74      0.71      0.72      2500\n",
      "weighted avg       0.75      0.75      0.75      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[604, 185,  33],\n",
       "       [133, 994,  90],\n",
       "       [ 30, 161, 270]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_proba = model_gsv.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Receiver Operating Characteristic - NeuralNetworkClassifier (PyTorch)')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for class_idx in range(len(model_gsv.best_estimator_.classes_)):\n",
    "    y_true = (y_test == model_gsv.best_estimator_.classes_[class_idx]).astype(int)\n",
    "    y_pred_proba = y_test_pred_proba[:, class_idx]\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'Class {model_gsv.best_estimator_.classes_[class_idx]} (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - NeuralNetworkClassifier (PyTorch)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
