{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df.dropna(subset=['Credit_Score'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = df.columns.tolist()\n",
    "x_columns.remove('Credit_Score')\n",
    "X = df[x_columns]\n",
    "y = df['Credit_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class Data_Transformer(object):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.mean_age = X[\"Age\"].mean()\n",
    "        self.occu_le = LabelEncoder() # create label-encoder\n",
    "        encoded_occupation = pd.Series(self.occu_le.fit_transform(X[\"Occupation\"])) # fit and transform occupation with label-encoder\n",
    "        self.majority_occupation = encoded_occupation.mode()[0] # obtain majority occupation code\n",
    "        self.mean_annual_income = X[\"Annual_Income\"].mean()\n",
    "        self.mean_monthly_inhand_salary = X[\"Monthly_Inhand_Salary\"].mean()\n",
    "        self.mean_num_bank_accounts = X[\"Num_Bank_Accounts\"].mean()\n",
    "        self.mean_num_creadit_card = X[\"Num_Credit_Card\"].mean()\n",
    "        self.mean_num_interest_rate = X['Interest_Rate'].mean()\n",
    "        self.mean_num_of_loan = X['Num_of_Loan'].mean()\n",
    "        self.mean_delay_from_due_date = X['Delay_from_due_date'].mean()\n",
    "        self.mean_num_of_delayed_payment = X['Num_of_Delayed_Payment'].mean()\n",
    "        self.mean_changed_credit_limit = X['Changed_Credit_Limit'].mean()\n",
    "        self.mean_num_credit_inquiries = X['Num_Credit_Inquiries'].mean()\n",
    "        self.cm_le = LabelEncoder() # create label-encoder\n",
    "        encoded_credit_mix = pd.Series(self.cm_le.fit_transform(X[\"Credit_Mix\"])) # fit and transform credit mix with label-encoder\n",
    "        self.majority_credit_mix = encoded_credit_mix.mode()[0] # obtain majority credit mix code\n",
    "        self.mean_outstanding_debt = X['Outstanding_Debt'].mean()\n",
    "        self.mean_credit_history_age = X['Credit_History_Age'].mean()\n",
    "        self.pma_le = LabelEncoder() # create label-encoder\n",
    "        encoded_payment_of_min_amount = pd.Series(self.pma_le.fit_transform(X[\"Payment_of_Min_Amount\"])) # fit and transform payment of min amount with label-encoder\n",
    "        self.majority_payment_of_min_amount = encoded_payment_of_min_amount.mode()[0] # obtain majority payment of min amount\n",
    "        self.mean_total_EMI_per_month = X['Total_EMI_per_month'].mean()\n",
    "        self.mean_amount_invested_monthly = X['Amount_invested_monthly'].mean()\n",
    "        self.pb_le = LabelEncoder() # create label-encoder\n",
    "        encoded_payment_behaviour = pd.Series(self.pb_le.fit_transform(X[\"Payment_Behaviour\"])) # fit and transform payment behaviour with label-encoder\n",
    "        self.majority_payment_behaviour = encoded_payment_behaviour.mode()[0] # obtain majority payment behaviour\n",
    "        self.mean_monthly_balance = X['Monthly_Balance'].mean()\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Age\"] = X[\"Age\"]\n",
    "        new_df[\"Age\"].fillna(self.mean_age,inplace=True)\n",
    "        new_df[\"Occupation\"] = self.occu_le.transform(X[\"Occupation\"])\n",
    "        new_df[\"Occupation\"].fillna(self.majority_occupation,inplace=True)\n",
    "        new_df[\"Annual_Income\"] = X[\"Annual_Income\"]\n",
    "        new_df[\"Annual_Income\"].fillna(self.mean_annual_income,inplace=True)\n",
    "        new_df[\"Monthly_Inhand_Salary\"] = X[\"Monthly_Inhand_Salary\"]\n",
    "        new_df[\"Monthly_Inhand_Salary\"].fillna(self.mean_monthly_inhand_salary,inplace=True)\n",
    "        new_df[\"Num_Bank_Accounts\"] = X[\"Num_Bank_Accounts\"]\n",
    "        new_df[\"Num_Bank_Accounts\"].fillna(self.mean_num_bank_accounts,inplace=True)\n",
    "        new_df[\"Num_Credit_Card\"] = X[\"Num_Credit_Card\"]\n",
    "        new_df[\"Num_Credit_Card\"].fillna(self.mean_num_creadit_card,inplace=True)\n",
    "        new_df[\"Interest_Rate\"] = X[\"Interest_Rate\"]\n",
    "        new_df[\"Interest_Rate\"].fillna(self.mean_num_interest_rate,inplace=True)\n",
    "        new_df[\"Num_of_Loan\"] = X[\"Num_of_Loan\"]\n",
    "        new_df[\"Num_of_Loan\"].fillna(self.mean_num_of_loan,inplace=True)\n",
    "        new_df[\"Delay_from_due_date\"] = X[\"Delay_from_due_date\"]\n",
    "        new_df[\"Delay_from_due_date\"].fillna(self.mean_delay_from_due_date,inplace=True)\n",
    "        new_df[\"Num_of_Delayed_Payment\"] = X[\"Num_of_Delayed_Payment\"]\n",
    "        new_df[\"Num_of_Delayed_Payment\"].fillna(self.mean_num_of_delayed_payment,inplace=True)\n",
    "        new_df[\"Changed_Credit_Limit\"] = X[\"Changed_Credit_Limit\"]\n",
    "        new_df[\"Changed_Credit_Limit\"].fillna(self.mean_changed_credit_limit,inplace=True)\n",
    "        new_df[\"Num_Credit_Inquiries\"] = X[\"Num_Credit_Inquiries\"]\n",
    "        new_df[\"Num_Credit_Inquiries\"].fillna(self.mean_num_credit_inquiries,inplace=True)\n",
    "        new_df[\"Credit_Mix\"] = self.cm_le.transform(X[\"Credit_Mix\"])\n",
    "        new_df[\"Credit_Mix\"].fillna(self.majority_credit_mix,inplace=True)\n",
    "        new_df[\"Outstanding_Debt\"] = X[\"Outstanding_Debt\"]\n",
    "        new_df[\"Outstanding_Debt\"].fillna(self.mean_outstanding_debt,inplace=True)\n",
    "        new_df[\"Credit_History_Age\"] = X[\"Credit_History_Age\"]\n",
    "        new_df[\"Credit_History_Age\"].fillna(self.mean_credit_history_age,inplace=True)\n",
    "        new_df[\"Payment_of_Min_Amount\"] = self.pma_le.transform(X[\"Payment_of_Min_Amount\"])\n",
    "        new_df[\"Payment_of_Min_Amount\"].fillna(self.majority_payment_of_min_amount,inplace=True)\n",
    "        new_df[\"Total_EMI_per_month\"] = X[\"Total_EMI_per_month\"]\n",
    "        new_df[\"Total_EMI_per_month\"].fillna(self.mean_total_EMI_per_month,inplace=True)\n",
    "        new_df[\"Amount_invested_monthly\"] = X[\"Amount_invested_monthly\"]\n",
    "        new_df[\"Amount_invested_monthly\"].fillna(self.mean_amount_invested_monthly,inplace=True)\n",
    "        new_df[\"Payment_Behaviour\"] = self.pb_le.transform(X[\"Payment_Behaviour\"])\n",
    "        new_df[\"Payment_Behaviour\"].fillna(self.majority_payment_behaviour,inplace=True)\n",
    "        new_df[\"Monthly_Balance\"] = X[\"Monthly_Balance\"]\n",
    "        new_df[\"Monthly_Balance\"].fillna(self.mean_monthly_balance,inplace=True)\n",
    "        return new_df\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch.classifier import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 3)\n",
    "        #If binary classification, last layer outputs 2 values\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.softmax(self.fc3(x), dim=1)\n",
    "        #If binary classification, last layer uses nn.functional.sigmoid\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler():\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = self.scaler.transform(X)\n",
    "        return torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps =[('dtf', Data_Transformer()),\n",
    "        ('rescale', CustomScaler()),\n",
    "        ('nn_model', NeuralNetClassifier(module=NeuralNetwork, device='cuda' if torch.cuda.is_available() else 'cpu'))]\n",
    "        #If binary classification, nn_model uses NeuralNetBinaryClassifier \n",
    "model = Pipeline(steps)\n",
    "param_grid = {'nn_model__batch_size': [32, 64],\n",
    "                'nn_model__max_epochs': [10, 50, 100],\n",
    "                'nn_model__lr': [0.01, 0.1],\n",
    "                'nn_model__optimizer': [optim.Adam, optim.RMSprop]}\n",
    "model_gsv = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, scoring=make_scorer(f1_score, average='macro', greater_is_better=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8196\u001b[0m       \u001b[32m0.6460\u001b[0m        \u001b[35m0.7451\u001b[0m  0.1775\n",
      "      2        \u001b[36m0.7094\u001b[0m       \u001b[32m0.6730\u001b[0m        \u001b[35m0.6973\u001b[0m  0.1430\n",
      "      3        \u001b[36m0.6708\u001b[0m       \u001b[32m0.6880\u001b[0m        \u001b[35m0.6958\u001b[0m  0.1415\n",
      "      4        \u001b[36m0.6587\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6902\u001b[0m  0.1440\n",
      "      5        \u001b[36m0.6498\u001b[0m       0.6830        \u001b[35m0.6884\u001b[0m  0.1395\n",
      "      6        \u001b[36m0.6424\u001b[0m       0.6900        \u001b[35m0.6818\u001b[0m  0.1400\n",
      "      7        \u001b[36m0.6344\u001b[0m       0.6780        0.6927  0.1475\n",
      "      8        \u001b[36m0.6339\u001b[0m       0.6780        0.7048  0.1530\n",
      "      9        \u001b[36m0.6291\u001b[0m       0.6800        0.6849  0.1475\n",
      "     10        \u001b[36m0.6196\u001b[0m       0.6880        \u001b[35m0.6791\u001b[0m  0.1530\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7848\u001b[0m       \u001b[32m0.6570\u001b[0m        \u001b[35m0.7211\u001b[0m  0.1485\n",
      "      2        \u001b[36m0.6690\u001b[0m       \u001b[32m0.6850\u001b[0m        \u001b[35m0.7142\u001b[0m  0.1420\n",
      "      3        \u001b[36m0.6389\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.6820\u001b[0m  0.1355\n",
      "      4        \u001b[36m0.6263\u001b[0m       \u001b[32m0.7330\u001b[0m        \u001b[35m0.6373\u001b[0m  0.1385\n",
      "      5        \u001b[36m0.6190\u001b[0m       \u001b[32m0.7470\u001b[0m        \u001b[35m0.6280\u001b[0m  0.1500\n",
      "      6        \u001b[36m0.6151\u001b[0m       0.7430        0.6320  0.1485\n",
      "      7        \u001b[36m0.6146\u001b[0m       \u001b[32m0.7520\u001b[0m        \u001b[35m0.6173\u001b[0m  0.1520\n",
      "      8        \u001b[36m0.6100\u001b[0m       \u001b[32m0.7540\u001b[0m        0.6184  0.1485\n",
      "      9        \u001b[36m0.6049\u001b[0m       0.7540        \u001b[35m0.6127\u001b[0m  0.1570\n",
      "     10        0.6050       \u001b[32m0.7570\u001b[0m        \u001b[35m0.6123\u001b[0m  0.1490\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8113\u001b[0m       \u001b[32m0.6960\u001b[0m        \u001b[35m0.7030\u001b[0m  0.1300\n",
      "      2        \u001b[36m0.6702\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6578\u001b[0m  0.1275\n",
      "      3        \u001b[36m0.6426\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6554\u001b[0m  0.1265\n",
      "      4        \u001b[36m0.6318\u001b[0m       0.7150        \u001b[35m0.6537\u001b[0m  0.1290\n",
      "      5        \u001b[36m0.6250\u001b[0m       \u001b[32m0.7170\u001b[0m        \u001b[35m0.6482\u001b[0m  0.1295\n",
      "      6        \u001b[36m0.6194\u001b[0m       0.7170        \u001b[35m0.6417\u001b[0m  0.1295\n",
      "      7        \u001b[36m0.6129\u001b[0m       \u001b[32m0.7280\u001b[0m        0.6432  0.1260\n",
      "      8        \u001b[36m0.6083\u001b[0m       0.7220        \u001b[35m0.6398\u001b[0m  0.1365\n",
      "      9        \u001b[36m0.6045\u001b[0m       0.7240        0.6423  0.1245\n",
      "     10        \u001b[36m0.5995\u001b[0m       0.7240        \u001b[35m0.6366\u001b[0m  0.1295\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8109\u001b[0m       \u001b[32m0.4980\u001b[0m        \u001b[35m1.2232\u001b[0m  0.1200\n",
      "      2        \u001b[36m0.6841\u001b[0m       \u001b[32m0.5270\u001b[0m        \u001b[35m1.0470\u001b[0m  0.1265\n",
      "      3        \u001b[36m0.6499\u001b[0m       \u001b[32m0.5490\u001b[0m        \u001b[35m0.9356\u001b[0m  0.1295\n",
      "      4        \u001b[36m0.6376\u001b[0m       \u001b[32m0.5820\u001b[0m        \u001b[35m0.8704\u001b[0m  0.1420\n",
      "      5        \u001b[36m0.6295\u001b[0m       \u001b[32m0.5880\u001b[0m        \u001b[35m0.8475\u001b[0m  0.1395\n",
      "      6        \u001b[36m0.6241\u001b[0m       \u001b[32m0.5970\u001b[0m        \u001b[35m0.8190\u001b[0m  0.1265\n",
      "      7        \u001b[36m0.6197\u001b[0m       \u001b[32m0.6040\u001b[0m        \u001b[35m0.8070\u001b[0m  0.1301\n",
      "      8        \u001b[36m0.6140\u001b[0m       \u001b[32m0.6290\u001b[0m        \u001b[35m0.7934\u001b[0m  0.1295\n",
      "      9        \u001b[36m0.6116\u001b[0m       \u001b[32m0.6340\u001b[0m        \u001b[35m0.7820\u001b[0m  0.1325\n",
      "     10        \u001b[36m0.6111\u001b[0m       0.6210        0.8005  0.1270\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8102\u001b[0m       \u001b[32m0.6540\u001b[0m        \u001b[35m0.7558\u001b[0m  0.1440\n",
      "      2        \u001b[36m0.7018\u001b[0m       \u001b[32m0.6800\u001b[0m        \u001b[35m0.6949\u001b[0m  0.1435\n",
      "      3        \u001b[36m0.6685\u001b[0m       \u001b[32m0.6840\u001b[0m        \u001b[35m0.6858\u001b[0m  0.1460\n",
      "      4        \u001b[36m0.6490\u001b[0m       0.6780        0.7005  0.1345\n",
      "      5        \u001b[36m0.6423\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.6761\u001b[0m  0.1440\n",
      "      6        \u001b[36m0.6341\u001b[0m       0.6990        0.6845  0.1385\n",
      "      7        \u001b[36m0.6299\u001b[0m       \u001b[32m0.7040\u001b[0m        \u001b[35m0.6727\u001b[0m  0.1540\n",
      "      8        \u001b[36m0.6231\u001b[0m       0.7040        0.6746  0.1595\n",
      "      9        \u001b[36m0.6198\u001b[0m       \u001b[32m0.7090\u001b[0m        0.6808  0.1460\n",
      "     10        \u001b[36m0.6171\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.6687\u001b[0m  0.1505\n",
      "     11        \u001b[36m0.6113\u001b[0m       0.7120        \u001b[35m0.6674\u001b[0m  0.1500\n",
      "     12        \u001b[36m0.6095\u001b[0m       0.7040        \u001b[35m0.6660\u001b[0m  0.1525\n",
      "     13        0.6128       0.7140        \u001b[35m0.6503\u001b[0m  0.1530\n",
      "     14        \u001b[36m0.6059\u001b[0m       0.7090        0.6662  0.1525\n",
      "     15        \u001b[36m0.6037\u001b[0m       \u001b[32m0.7180\u001b[0m        0.6767  0.1540\n",
      "     16        \u001b[36m0.6022\u001b[0m       0.7140        0.6773  0.1570\n",
      "     17        \u001b[36m0.6013\u001b[0m       \u001b[32m0.7270\u001b[0m        0.6582  0.1505\n",
      "     18        \u001b[36m0.5956\u001b[0m       0.7240        0.6671  0.1516\n",
      "     19        \u001b[36m0.5948\u001b[0m       0.7220        0.6544  0.1615\n",
      "     20        \u001b[36m0.5930\u001b[0m       0.7200        0.6512  0.1490\n",
      "     21        \u001b[36m0.5903\u001b[0m       0.7220        0.6635  0.1515\n",
      "     22        \u001b[36m0.5863\u001b[0m       \u001b[32m0.7290\u001b[0m        0.6803  0.1510\n",
      "     23        0.5864       0.7170        0.6562  0.1485\n",
      "     24        \u001b[36m0.5858\u001b[0m       \u001b[32m0.7330\u001b[0m        0.6642  0.1570\n",
      "     25        \u001b[36m0.5841\u001b[0m       0.7100        0.6955  0.1535\n",
      "     26        0.5870       0.7160        0.6713  0.1470\n",
      "     27        \u001b[36m0.5816\u001b[0m       0.7030        0.6946  0.1550\n",
      "     28        0.5825       0.7120        0.6929  0.1475\n",
      "     29        \u001b[36m0.5793\u001b[0m       0.7150        0.6895  0.1510\n",
      "     30        \u001b[36m0.5781\u001b[0m       0.7090        0.7082  0.1545\n",
      "     31        \u001b[36m0.5756\u001b[0m       0.7100        0.7264  0.1690\n",
      "     32        0.5774       0.7210        0.7068  0.1585\n",
      "     33        0.5761       0.7150        0.7239  0.1610\n",
      "     34        \u001b[36m0.5741\u001b[0m       0.7190        0.6886  0.1790\n",
      "     35        \u001b[36m0.5709\u001b[0m       0.7160        0.6714  0.1595\n",
      "     36        \u001b[36m0.5682\u001b[0m       0.7110        0.7126  0.1620\n",
      "     37        0.5690       0.7100        0.6937  0.1570\n",
      "     38        0.5706       0.7180        0.6718  0.1635\n",
      "     39        \u001b[36m0.5681\u001b[0m       0.7160        0.7100  0.1570\n",
      "     40        0.5706       0.7240        0.7091  0.1587\n",
      "     41        \u001b[36m0.5679\u001b[0m       0.7200        0.6711  0.1725\n",
      "     42        \u001b[36m0.5634\u001b[0m       0.7160        0.7019  0.1580\n",
      "     43        \u001b[36m0.5615\u001b[0m       0.7160        0.7110  0.1565\n",
      "     44        0.5683       0.7180        0.7105  0.1650\n",
      "     45        0.5632       0.7080        0.7065  0.1630\n",
      "     46        \u001b[36m0.5603\u001b[0m       0.7170        0.6986  0.1695\n",
      "     47        0.5626       0.7080        0.7138  0.1680\n",
      "     48        0.5636       0.7280        0.6982  0.1750\n",
      "     49        \u001b[36m0.5572\u001b[0m       0.7260        0.7110  0.1616\n",
      "     50        0.5588       0.7150        0.7140  0.1685\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7584\u001b[0m       \u001b[32m0.6930\u001b[0m        \u001b[35m0.7161\u001b[0m  0.1560\n",
      "      2        \u001b[36m0.6669\u001b[0m       \u001b[32m0.7330\u001b[0m        \u001b[35m0.6540\u001b[0m  0.1475\n",
      "      3        \u001b[36m0.6367\u001b[0m       \u001b[32m0.7470\u001b[0m        \u001b[35m0.6336\u001b[0m  0.1410\n",
      "      4        \u001b[36m0.6260\u001b[0m       0.7460        \u001b[35m0.6303\u001b[0m  0.1465\n",
      "      5        \u001b[36m0.6195\u001b[0m       0.7460        \u001b[35m0.6207\u001b[0m  0.1470\n",
      "      6        \u001b[36m0.6134\u001b[0m       0.7470        \u001b[35m0.6202\u001b[0m  0.1512\n",
      "      7        \u001b[36m0.6084\u001b[0m       0.7460        \u001b[35m0.6128\u001b[0m  0.1520\n",
      "      8        \u001b[36m0.6057\u001b[0m       0.7440        0.6194  0.1522\n",
      "      9        \u001b[36m0.6045\u001b[0m       \u001b[32m0.7510\u001b[0m        0.6153  0.1500\n",
      "     10        \u001b[36m0.6029\u001b[0m       \u001b[32m0.7540\u001b[0m        0.6159  0.1555\n",
      "     11        \u001b[36m0.5997\u001b[0m       0.7520        0.6172  0.1600\n",
      "     12        \u001b[36m0.5975\u001b[0m       0.7480        0.6271  0.1580\n",
      "     13        0.6002       0.7420        0.6413  0.1505\n",
      "     14        \u001b[36m0.5955\u001b[0m       0.7520        0.6275  0.1610\n",
      "     15        0.5962       0.7430        0.6405  0.1685\n",
      "     16        0.5960       0.7510        0.6194  0.1550\n",
      "     17        0.5967       \u001b[32m0.7590\u001b[0m        0.6131  0.1620\n",
      "     18        \u001b[36m0.5917\u001b[0m       0.7510        0.6151  0.1555\n",
      "     19        \u001b[36m0.5895\u001b[0m       0.7510        0.6289  0.1550\n",
      "     20        0.5923       0.7480        0.6153  0.1665\n",
      "     21        \u001b[36m0.5884\u001b[0m       0.7540        \u001b[35m0.6112\u001b[0m  0.1610\n",
      "     22        \u001b[36m0.5862\u001b[0m       0.7530        \u001b[35m0.6067\u001b[0m  0.1540\n",
      "     23        \u001b[36m0.5813\u001b[0m       0.7550        \u001b[35m0.6028\u001b[0m  0.1595\n",
      "     24        \u001b[36m0.5795\u001b[0m       0.7580        0.6073  0.1560\n",
      "     25        0.5849       \u001b[32m0.7650\u001b[0m        \u001b[35m0.6000\u001b[0m  0.1605\n",
      "     26        \u001b[36m0.5786\u001b[0m       \u001b[32m0.7690\u001b[0m        0.6018  0.1610\n",
      "     27        \u001b[36m0.5771\u001b[0m       0.7630        \u001b[35m0.5985\u001b[0m  0.1700\n",
      "     28        \u001b[36m0.5764\u001b[0m       0.7560        0.6037  0.1655\n",
      "     29        \u001b[36m0.5761\u001b[0m       0.7590        0.6060  0.1505\n",
      "     30        \u001b[36m0.5749\u001b[0m       0.7640        0.6003  0.1580\n",
      "     31        \u001b[36m0.5734\u001b[0m       \u001b[32m0.7700\u001b[0m        \u001b[35m0.5947\u001b[0m  0.1545\n",
      "     32        \u001b[36m0.5661\u001b[0m       0.7530        0.6084  0.1680\n",
      "     33        0.5697       0.7610        0.6027  0.1575\n",
      "     34        \u001b[36m0.5660\u001b[0m       0.7670        0.6028  0.1550\n",
      "     35        \u001b[36m0.5651\u001b[0m       0.7600        0.6090  0.1620\n",
      "     36        \u001b[36m0.5645\u001b[0m       0.7560        0.6162  0.1645\n",
      "     37        \u001b[36m0.5609\u001b[0m       0.7320        0.6314  0.1600\n",
      "     38        0.5615       0.7630        0.6095  0.1525\n",
      "     39        \u001b[36m0.5574\u001b[0m       0.7580        0.6144  0.1565\n",
      "     40        \u001b[36m0.5551\u001b[0m       0.7430        0.6242  0.1550\n",
      "     41        0.5569       0.7550        0.6243  0.1615\n",
      "     42        \u001b[36m0.5512\u001b[0m       0.7510        0.6274  0.1570\n",
      "     43        0.5557       0.7470        0.6272  0.1600\n",
      "     44        0.5590       0.7520        0.6356  0.1525\n",
      "     45        0.5558       0.7550        0.6245  0.1581\n",
      "     46        0.5513       0.7490        0.6357  0.1643\n",
      "     47        0.5541       0.7480        0.6293  0.1510\n",
      "     48        0.5538       0.7430        0.6317  0.1525\n",
      "     49        \u001b[36m0.5466\u001b[0m       0.7470        0.6353  0.1579\n",
      "     50        \u001b[36m0.5448\u001b[0m       0.7590        0.6232  0.1666\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8295\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.7043\u001b[0m  0.1325\n",
      "      2        \u001b[36m0.6782\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6636\u001b[0m  0.1331\n",
      "      3        \u001b[36m0.6495\u001b[0m       \u001b[32m0.7190\u001b[0m        \u001b[35m0.6533\u001b[0m  0.1471\n",
      "      4        \u001b[36m0.6369\u001b[0m       \u001b[32m0.7200\u001b[0m        \u001b[35m0.6504\u001b[0m  0.1363\n",
      "      5        \u001b[36m0.6304\u001b[0m       \u001b[32m0.7230\u001b[0m        0.6519  0.1450\n",
      "      6        \u001b[36m0.6267\u001b[0m       0.7170        \u001b[35m0.6495\u001b[0m  0.1334\n",
      "      7        \u001b[36m0.6250\u001b[0m       0.7180        \u001b[35m0.6492\u001b[0m  0.1365\n",
      "      8        \u001b[36m0.6200\u001b[0m       0.7170        \u001b[35m0.6463\u001b[0m  0.1303\n",
      "      9        \u001b[36m0.6166\u001b[0m       0.7130        0.6482  0.1305\n",
      "     10        \u001b[36m0.6139\u001b[0m       0.7090        \u001b[35m0.6448\u001b[0m  0.1385\n",
      "     11        \u001b[36m0.6136\u001b[0m       0.7110        \u001b[35m0.6425\u001b[0m  0.1340\n",
      "     12        \u001b[36m0.6104\u001b[0m       0.7160        \u001b[35m0.6370\u001b[0m  0.1351\n",
      "     13        \u001b[36m0.6059\u001b[0m       \u001b[32m0.7270\u001b[0m        \u001b[35m0.6367\u001b[0m  0.1311\n",
      "     14        \u001b[36m0.6036\u001b[0m       \u001b[32m0.7290\u001b[0m        0.6376  0.1337\n",
      "     15        \u001b[36m0.6002\u001b[0m       0.7220        0.6397  0.1265\n",
      "     16        \u001b[36m0.5975\u001b[0m       0.7250        \u001b[35m0.6356\u001b[0m  0.1375\n",
      "     17        \u001b[36m0.5934\u001b[0m       0.7270        \u001b[35m0.6350\u001b[0m  0.1330\n",
      "     18        0.5937       0.7240        0.6356  0.1305\n",
      "     19        \u001b[36m0.5910\u001b[0m       0.7280        \u001b[35m0.6307\u001b[0m  0.1335\n",
      "     20        \u001b[36m0.5903\u001b[0m       0.7270        \u001b[35m0.6278\u001b[0m  0.1360\n",
      "     21        \u001b[36m0.5889\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.6223\u001b[0m  0.1305\n",
      "     22        \u001b[36m0.5884\u001b[0m       0.7260        0.6385  0.1315\n",
      "     23        \u001b[36m0.5867\u001b[0m       0.7180        0.6288  0.1430\n",
      "     24        \u001b[36m0.5835\u001b[0m       0.7190        0.6346  0.1355\n",
      "     25        \u001b[36m0.5819\u001b[0m       0.7220        0.6350  0.1460\n",
      "     26        \u001b[36m0.5809\u001b[0m       0.7210        0.6299  0.1345\n",
      "     27        \u001b[36m0.5798\u001b[0m       0.7160        0.6300  0.1410\n",
      "     28        \u001b[36m0.5787\u001b[0m       0.7240        0.6305  0.1345\n",
      "     29        \u001b[36m0.5767\u001b[0m       0.7190        0.6296  0.1315\n",
      "     30        \u001b[36m0.5765\u001b[0m       0.7250        0.6269  0.1320\n",
      "     31        \u001b[36m0.5742\u001b[0m       0.7190        0.6409  0.1385\n",
      "     32        \u001b[36m0.5722\u001b[0m       0.7210        0.6314  0.1265\n",
      "     33        \u001b[36m0.5713\u001b[0m       0.7140        0.6358  0.1410\n",
      "     34        \u001b[36m0.5706\u001b[0m       0.7270        0.6360  0.1425\n",
      "     35        \u001b[36m0.5688\u001b[0m       0.7160        0.6404  0.1315\n",
      "     36        \u001b[36m0.5681\u001b[0m       0.7150        0.6435  0.1430\n",
      "     37        \u001b[36m0.5667\u001b[0m       0.7270        0.6438  0.1455\n",
      "     38        0.5670       0.7170        0.6415  0.1380\n",
      "     39        \u001b[36m0.5610\u001b[0m       0.7190        0.6524  0.1315\n",
      "     40        0.5625       0.7110        0.6557  0.1380\n",
      "     41        0.5614       0.7150        0.6552  0.1305\n",
      "     42        \u001b[36m0.5597\u001b[0m       0.7170        0.6630  0.1425\n",
      "     43        \u001b[36m0.5587\u001b[0m       0.7080        0.6645  0.1340\n",
      "     44        0.5599       0.7150        0.6652  0.1325\n",
      "     45        \u001b[36m0.5579\u001b[0m       0.7140        0.6666  0.1325\n",
      "     46        \u001b[36m0.5566\u001b[0m       0.7130        0.6658  0.1391\n",
      "     47        \u001b[36m0.5553\u001b[0m       0.7160        0.6718  0.1365\n",
      "     48        \u001b[36m0.5549\u001b[0m       0.7170        0.6774  0.1440\n",
      "     49        0.5557       0.7180        0.6764  0.1402\n",
      "     50        \u001b[36m0.5544\u001b[0m       0.7190        0.6763  0.1365\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7961\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.4331\u001b[0m  0.1290\n",
      "      2        \u001b[36m0.6734\u001b[0m       \u001b[32m0.5180\u001b[0m        \u001b[35m0.9313\u001b[0m  0.1325\n",
      "      3        \u001b[36m0.6439\u001b[0m       \u001b[32m0.5560\u001b[0m        \u001b[35m0.8582\u001b[0m  0.1395\n",
      "      4        \u001b[36m0.6347\u001b[0m       \u001b[32m0.6120\u001b[0m        \u001b[35m0.8015\u001b[0m  0.1271\n",
      "      5        \u001b[36m0.6265\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.7837\u001b[0m  0.1325\n",
      "      6        \u001b[36m0.6207\u001b[0m       \u001b[32m0.6540\u001b[0m        \u001b[35m0.7591\u001b[0m  0.1335\n",
      "      7        \u001b[36m0.6157\u001b[0m       \u001b[32m0.6940\u001b[0m        \u001b[35m0.7333\u001b[0m  0.1360\n",
      "      8        \u001b[36m0.6106\u001b[0m       0.6890        0.7353  0.1335\n",
      "      9        \u001b[36m0.6070\u001b[0m       0.6880        0.7367  0.1355\n",
      "     10        \u001b[36m0.6047\u001b[0m       \u001b[32m0.7030\u001b[0m        \u001b[35m0.7236\u001b[0m  0.1371\n",
      "     11        \u001b[36m0.6024\u001b[0m       0.5950        0.9091  0.1325\n",
      "     12        0.6053       0.7020        \u001b[35m0.7079\u001b[0m  0.1360\n",
      "     13        \u001b[36m0.6002\u001b[0m       0.6980        \u001b[35m0.7046\u001b[0m  0.1495\n",
      "     14        \u001b[36m0.5985\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.7038\u001b[0m  0.1365\n",
      "     15        \u001b[36m0.5967\u001b[0m       0.7060        \u001b[35m0.7018\u001b[0m  0.1320\n",
      "     16        \u001b[36m0.5957\u001b[0m       0.6980        0.7081  0.1325\n",
      "     17        \u001b[36m0.5939\u001b[0m       0.7050        \u001b[35m0.6901\u001b[0m  0.1360\n",
      "     18        \u001b[36m0.5912\u001b[0m       0.7030        0.6909  0.1315\n",
      "     19        \u001b[36m0.5893\u001b[0m       0.7040        \u001b[35m0.6868\u001b[0m  0.1215\n",
      "     20        \u001b[36m0.5869\u001b[0m       0.7030        0.6877  0.1335\n",
      "     21        \u001b[36m0.5857\u001b[0m       0.7090        \u001b[35m0.6816\u001b[0m  0.1390\n",
      "     22        \u001b[36m0.5839\u001b[0m       \u001b[32m0.7130\u001b[0m        0.6886  0.1345\n",
      "     23        \u001b[36m0.5829\u001b[0m       0.6970        0.7086  0.1300\n",
      "     24        \u001b[36m0.5806\u001b[0m       0.6970        0.7048  0.1355\n",
      "     25        \u001b[36m0.5805\u001b[0m       0.7000        0.7080  0.1285\n",
      "     26        \u001b[36m0.5791\u001b[0m       0.7100        0.6883  0.1340\n",
      "     27        0.5799       0.7090        0.6840  0.1285\n",
      "     28        \u001b[36m0.5778\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6779\u001b[0m  0.1325\n",
      "     29        0.5786       0.7110        0.6976  0.1321\n",
      "     30        0.5779       \u001b[32m0.7180\u001b[0m        0.6839  0.1335\n",
      "     31        \u001b[36m0.5740\u001b[0m       0.7110        0.6992  0.1315\n",
      "     32        0.5747       0.7050        0.7014  0.1330\n",
      "     33        \u001b[36m0.5710\u001b[0m       0.6970        0.7090  0.1415\n",
      "     34        \u001b[36m0.5702\u001b[0m       0.6890        0.7314  0.1285\n",
      "     35        \u001b[36m0.5686\u001b[0m       0.6810        0.7319  0.1330\n",
      "     36        \u001b[36m0.5667\u001b[0m       0.6900        0.7205  0.1345\n",
      "     37        \u001b[36m0.5654\u001b[0m       0.6850        0.7194  0.1205\n",
      "     38        0.5655       0.7140        0.7113  0.1270\n",
      "     39        \u001b[36m0.5647\u001b[0m       0.7000        0.7051  0.1324\n",
      "     40        \u001b[36m0.5609\u001b[0m       0.7070        0.7211  0.1315\n",
      "     41        0.5616       0.6970        0.7110  0.1410\n",
      "     42        \u001b[36m0.5603\u001b[0m       0.6970        0.6992  0.1385\n",
      "     43        \u001b[36m0.5600\u001b[0m       0.6900        0.7465  0.1325\n",
      "     44        \u001b[36m0.5596\u001b[0m       0.7040        0.7078  0.1340\n",
      "     45        \u001b[36m0.5592\u001b[0m       0.7180        0.7163  0.1295\n",
      "     46        \u001b[36m0.5591\u001b[0m       \u001b[32m0.7220\u001b[0m        0.7215  0.1345\n",
      "     47        0.5602       0.7220        0.7149  0.1400\n",
      "     48        0.5600       0.7190        0.7266  0.1305\n",
      "     49        \u001b[36m0.5583\u001b[0m       0.7220        0.7156  0.1295\n",
      "     50        \u001b[36m0.5582\u001b[0m       0.7140        0.7162  0.1355\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7910\u001b[0m       \u001b[32m0.6440\u001b[0m        \u001b[35m0.7544\u001b[0m  0.1465\n",
      "      2        \u001b[36m0.6967\u001b[0m       \u001b[32m0.6910\u001b[0m        \u001b[35m0.6863\u001b[0m  0.1440\n",
      "      3        \u001b[36m0.6589\u001b[0m       0.6870        0.6922  0.1425\n",
      "      4        \u001b[36m0.6517\u001b[0m       \u001b[32m0.6940\u001b[0m        0.6882  0.1275\n",
      "      5        \u001b[36m0.6426\u001b[0m       \u001b[32m0.7000\u001b[0m        \u001b[35m0.6790\u001b[0m  0.1510\n",
      "      6        \u001b[36m0.6340\u001b[0m       0.6990        0.6903  0.1485\n",
      "      7        \u001b[36m0.6299\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6764\u001b[0m  0.1540\n",
      "      8        \u001b[36m0.6194\u001b[0m       0.7040        0.6767  0.1579\n",
      "      9        \u001b[36m0.6161\u001b[0m       \u001b[32m0.7200\u001b[0m        \u001b[35m0.6613\u001b[0m  0.1525\n",
      "     10        \u001b[36m0.6074\u001b[0m       \u001b[32m0.7220\u001b[0m        \u001b[35m0.6563\u001b[0m  0.1607\n",
      "     11        \u001b[36m0.6020\u001b[0m       0.7220        0.6610  0.1485\n",
      "     12        \u001b[36m0.5986\u001b[0m       0.7130        \u001b[35m0.6542\u001b[0m  0.1600\n",
      "     13        \u001b[36m0.5963\u001b[0m       0.7190        0.6606  0.1555\n",
      "     14        0.5980       0.7170        0.6629  0.1530\n",
      "     15        0.5968       0.7150        0.6697  0.1620\n",
      "     16        \u001b[36m0.5947\u001b[0m       \u001b[32m0.7250\u001b[0m        0.6660  0.1535\n",
      "     17        \u001b[36m0.5886\u001b[0m       0.7180        0.6677  0.1576\n",
      "     18        0.5890       0.7130        0.6710  0.1502\n",
      "     19        \u001b[36m0.5849\u001b[0m       0.7210        0.6773  0.1560\n",
      "     20        \u001b[36m0.5837\u001b[0m       0.7230        0.6699  0.1820\n",
      "     21        \u001b[36m0.5826\u001b[0m       0.7200        0.6694  0.1693\n",
      "     22        \u001b[36m0.5792\u001b[0m       0.7110        0.6576  0.1456\n",
      "     23        \u001b[36m0.5771\u001b[0m       0.7050        0.6769  0.1617\n",
      "     24        \u001b[36m0.5754\u001b[0m       0.7100        0.6688  0.1445\n",
      "     25        \u001b[36m0.5728\u001b[0m       0.7150        0.6648  0.1570\n",
      "     26        \u001b[36m0.5666\u001b[0m       0.7070        0.6784  0.1775\n",
      "     27        0.5675       0.7030        0.6888  0.1633\n",
      "     28        0.5695       0.7200        0.6824  0.1566\n",
      "     29        0.5709       \u001b[32m0.7280\u001b[0m        0.6749  0.1735\n",
      "     30        \u001b[36m0.5662\u001b[0m       0.7130        0.6815  0.1650\n",
      "     31        0.5693       0.7170        0.6753  0.1576\n",
      "     32        0.5675       0.7260        0.6734  0.1705\n",
      "     33        \u001b[36m0.5547\u001b[0m       0.7220        0.6763  0.1505\n",
      "     34        0.5579       0.7280        0.6752  0.1586\n",
      "     35        0.5599       \u001b[32m0.7310\u001b[0m        0.6986  0.1590\n",
      "     36        0.5604       0.7290        0.6810  0.1520\n",
      "     37        0.5602       0.7270        0.6586  0.1565\n",
      "     38        0.5585       0.7200        0.6870  0.1638\n",
      "     39        \u001b[36m0.5538\u001b[0m       \u001b[32m0.7400\u001b[0m        0.6738  0.1606\n",
      "     40        \u001b[36m0.5505\u001b[0m       0.7280        0.6919  0.1655\n",
      "     41        \u001b[36m0.5494\u001b[0m       0.7220        0.7016  0.1550\n",
      "     42        \u001b[36m0.5464\u001b[0m       0.7320        0.6863  0.1445\n",
      "     43        \u001b[36m0.5444\u001b[0m       0.7310        0.6955  0.1646\n",
      "     44        0.5479       0.7340        0.6991  0.1641\n",
      "     45        \u001b[36m0.5425\u001b[0m       0.7200        0.6886  0.1774\n",
      "     46        0.5430       0.7320        0.6970  0.1500\n",
      "     47        \u001b[36m0.5405\u001b[0m       0.7230        0.7404  0.1545\n",
      "     48        \u001b[36m0.5397\u001b[0m       0.7390        0.7383  0.1570\n",
      "     49        0.5412       0.7390        0.7050  0.1541\n",
      "     50        0.5404       0.7280        0.7139  0.1575\n",
      "     51        \u001b[36m0.5366\u001b[0m       0.7310        0.7015  0.1480\n",
      "     52        0.5372       0.7240        0.6975  0.1615\n",
      "     53        \u001b[36m0.5307\u001b[0m       0.7240        0.7058  0.1551\n",
      "     54        \u001b[36m0.5272\u001b[0m       0.7290        0.7297  0.1555\n",
      "     55        0.5310       0.7320        0.6941  0.1620\n",
      "     56        0.5283       0.7300        0.7291  0.1580\n",
      "     57        0.5311       0.7290        0.7281  0.1545\n",
      "     58        0.5335       0.7320        0.7020  0.1660\n",
      "     59        \u001b[36m0.5206\u001b[0m       0.7260        0.7512  0.1590\n",
      "     60        0.5273       0.7120        0.6984  0.1505\n",
      "     61        0.5275       0.7310        0.7061  0.1530\n",
      "     62        0.5238       0.7220        0.7105  0.1615\n",
      "     63        \u001b[36m0.5204\u001b[0m       0.7230        0.7212  0.1600\n",
      "     64        \u001b[36m0.5159\u001b[0m       0.7130        0.7313  0.1505\n",
      "     65        \u001b[36m0.5147\u001b[0m       0.7050        0.7693  0.1560\n",
      "     66        0.5163       0.7180        0.7464  0.1505\n",
      "     67        0.5237       0.7070        0.7499  0.1555\n",
      "     68        \u001b[36m0.5129\u001b[0m       0.7140        0.7572  0.1450\n",
      "     69        0.5142       0.7170        0.7664  0.1655\n",
      "     70        0.5165       0.7130        0.7536  0.1550\n",
      "     71        \u001b[36m0.5101\u001b[0m       0.7130        0.7417  0.1575\n",
      "     72        0.5111       0.7200        0.7873  0.1610\n",
      "     73        \u001b[36m0.5083\u001b[0m       0.7170        0.7364  0.1570\n",
      "     74        \u001b[36m0.5073\u001b[0m       0.7130        0.7652  0.1615\n",
      "     75        \u001b[36m0.5024\u001b[0m       0.7060        0.7745  0.1560\n",
      "     76        0.5157       0.7170        0.7550  0.1595\n",
      "     77        \u001b[36m0.4994\u001b[0m       0.7110        0.7679  0.1680\n",
      "     78        0.5020       0.7140        0.7879  0.1640\n",
      "     79        \u001b[36m0.4954\u001b[0m       0.7230        0.8189  0.1605\n",
      "     80        0.4987       0.7070        0.8014  0.1590\n",
      "     81        0.4982       0.7150        0.7855  0.1730\n",
      "     82        \u001b[36m0.4911\u001b[0m       0.7170        0.7769  0.1575\n",
      "     83        0.5006       0.7010        0.8110  0.1560\n",
      "     84        0.5011       0.7030        0.8051  0.1555\n",
      "     85        0.4918       0.6880        0.8190  0.1610\n",
      "     86        \u001b[36m0.4868\u001b[0m       0.7090        0.8332  0.1550\n",
      "     87        0.4943       0.7000        0.8073  0.1505\n",
      "     88        0.4896       0.7110        0.8447  0.1530\n",
      "     89        0.5010       0.6890        0.8379  0.1605\n",
      "     90        0.5007       0.7020        0.8415  0.1640\n",
      "     91        0.4987       0.7060        0.8494  0.1550\n",
      "     92        0.4914       0.7020        0.8540  0.1565\n",
      "     93        0.5016       0.7000        0.8437  0.1560\n",
      "     94        0.4960       0.7100        0.8433  0.1575\n",
      "     95        0.4974       0.6930        0.8586  0.1700\n",
      "     96        0.4974       0.6970        0.8517  0.1490\n",
      "     97        \u001b[36m0.4851\u001b[0m       0.7050        0.8482  0.1645\n",
      "     98        \u001b[36m0.4760\u001b[0m       0.7040        0.8953  0.1510\n",
      "     99        0.4810       0.7010        0.8596  0.1760\n",
      "    100        0.4905       0.6920        0.8575  0.1605\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7608\u001b[0m       \u001b[32m0.6720\u001b[0m        \u001b[35m0.7420\u001b[0m  0.1581\n",
      "      2        \u001b[36m0.6648\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6860\u001b[0m  0.1495\n",
      "      3        \u001b[36m0.6383\u001b[0m       \u001b[32m0.7490\u001b[0m        \u001b[35m0.6270\u001b[0m  0.1590\n",
      "      4        \u001b[36m0.6235\u001b[0m       0.7410        0.6410  0.1505\n",
      "      5        \u001b[36m0.6170\u001b[0m       \u001b[32m0.7500\u001b[0m        0.6319  0.1590\n",
      "      6        \u001b[36m0.6149\u001b[0m       \u001b[32m0.7550\u001b[0m        \u001b[35m0.6241\u001b[0m  0.1550\n",
      "      7        \u001b[36m0.6083\u001b[0m       0.7530        0.6294  0.1525\n",
      "      8        0.6112       0.7480        \u001b[35m0.6157\u001b[0m  0.1580\n",
      "      9        \u001b[36m0.6065\u001b[0m       0.7500        0.6291  0.1585\n",
      "     10        0.6069       0.7400        0.6283  0.1400\n",
      "     11        \u001b[36m0.6052\u001b[0m       0.7490        0.6261  0.1565\n",
      "     12        \u001b[36m0.6000\u001b[0m       0.7430        0.6276  0.1641\n",
      "     13        0.6007       0.7490        0.6198  0.1495\n",
      "     14        \u001b[36m0.5979\u001b[0m       0.7460        0.6207  0.1566\n",
      "     15        0.5987       0.7390        0.6284  0.1620\n",
      "     16        \u001b[36m0.5969\u001b[0m       0.7460        0.6297  0.1575\n",
      "     17        \u001b[36m0.5946\u001b[0m       0.7410        0.6245  0.1590\n",
      "     18        \u001b[36m0.5899\u001b[0m       0.7410        0.6240  0.1621\n",
      "     19        0.5901       0.7510        0.6158  0.1595\n",
      "     20        0.5900       0.7530        \u001b[35m0.6078\u001b[0m  0.1580\n",
      "     21        \u001b[36m0.5833\u001b[0m       \u001b[32m0.7590\u001b[0m        0.6148  0.1565\n",
      "     22        \u001b[36m0.5821\u001b[0m       0.7590        \u001b[35m0.6067\u001b[0m  0.1501\n",
      "     23        0.5831       0.7510        0.6156  0.1525\n",
      "     24        \u001b[36m0.5811\u001b[0m       0.7520        0.6085  0.1540\n",
      "     25        \u001b[36m0.5789\u001b[0m       0.7540        \u001b[35m0.6062\u001b[0m  0.1515\n",
      "     26        \u001b[36m0.5772\u001b[0m       0.7540        0.6098  0.1547\n",
      "     27        \u001b[36m0.5744\u001b[0m       0.7560        \u001b[35m0.6031\u001b[0m  0.1650\n",
      "     28        \u001b[36m0.5744\u001b[0m       0.7530        0.6055  0.1545\n",
      "     29        \u001b[36m0.5695\u001b[0m       0.7580        \u001b[35m0.6012\u001b[0m  0.1600\n",
      "     30        \u001b[36m0.5682\u001b[0m       0.7550        0.6078  0.1555\n",
      "     31        0.5700       0.7570        \u001b[35m0.5940\u001b[0m  0.1600\n",
      "     32        0.5705       \u001b[32m0.7670\u001b[0m        \u001b[35m0.5922\u001b[0m  0.1580\n",
      "     33        \u001b[36m0.5664\u001b[0m       0.7650        0.5966  0.1535\n",
      "     34        \u001b[36m0.5657\u001b[0m       \u001b[32m0.7720\u001b[0m        0.5947  0.1510\n",
      "     35        \u001b[36m0.5633\u001b[0m       0.7590        0.6006  0.1635\n",
      "     36        \u001b[36m0.5599\u001b[0m       0.7580        0.5981  0.1610\n",
      "     37        0.5667       0.7520        0.6100  0.1569\n",
      "     38        0.5679       0.7460        0.6118  0.1595\n",
      "     39        0.5646       0.7330        0.6227  0.1590\n",
      "     40        0.5664       0.7540        0.6091  0.1625\n",
      "     41        0.5649       0.7550        0.6105  0.1505\n",
      "     42        0.5638       0.7500        0.6052  0.1620\n",
      "     43        0.5612       0.7550        0.6075  0.1645\n",
      "     44        \u001b[36m0.5591\u001b[0m       0.7500        0.6026  0.1530\n",
      "     45        0.5596       0.7490        0.6026  0.1595\n",
      "     46        \u001b[36m0.5564\u001b[0m       0.7570        0.6137  0.1690\n",
      "     47        0.5565       0.7550        0.5978  0.1520\n",
      "     48        \u001b[36m0.5484\u001b[0m       0.7570        0.6026  0.1615\n",
      "     49        \u001b[36m0.5468\u001b[0m       0.7590        0.6000  0.1630\n",
      "     50        \u001b[36m0.5460\u001b[0m       0.7590        0.6004  0.1570\n",
      "     51        \u001b[36m0.5399\u001b[0m       0.7540        0.6020  0.1565\n",
      "     52        \u001b[36m0.5388\u001b[0m       0.7570        0.6139  0.1580\n",
      "     53        0.5432       0.7550        0.6037  0.1575\n",
      "     54        0.5440       0.7590        0.6121  0.1700\n",
      "     55        0.5390       0.7590        0.6096  0.1670\n",
      "     56        \u001b[36m0.5384\u001b[0m       0.7540        0.6185  0.1595\n",
      "     57        0.5407       0.7530        0.6179  0.1620\n",
      "     58        0.5404       0.7590        0.6168  0.1600\n",
      "     59        0.5426       0.7600        0.6023  0.1655\n",
      "     60        0.5392       0.7680        0.6002  0.1650\n",
      "     61        0.5401       0.7680        0.6019  0.1630\n",
      "     62        \u001b[36m0.5358\u001b[0m       0.7690        0.6064  0.1555\n",
      "     63        \u001b[36m0.5350\u001b[0m       0.7640        0.6026  0.1560\n",
      "     64        0.5367       0.7690        0.6041  0.1656\n",
      "     65        \u001b[36m0.5305\u001b[0m       0.7580        0.6080  0.1580\n",
      "     66        \u001b[36m0.5269\u001b[0m       0.7570        0.6165  0.1580\n",
      "     67        0.5319       0.7530        0.6251  0.1625\n",
      "     68        0.5287       0.7670        0.6115  0.1610\n",
      "     69        0.5285       0.7560        0.6184  0.1585\n",
      "     70        \u001b[36m0.5249\u001b[0m       0.7630        0.6186  0.1615\n",
      "     71        0.5250       0.7520        0.6634  0.1500\n",
      "     72        0.5273       0.7540        0.6246  0.1615\n",
      "     73        \u001b[36m0.5245\u001b[0m       0.7580        0.6218  0.1570\n",
      "     74        \u001b[36m0.5221\u001b[0m       0.7510        0.6311  0.1595\n",
      "     75        0.5242       0.7540        0.6388  0.1640\n",
      "     76        \u001b[36m0.5208\u001b[0m       0.7530        0.6255  0.1560\n",
      "     77        \u001b[36m0.5132\u001b[0m       0.7480        0.6337  0.1595\n",
      "     78        0.5134       0.7510        0.6487  0.1551\n",
      "     79        0.5154       0.7470        0.6494  0.1555\n",
      "     80        \u001b[36m0.5097\u001b[0m       0.7460        0.6478  0.1570\n",
      "     81        \u001b[36m0.5066\u001b[0m       0.7530        0.6478  0.1590\n",
      "     82        0.5068       0.7510        0.6649  0.1605\n",
      "     83        \u001b[36m0.5060\u001b[0m       0.7470        0.6717  0.1576\n",
      "     84        0.5120       0.7420        0.6645  0.1585\n",
      "     85        0.5134       0.7420        0.6670  0.1565\n",
      "     86        0.5141       0.7310        0.6888  0.1500\n",
      "     87        0.5072       0.7430        0.6759  0.1635\n",
      "     88        0.5082       0.7440        0.6823  0.1560\n",
      "     89        0.5121       0.7350        0.6765  0.1525\n",
      "     90        \u001b[36m0.4996\u001b[0m       0.7530        0.6738  0.1690\n",
      "     91        0.5031       0.7460        0.6843  0.1580\n",
      "     92        0.5000       0.7440        0.6846  0.1615\n",
      "     93        0.5018       0.7370        0.6690  0.1577\n",
      "     94        0.4998       0.7400        0.6789  0.1620\n",
      "     95        0.5072       0.7310        0.6933  0.1645\n",
      "     96        0.5091       0.7270        0.7053  0.1580\n",
      "     97        0.5125       0.7400        0.6787  0.1635\n",
      "     98        0.5085       0.7400        0.6966  0.1630\n",
      "     99        0.5044       0.7400        0.6850  0.1630\n",
      "    100        0.5023       0.7380        0.6820  0.1615\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7962\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.6853\u001b[0m  0.1340\n",
      "      2        \u001b[36m0.6783\u001b[0m       \u001b[32m0.7080\u001b[0m        \u001b[35m0.6756\u001b[0m  0.1375\n",
      "      3        \u001b[36m0.6595\u001b[0m       \u001b[32m0.7200\u001b[0m        \u001b[35m0.6678\u001b[0m  0.1435\n",
      "      4        \u001b[36m0.6436\u001b[0m       0.7190        0.6712  0.1290\n",
      "      5        \u001b[36m0.6304\u001b[0m       0.7180        \u001b[35m0.6542\u001b[0m  0.1315\n",
      "      6        \u001b[36m0.6202\u001b[0m       0.7200        \u001b[35m0.6478\u001b[0m  0.1345\n",
      "      7        \u001b[36m0.6121\u001b[0m       0.7200        \u001b[35m0.6452\u001b[0m  0.1280\n",
      "      8        \u001b[36m0.6079\u001b[0m       \u001b[32m0.7220\u001b[0m        0.6509  0.1225\n",
      "      9        \u001b[36m0.6035\u001b[0m       0.7220        0.6520  0.1355\n",
      "     10        \u001b[36m0.6003\u001b[0m       0.7210        0.6478  0.1350\n",
      "     11        \u001b[36m0.5967\u001b[0m       0.7220        0.6479  0.1385\n",
      "     12        \u001b[36m0.5935\u001b[0m       \u001b[32m0.7310\u001b[0m        \u001b[35m0.6451\u001b[0m  0.1315\n",
      "     13        \u001b[36m0.5914\u001b[0m       0.7250        0.6524  0.1240\n",
      "     14        \u001b[36m0.5898\u001b[0m       0.7300        \u001b[35m0.6445\u001b[0m  0.1285\n",
      "     15        \u001b[36m0.5864\u001b[0m       0.7280        0.6513  0.1325\n",
      "     16        \u001b[36m0.5829\u001b[0m       0.7270        0.6518  0.1330\n",
      "     17        \u001b[36m0.5811\u001b[0m       0.7170        0.6622  0.1385\n",
      "     18        \u001b[36m0.5793\u001b[0m       0.7190        0.6587  0.1255\n",
      "     19        \u001b[36m0.5770\u001b[0m       0.7300        0.6574  0.1310\n",
      "     20        \u001b[36m0.5764\u001b[0m       0.7300        0.6497  0.1365\n",
      "     21        0.5782       \u001b[32m0.7330\u001b[0m        \u001b[35m0.6401\u001b[0m  0.1345\n",
      "     22        \u001b[36m0.5748\u001b[0m       0.7180        0.6523  0.1305\n",
      "     23        \u001b[36m0.5713\u001b[0m       0.7290        0.6488  0.1395\n",
      "     24        0.5718       0.7290        \u001b[35m0.6368\u001b[0m  0.1330\n",
      "     25        \u001b[36m0.5679\u001b[0m       0.7220        0.6501  0.1325\n",
      "     26        \u001b[36m0.5663\u001b[0m       0.7290        0.6488  0.1305\n",
      "     27        0.5666       0.7210        0.6403  0.1320\n",
      "     28        \u001b[36m0.5629\u001b[0m       \u001b[32m0.7370\u001b[0m        0.6553  0.1565\n",
      "     29        0.5651       0.7320        0.6435  0.1360\n",
      "     30        0.5648       0.7180        0.6524  0.1355\n",
      "     31        \u001b[36m0.5599\u001b[0m       0.7330        0.6483  0.1445\n",
      "     32        \u001b[36m0.5593\u001b[0m       0.7160        0.6569  0.1280\n",
      "     33        \u001b[36m0.5566\u001b[0m       0.7170        0.6666  0.1315\n",
      "     34        \u001b[36m0.5558\u001b[0m       0.7180        0.6461  0.1315\n",
      "     35        0.5563       0.7270        0.6500  0.1370\n",
      "     36        \u001b[36m0.5540\u001b[0m       0.7250        0.6633  0.1395\n",
      "     37        \u001b[36m0.5538\u001b[0m       0.7230        0.6537  0.1295\n",
      "     38        \u001b[36m0.5500\u001b[0m       0.7220        0.6707  0.1290\n",
      "     39        \u001b[36m0.5500\u001b[0m       0.7220        0.6895  0.1245\n",
      "     40        0.5524       0.7210        0.6683  0.1325\n",
      "     41        \u001b[36m0.5499\u001b[0m       0.7140        0.6696  0.1340\n",
      "     42        \u001b[36m0.5497\u001b[0m       0.7190        0.6769  0.1315\n",
      "     43        \u001b[36m0.5478\u001b[0m       0.7110        0.6924  0.1405\n",
      "     44        \u001b[36m0.5471\u001b[0m       0.7090        0.7157  0.1415\n",
      "     45        \u001b[36m0.5458\u001b[0m       0.7170        0.7046  0.1315\n",
      "     46        \u001b[36m0.5411\u001b[0m       0.7120        0.7384  0.1400\n",
      "     47        0.5420       0.7080        0.7080  0.1355\n",
      "     48        0.5435       0.7070        0.7078  0.1490\n",
      "     49        0.5475       0.7090        0.7587  0.1315\n",
      "     50        0.5456       0.7190        0.6947  0.1325\n",
      "     51        0.5434       0.7140        0.7117  0.1480\n",
      "     52        \u001b[36m0.5403\u001b[0m       0.7220        0.6994  0.1435\n",
      "     53        \u001b[36m0.5393\u001b[0m       0.7240        0.7024  0.1370\n",
      "     54        0.5468       0.7220        0.7048  0.1325\n",
      "     55        0.5397       0.7160        0.7215  0.1365\n",
      "     56        0.5528       0.7100        0.7065  0.1410\n",
      "     57        0.5398       0.7220        0.6884  0.1405\n",
      "     58        \u001b[36m0.5383\u001b[0m       0.7230        0.7059  0.1480\n",
      "     59        \u001b[36m0.5339\u001b[0m       0.7150        0.7404  0.1505\n",
      "     60        0.5473       0.7050        0.7269  0.1510\n",
      "     61        0.5430       0.7130        0.7029  0.1495\n",
      "     62        0.5405       0.7070        0.7129  0.1390\n",
      "     63        0.5344       0.7070        0.7157  0.1405\n",
      "     64        \u001b[36m0.5313\u001b[0m       0.7130        0.7334  0.1425\n",
      "     65        0.5371       0.7130        0.7306  0.1370\n",
      "     66        0.5322       0.7190        0.7242  0.1455\n",
      "     67        0.5328       0.7190        0.7401  0.1450\n",
      "     68        \u001b[36m0.5268\u001b[0m       0.7170        0.7363  0.1425\n",
      "     69        0.5280       0.7220        0.7588  0.1450\n",
      "     70        0.5310       0.7180        0.7684  0.1425\n",
      "     71        \u001b[36m0.5252\u001b[0m       0.7220        0.7408  0.1450\n",
      "     72        0.5273       0.7160        0.7488  0.1385\n",
      "     73        \u001b[36m0.5240\u001b[0m       0.7200        0.7657  0.1405\n",
      "     74        \u001b[36m0.5234\u001b[0m       0.7190        0.7492  0.1490\n",
      "     75        \u001b[36m0.5231\u001b[0m       0.7230        0.7634  0.1405\n",
      "     76        0.5234       0.7170        0.7799  0.1470\n",
      "     77        0.5310       0.7200        0.7536  0.1515\n",
      "     78        0.5281       0.7180        0.7411  0.1390\n",
      "     79        0.5269       0.7190        0.7519  0.1575\n",
      "     80        0.5256       0.7090        0.7434  0.1511\n",
      "     81        0.5259       0.7290        0.7370  0.1545\n",
      "     82        \u001b[36m0.5231\u001b[0m       0.7280        0.7380  0.1615\n",
      "     83        0.5274       0.7130        0.7447  0.1400\n",
      "     84        \u001b[36m0.5224\u001b[0m       0.7200        0.7435  0.1445\n",
      "     85        0.5226       0.7270        0.7405  0.1660\n",
      "     86        0.5252       0.7080        0.7484  0.1425\n",
      "     87        \u001b[36m0.5220\u001b[0m       0.7160        0.7452  0.1430\n",
      "     88        0.5270       0.7180        0.7622  0.1455\n",
      "     89        0.5276       0.7080        0.7647  0.1415\n",
      "     90        \u001b[36m0.5216\u001b[0m       0.7220        0.7670  0.1380\n",
      "     91        0.5253       0.7170        0.7728  0.1455\n",
      "     92        \u001b[36m0.5215\u001b[0m       0.7220        0.7774  0.1410\n",
      "     93        \u001b[36m0.5214\u001b[0m       0.7130        0.7791  0.1415\n",
      "     94        \u001b[36m0.5195\u001b[0m       0.7250        0.7825  0.1457\n",
      "     95        0.5217       0.7230        0.7705  0.1475\n",
      "     96        \u001b[36m0.5178\u001b[0m       0.7210        0.7703  0.1420\n",
      "     97        0.5183       0.7170        0.7771  0.1425\n",
      "     98        \u001b[36m0.5163\u001b[0m       0.7170        0.7770  0.1460\n",
      "     99        \u001b[36m0.5140\u001b[0m       0.7290        0.7949  0.1515\n",
      "    100        0.5193       0.7220        0.7856  0.1430\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7958\u001b[0m       \u001b[32m0.5210\u001b[0m        \u001b[35m1.0208\u001b[0m  0.1360\n",
      "      2        \u001b[36m0.6844\u001b[0m       \u001b[32m0.5290\u001b[0m        \u001b[35m1.0085\u001b[0m  0.1311\n",
      "      3        \u001b[36m0.6494\u001b[0m       0.5080        \u001b[35m0.9386\u001b[0m  0.1325\n",
      "      4        \u001b[36m0.6370\u001b[0m       \u001b[32m0.6010\u001b[0m        \u001b[35m0.8392\u001b[0m  0.1320\n",
      "      5        \u001b[36m0.6291\u001b[0m       \u001b[32m0.6300\u001b[0m        \u001b[35m0.8061\u001b[0m  0.1345\n",
      "      6        \u001b[36m0.6227\u001b[0m       \u001b[32m0.6400\u001b[0m        \u001b[35m0.8000\u001b[0m  0.1400\n",
      "      7        \u001b[36m0.6189\u001b[0m       \u001b[32m0.6590\u001b[0m        \u001b[35m0.7605\u001b[0m  0.1348\n",
      "      8        \u001b[36m0.6153\u001b[0m       \u001b[32m0.6660\u001b[0m        0.7682  0.1395\n",
      "      9        \u001b[36m0.6129\u001b[0m       0.6650        0.7610  0.1340\n",
      "     10        \u001b[36m0.6101\u001b[0m       \u001b[32m0.6680\u001b[0m        \u001b[35m0.7499\u001b[0m  0.1304\n",
      "     11        \u001b[36m0.6064\u001b[0m       0.6630        \u001b[35m0.7390\u001b[0m  0.1315\n",
      "     12        \u001b[36m0.6044\u001b[0m       \u001b[32m0.6700\u001b[0m        0.7413  0.1290\n",
      "     13        \u001b[36m0.6009\u001b[0m       \u001b[32m0.6720\u001b[0m        \u001b[35m0.7313\u001b[0m  0.1285\n",
      "     14        \u001b[36m0.5990\u001b[0m       \u001b[32m0.6780\u001b[0m        \u001b[35m0.7307\u001b[0m  0.1375\n",
      "     15        \u001b[36m0.5978\u001b[0m       \u001b[32m0.6910\u001b[0m        \u001b[35m0.7237\u001b[0m  0.1320\n",
      "     16        \u001b[36m0.5968\u001b[0m       0.6890        0.7302  0.1345\n",
      "     17        \u001b[36m0.5955\u001b[0m       \u001b[32m0.7010\u001b[0m        0.7266  0.1315\n",
      "     18        \u001b[36m0.5929\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.7170\u001b[0m  0.1280\n",
      "     19        \u001b[36m0.5908\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.7106\u001b[0m  0.1305\n",
      "     20        \u001b[36m0.5887\u001b[0m       0.7050        \u001b[35m0.7014\u001b[0m  0.1325\n",
      "     21        \u001b[36m0.5871\u001b[0m       0.7100        0.7048  0.1340\n",
      "     22        \u001b[36m0.5859\u001b[0m       0.7060        0.7039  0.1385\n",
      "     23        \u001b[36m0.5853\u001b[0m       0.7150        \u001b[35m0.6953\u001b[0m  0.1255\n",
      "     24        \u001b[36m0.5833\u001b[0m       0.7120        \u001b[35m0.6943\u001b[0m  0.1330\n",
      "     25        \u001b[36m0.5829\u001b[0m       0.7150        \u001b[35m0.6869\u001b[0m  0.1415\n",
      "     26        \u001b[36m0.5795\u001b[0m       \u001b[32m0.7210\u001b[0m        0.6935  0.1360\n",
      "     27        0.5808       \u001b[32m0.7230\u001b[0m        \u001b[35m0.6843\u001b[0m  0.1255\n",
      "     28        0.5795       \u001b[32m0.7280\u001b[0m        \u001b[35m0.6760\u001b[0m  0.1245\n",
      "     29        0.5815       0.7190        0.6788  0.1355\n",
      "     30        \u001b[36m0.5775\u001b[0m       0.7230        0.6806  0.1310\n",
      "     31        \u001b[36m0.5748\u001b[0m       0.7120        0.6876  0.1315\n",
      "     32        0.5802       \u001b[32m0.7310\u001b[0m        \u001b[35m0.6622\u001b[0m  0.1325\n",
      "     33        \u001b[36m0.5737\u001b[0m       0.7160        0.6716  0.1360\n",
      "     34        \u001b[36m0.5720\u001b[0m       0.7210        0.6793  0.1305\n",
      "     35        0.5741       0.7310        0.6696  0.1195\n",
      "     36        0.5763       0.7140        0.6995  0.1390\n",
      "     37        0.5726       0.7240        0.6827  0.1385\n",
      "     38        \u001b[36m0.5684\u001b[0m       0.7240        0.6904  0.1315\n",
      "     39        \u001b[36m0.5680\u001b[0m       0.7280        0.6769  0.1310\n",
      "     40        0.5686       0.7310        0.7004  0.1405\n",
      "     41        0.5720       0.7050        0.7004  0.1350\n",
      "     42        \u001b[36m0.5672\u001b[0m       0.7180        0.7017  0.1395\n",
      "     43        \u001b[36m0.5638\u001b[0m       0.7280        0.7077  0.1375\n",
      "     44        0.5660       0.7230        0.7089  0.1380\n",
      "     45        \u001b[36m0.5637\u001b[0m       0.7290        0.7095  0.1365\n",
      "     46        0.5661       \u001b[32m0.7340\u001b[0m        0.6940  0.1330\n",
      "     47        \u001b[36m0.5611\u001b[0m       0.7250        0.6990  0.1345\n",
      "     48        0.5670       \u001b[32m0.7410\u001b[0m        0.6758  0.1385\n",
      "     49        \u001b[36m0.5603\u001b[0m       0.7320        \u001b[35m0.6552\u001b[0m  0.1380\n",
      "     50        \u001b[36m0.5585\u001b[0m       0.7290        0.6855  0.1385\n",
      "     51        0.5588       0.7320        0.6798  0.1325\n",
      "     52        0.5614       0.7270        0.7165  0.1345\n",
      "     53        0.5598       0.7240        0.6725  0.1405\n",
      "     54        \u001b[36m0.5563\u001b[0m       0.7210        0.6948  0.1380\n",
      "     55        0.5571       0.7250        0.7072  0.1355\n",
      "     56        \u001b[36m0.5546\u001b[0m       0.7250        0.6913  0.1415\n",
      "     57        \u001b[36m0.5545\u001b[0m       0.7390        0.6847  0.1345\n",
      "     58        \u001b[36m0.5520\u001b[0m       0.7240        0.6914  0.1505\n",
      "     59        0.5583       0.7340        0.6732  0.1530\n",
      "     60        0.5541       0.7310        0.6897  0.1435\n",
      "     61        0.5545       0.7360        0.6668  0.1380\n",
      "     62        \u001b[36m0.5504\u001b[0m       0.7330        0.6938  0.1465\n",
      "     63        0.5540       0.7400        0.7026  0.1420\n",
      "     64        0.5538       0.7330        0.6771  0.1355\n",
      "     65        \u001b[36m0.5503\u001b[0m       0.7220        0.7105  0.1450\n",
      "     66        0.5527       0.7390        0.6894  0.1395\n",
      "     67        0.5524       0.7360        0.6884  0.1505\n",
      "     68        0.5527       \u001b[32m0.7470\u001b[0m        0.7071  0.1455\n",
      "     69        0.5536       0.7410        0.6730  0.1445\n",
      "     70        0.5540       0.7310        0.6611  0.1450\n",
      "     71        0.5530       0.7410        0.6933  0.1435\n",
      "     72        0.5566       0.7260        0.7107  0.1420\n",
      "     73        0.5534       0.7340        0.7108  0.1465\n",
      "     74        0.5504       0.7340        0.7452  0.1470\n",
      "     75        \u001b[36m0.5486\u001b[0m       0.7450        0.6839  0.1445\n",
      "     76        \u001b[36m0.5459\u001b[0m       0.7410        0.6901  0.1410\n",
      "     77        0.5508       0.7430        0.6884  0.1395\n",
      "     78        0.5470       0.7350        0.7063  0.1405\n",
      "     79        0.5467       0.7300        0.6906  0.1420\n",
      "     80        0.5495       0.7280        0.7235  0.1435\n",
      "     81        0.5491       0.7330        0.7158  0.1430\n",
      "     82        0.5538       0.7410        0.6954  0.1505\n",
      "     83        \u001b[36m0.5438\u001b[0m       0.7420        0.6839  0.1460\n",
      "     84        0.5475       0.7280        0.7143  0.1375\n",
      "     85        0.5449       0.7310        0.6973  0.1430\n",
      "     86        0.5445       0.7380        0.7256  0.1492\n",
      "     87        \u001b[36m0.5435\u001b[0m       0.7410        0.7107  0.1470\n",
      "     88        0.5477       0.7390        0.6955  0.1455\n",
      "     89        0.5442       0.7320        0.7204  0.1440\n",
      "     90        \u001b[36m0.5415\u001b[0m       0.7360        0.7100  0.1435\n",
      "     91        0.5429       0.7440        0.7024  0.1455\n",
      "     92        0.5464       0.7380        0.7116  0.1425\n",
      "     93        0.5471       \u001b[32m0.7480\u001b[0m        0.6820  0.1445\n",
      "     94        0.5416       0.7300        0.7253  0.1490\n",
      "     95        \u001b[36m0.5393\u001b[0m       0.7410        0.7001  0.1415\n",
      "     96        0.5445       0.7300        0.7387  0.1496\n",
      "     97        0.5436       0.7460        0.6984  0.1495\n",
      "     98        \u001b[36m0.5384\u001b[0m       0.7390        0.7352  0.1380\n",
      "     99        0.5405       0.7340        0.7476  0.1505\n",
      "    100        \u001b[36m0.5383\u001b[0m       0.7330        0.7781  0.1390\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8243\u001b[0m       \u001b[32m0.6680\u001b[0m        \u001b[35m0.7095\u001b[0m  0.1535\n",
      "      2        \u001b[36m0.7620\u001b[0m       \u001b[32m0.6900\u001b[0m        0.7211  0.1490\n",
      "      3        \u001b[36m0.7138\u001b[0m       0.6870        0.7304  0.1425\n",
      "      4        0.7208       0.6900        0.7166  0.1520\n",
      "      5        \u001b[36m0.7058\u001b[0m       \u001b[32m0.7000\u001b[0m        0.7218  0.1405\n",
      "      6        0.7259       \u001b[32m0.7020\u001b[0m        0.7234  0.1385\n",
      "      7        0.7407       0.6900        0.7355  0.1570\n",
      "      8        0.7312       0.6790        0.7467  0.1640\n",
      "      9        0.7401       0.6810        0.7955  0.1555\n",
      "     10        0.7472       0.6830        0.7726  0.1500\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8036\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m0.9749\u001b[0m  0.1405\n",
      "      2        \u001b[36m0.7059\u001b[0m       \u001b[32m0.6370\u001b[0m        \u001b[35m0.8214\u001b[0m  0.1395\n",
      "      3        \u001b[36m0.7028\u001b[0m       0.5500        1.1535  0.1490\n",
      "      4        0.7132       0.6100        \u001b[35m0.8125\u001b[0m  0.1415\n",
      "      5        0.7049       0.4990        1.1232  0.1460\n",
      "      6        0.7220       0.5380        0.8312  0.1665\n",
      "      7        \u001b[36m0.6901\u001b[0m       0.5330        0.8469  0.1637\n",
      "      8        0.7073       0.5630        0.8170  0.1600\n",
      "      9        \u001b[36m0.6760\u001b[0m       0.6010        \u001b[35m0.7947\u001b[0m  0.1675\n",
      "     10        \u001b[36m0.6741\u001b[0m       \u001b[32m0.7230\u001b[0m        \u001b[35m0.6910\u001b[0m  0.1590\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.6179\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1415\n",
      "      2       \u001b[36m10.6176\u001b[0m       0.3340       10.6176  0.1360\n",
      "      3       10.6176       0.3340       10.6176  0.1365\n",
      "      4       10.6176       0.3340       10.6176  0.1285\n",
      "      5       10.6176       0.3340       10.6176  0.1340\n",
      "      6       10.6176       0.3340       10.6176  0.1345\n",
      "      7       10.6176       0.3340       10.6176  0.1225\n",
      "      8       10.6176       0.3340       10.6176  0.1300\n",
      "      9       10.6176       0.3340       10.6176  0.1355\n",
      "     10       10.6176       0.3340       10.6176  0.1375\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5662\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1300\n",
      "      2       10.6176       0.3340       10.6176  0.1245\n",
      "      3       10.6176       0.3340       10.6176  0.1325\n",
      "      4       10.6176       0.3340       10.6176  0.1340\n",
      "      5       10.6176       0.3340       10.6176  0.1295\n",
      "      6       10.6176       0.3340       10.6176  0.1505\n",
      "      7       10.6176       0.3340       10.6176  0.1300\n",
      "      8       10.6176       0.3340       10.6176  0.1333\n",
      "      9       10.6176       0.3340       10.6176  0.1345\n",
      "     10       10.6176       0.3340       10.6176  0.1360\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8172\u001b[0m       \u001b[32m0.6690\u001b[0m        \u001b[35m0.7107\u001b[0m  0.1445\n",
      "      2        \u001b[36m0.7527\u001b[0m       \u001b[32m0.6850\u001b[0m        0.7273  0.1480\n",
      "      3        \u001b[36m0.7207\u001b[0m       \u001b[32m0.7020\u001b[0m        0.7130  0.1455\n",
      "      4        0.7307       0.6920        \u001b[35m0.6982\u001b[0m  0.1460\n",
      "      5        \u001b[36m0.7125\u001b[0m       \u001b[32m0.7080\u001b[0m        0.7168  0.1505\n",
      "      6        \u001b[36m0.6972\u001b[0m       \u001b[32m0.7190\u001b[0m        0.7020  0.1520\n",
      "      7        \u001b[36m0.6934\u001b[0m       0.7040        0.7118  0.1655\n",
      "      8        0.6975       0.7080        \u001b[35m0.6954\u001b[0m  0.1647\n",
      "      9        \u001b[36m0.6818\u001b[0m       0.7110        0.7207  0.1620\n",
      "     10        0.7207       0.6980        0.7507  0.1595\n",
      "     11        0.7185       0.7040        0.7200  0.1670\n",
      "     12        0.7124       0.7180        \u001b[35m0.6840\u001b[0m  0.1747\n",
      "     13        0.6912       0.7140        \u001b[35m0.6750\u001b[0m  0.1585\n",
      "     14        \u001b[36m0.6721\u001b[0m       0.7100        0.6955  0.1660\n",
      "     15        0.7102       0.7060        0.7174  0.1666\n",
      "     16        0.7009       \u001b[32m0.7200\u001b[0m        0.6806  0.1635\n",
      "     17        0.7063       0.7140        \u001b[35m0.6747\u001b[0m  0.1690\n",
      "     18        0.6834       0.7010        0.6932  0.1570\n",
      "     19        0.7007       0.7190        0.6997  0.1575\n",
      "     20        0.6806       0.7150        0.6934  0.1595\n",
      "     21        0.6793       0.7150        0.7028  0.1691\n",
      "     22        0.6918       0.7040        0.6786  0.1636\n",
      "     23        0.6979       0.7000        0.7631  0.1560\n",
      "     24        0.6976       0.7100        0.7076  0.1555\n",
      "     25        0.7339       \u001b[32m0.7220\u001b[0m        0.7011  0.1650\n",
      "     26        0.7035       0.7160        0.6951  0.1530\n",
      "     27        0.6969       \u001b[32m0.7230\u001b[0m        0.7165  0.1784\n",
      "     28        0.6930       0.7170        0.7033  0.1560\n",
      "     29        0.7041       0.7220        0.7414  0.1620\n",
      "     30        0.7012       \u001b[32m0.7240\u001b[0m        0.6913  0.1705\n",
      "     31        0.6965       \u001b[32m0.7250\u001b[0m        0.7021  0.1528\n",
      "     32        0.6975       0.7230        0.6903  0.1635\n",
      "     33        0.7141       0.7200        0.6822  0.1572\n",
      "     34        0.6943       0.7120        0.7074  0.1610\n",
      "     35        0.6868       0.7150        0.6875  0.1615\n",
      "     36        0.6849       0.7190        0.7164  0.1816\n",
      "     37        0.7227       0.7210        0.6924  0.1570\n",
      "     38        0.6932       0.6910        0.7498  0.1680\n",
      "     39        0.7042       0.7180        0.7066  0.1636\n",
      "     40        0.6991       0.7150        0.6946  0.1525\n",
      "     41        0.6849       0.7190        0.6994  0.1530\n",
      "     42        0.6819       0.7200        0.6930  0.1615\n",
      "     43        0.6951       0.7160        0.6941  0.1530\n",
      "     44        0.7044       0.7210        0.6748  0.1550\n",
      "     45        0.6889       0.7200        0.6842  0.1585\n",
      "     46        0.7024       0.7140        0.6863  0.1580\n",
      "     47        0.6971       0.7190        \u001b[35m0.6718\u001b[0m  0.1555\n",
      "     48        0.7050       0.7200        \u001b[35m0.6637\u001b[0m  0.1580\n",
      "     49        0.6801       0.6950        0.6761  0.1700\n",
      "     50        0.6829       0.7200        0.6886  0.1645\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8790\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m0.9247\u001b[0m  0.1460\n",
      "      2        \u001b[36m0.7703\u001b[0m       \u001b[32m0.4960\u001b[0m        \u001b[35m0.8818\u001b[0m  0.1465\n",
      "      3        \u001b[36m0.7052\u001b[0m       \u001b[32m0.7280\u001b[0m        \u001b[35m0.6898\u001b[0m  0.1620\n",
      "      4        \u001b[36m0.6809\u001b[0m       0.5420        1.7131  0.1445\n",
      "      5        0.8659       0.4900        0.8612  0.1490\n",
      "      6        0.8301       0.6570        0.8545  0.1405\n",
      "      7        0.8241       0.6550        0.8505  0.1620\n",
      "      8        0.8301       0.6560        0.8410  0.1565\n",
      "      9        0.8227       0.6580        0.8419  0.1630\n",
      "     10        0.8204       0.6580        0.8274  0.1600\n",
      "     11        0.8202       0.6560        0.8439  0.1555\n",
      "     12        0.8299       0.4900        0.9206  0.1560\n",
      "     13        0.8380       0.6580        0.8562  0.1605\n",
      "     14        0.8277       0.4900        0.8863  0.1600\n",
      "     15        0.8354       0.6550        0.8535  0.1591\n",
      "     16        0.8230       0.4900        0.8673  0.1485\n",
      "     17        0.8405       0.6600        0.8391  0.1620\n",
      "     18        0.8224       0.6570        0.8505  0.1605\n",
      "     19        0.8348       0.6570        0.8455  0.1580\n",
      "     20        0.8285       0.4910        0.8636  0.1530\n",
      "     21        0.8311       0.6560        0.8339  0.1595\n",
      "     22        0.8305       0.6540        0.8590  0.1600\n",
      "     23        0.8294       0.6550        0.8449  0.1585\n",
      "     24        0.8321       0.4900        0.8864  0.1750\n",
      "     25        0.8284       0.6530        0.8480  0.1640\n",
      "     26        0.8248       0.6540        0.8546  0.1615\n",
      "     27        0.8300       0.6500        0.8665  0.1606\n",
      "     28        0.8337       0.4900        0.8654  0.1593\n",
      "     29        0.8310       0.6470        0.8594  0.1595\n",
      "     30        0.8263       0.4900        0.9032  0.1560\n",
      "     31        0.8286       0.4900        0.9283  0.1595\n",
      "     32        0.8266       0.4900        0.8748  0.1535\n",
      "     33        0.8369       0.4900        0.8918  0.1546\n",
      "     34        0.8393       0.4900        0.8843  0.1635\n",
      "     35        0.8262       0.4900        0.8695  0.1600\n",
      "     36        0.8251       0.6550        0.8612  0.1565\n",
      "     37        0.8326       0.6500        0.8562  0.1585\n",
      "     38        0.8334       0.6470        0.8620  0.1530\n",
      "     39        0.8286       0.6550        0.8427  0.1585\n",
      "     40        0.8371       0.6540        0.8473  0.1550\n",
      "     41        0.8414       0.6560        0.8608  0.1535\n",
      "     42        0.8501       0.6460        0.8538  0.1570\n",
      "     43        0.8421       0.6550        0.8509  0.1521\n",
      "     44        0.8255       0.6550        0.8603  0.1570\n",
      "     45        0.8438       0.6480        0.8557  0.1550\n",
      "     46        0.8341       0.4900        0.8792  0.1635\n",
      "     47        0.8301       0.4900        0.8789  0.1550\n",
      "     48        0.8360       0.6520        0.8468  0.1555\n",
      "     49        0.8338       0.6480        0.8590  0.1710\n",
      "     50        0.8327       0.4900        0.8703  0.1570\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.6181\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1385\n",
      "      2       \u001b[36m10.6176\u001b[0m       0.3340       10.6176  0.1315\n",
      "      3       10.6176       0.3340       10.6176  0.1350\n",
      "      4       10.6176       0.3340       10.6176  0.1325\n",
      "      5       10.6176       0.3340       10.6176  0.1312\n",
      "      6       10.6176       0.3340       10.6176  0.1340\n",
      "      7       10.6176       0.3340       10.6176  0.1335\n",
      "      8       10.6176       0.3340       10.6176  0.1315\n",
      "      9       10.6176       0.3340       10.6176  0.1311\n",
      "     10       10.6176       0.3340       10.6176  0.1555\n",
      "     11       10.6176       0.3340       10.6176  0.1390\n",
      "     12       10.6176       0.3340       10.6176  0.1305\n",
      "     13       10.6176       0.3340       10.6176  0.1365\n",
      "     14       10.6176       0.3340       10.6176  0.1350\n",
      "     15       10.6176       0.3340       10.6176  0.1365\n",
      "     16       10.6176       0.3340       10.6176  0.1280\n",
      "     17       10.6176       0.3340       10.6176  0.1316\n",
      "     18       10.6176       0.3340       10.6176  0.1315\n",
      "     19       10.6176       0.3340       10.6176  0.1360\n",
      "     20       10.6176       0.3340       10.6176  0.1365\n",
      "     21       10.6176       0.3340       10.6176  0.1375\n",
      "     22       10.6176       0.3340       10.6176  0.1340\n",
      "     23       10.6176       0.3340       10.6176  0.1362\n",
      "     24       10.6176       0.3340       10.6176  0.1325\n",
      "     25       10.6176       0.3340       10.6176  0.1310\n",
      "     26       10.6176       0.3340       10.6176  0.1365\n",
      "     27       10.6176       0.3340       10.6176  0.1325\n",
      "     28       10.6176       0.3340       10.6176  0.1380\n",
      "     29       10.6176       0.3340       10.6176  0.1385\n",
      "     30       10.6176       0.3340       10.6176  0.1360\n",
      "     31       10.6176       0.3340       10.6176  0.1285\n",
      "     32       10.6176       0.3340       10.6176  0.1365\n",
      "     33       10.6176       0.3340       10.6176  0.1270\n",
      "     34       10.6176       0.3340       10.6176  0.1485\n",
      "     35       10.6176       0.3340       10.6176  0.1335\n",
      "     36       10.6176       0.3340       10.6176  0.1305\n",
      "     37       10.6176       0.3340       10.6176  0.1335\n",
      "     38       10.6176       0.3340       10.6176  0.1380\n",
      "     39       10.6176       0.3340       10.6176  0.1405\n",
      "     40       10.6176       0.3340       10.6176  0.1425\n",
      "     41       10.6176       0.3340       10.6176  0.1410\n",
      "     42       10.6176       0.3340       10.6176  0.1415\n",
      "     43       10.6176       0.3340       10.6176  0.1370\n",
      "     44       10.6176       0.3340       10.6176  0.1395\n",
      "     45       10.6176       0.3340       10.6176  0.1440\n",
      "     46       10.6176       0.3340       10.6176  0.1375\n",
      "     47       10.6176       0.3340       10.6176  0.1395\n",
      "     48       10.6176       0.3340       10.6176  0.1250\n",
      "     49       10.6176       0.3340       10.6176  0.1475\n",
      "     50       10.6176       0.3340       10.6176  0.1355\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5663\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1350\n",
      "      2       10.6176       0.3340       10.6176  0.1335\n",
      "      3       10.6176       0.3340       10.6176  0.1315\n",
      "      4       10.6176       0.3340       10.6176  0.1316\n",
      "      5       10.6176       0.3340       10.6176  0.1295\n",
      "      6       10.6176       0.3340       10.6176  0.1408\n",
      "      7       10.6176       0.3340       10.6176  0.1395\n",
      "      8       10.6176       0.3340       10.6176  0.1315\n",
      "      9       10.6176       0.3340       10.6176  0.1326\n",
      "     10       10.6176       0.3340       10.6176  0.1355\n",
      "     11       10.6176       0.3340       10.6176  0.1405\n",
      "     12       10.6176       0.3340       10.6176  0.1326\n",
      "     13       10.6176       0.3340       10.6176  0.1425\n",
      "     14       10.6176       0.3340       10.6176  0.1310\n",
      "     15       10.6176       0.3340       10.6176  0.1385\n",
      "     16       10.6176       0.3340       10.6176  0.1325\n",
      "     17       10.6176       0.3340       10.6176  0.1420\n",
      "     18       10.6176       0.3340       10.6176  0.1345\n",
      "     19       10.6176       0.3340       10.6176  0.1295\n",
      "     20       10.6176       0.3340       10.6176  0.1320\n",
      "     21       10.6176       0.3340       10.6176  0.1335\n",
      "     22       10.6176       0.3340       10.6176  0.1355\n",
      "     23       10.6176       0.3340       10.6176  0.1389\n",
      "     24       10.6176       0.3340       10.6176  0.1375\n",
      "     25       10.6176       0.3340       10.6176  0.1310\n",
      "     26       10.6176       0.3340       10.6176  0.1405\n",
      "     27       10.6176       0.3340       10.6176  0.1355\n",
      "     28       10.6176       0.3340       10.6176  0.1250\n",
      "     29       10.6176       0.3340       10.6176  0.1315\n",
      "     30       10.6176       0.3340       10.6176  0.1375\n",
      "     31       10.6176       0.3340       10.6176  0.1370\n",
      "     32       10.6176       0.3340       10.6176  0.1355\n",
      "     33       10.6176       0.3340       10.6176  0.1400\n",
      "     34       10.6176       0.3340       10.6176  0.1315\n",
      "     35       10.6176       0.3340       10.6176  0.1355\n",
      "     36       10.6176       0.3340       10.6176  0.1350\n",
      "     37       10.6176       0.3340       10.6176  0.1365\n",
      "     38       10.6176       0.3340       10.6176  0.1395\n",
      "     39       10.6176       0.3340       10.6176  0.1390\n",
      "     40       10.6176       0.3340       10.6176  0.1415\n",
      "     41       10.6176       0.3340       10.6176  0.1340\n",
      "     42       10.6176       0.3340       10.6176  0.1425\n",
      "     43       10.6176       0.3340       10.6176  0.1365\n",
      "     44       10.6176       0.3340       10.6176  0.1388\n",
      "     45       10.6176       0.3340       10.6176  0.1405\n",
      "     46       10.6176       0.3340       10.6176  0.1390\n",
      "     47       10.6176       0.3340       10.6176  0.1395\n",
      "     48       10.6176       0.3340       10.6176  0.1365\n",
      "     49       10.6176       0.3340       10.6176  0.1351\n",
      "     50       10.6176       0.3340       10.6176  0.1475\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8559\u001b[0m       \u001b[32m0.6350\u001b[0m        \u001b[35m0.7724\u001b[0m  0.1470\n",
      "      2        0.9035       0.4890        0.9106  0.1485\n",
      "      3        0.8595       \u001b[32m0.6450\u001b[0m        0.8641  0.1490\n",
      "      4        0.8830       0.5340        0.8962  0.1495\n",
      "      5        0.8861       0.4990        0.9070  0.1510\n",
      "      6        0.8615       \u001b[32m0.6530\u001b[0m        0.7880  0.1555\n",
      "      7        \u001b[36m0.8510\u001b[0m       0.6360        0.8576  0.1580\n",
      "      8        0.8624       0.6510        0.8360  0.1559\n",
      "      9        \u001b[36m0.8414\u001b[0m       0.6520        0.8337  0.1665\n",
      "     10        \u001b[36m0.8384\u001b[0m       0.6500        0.8313  0.1570\n",
      "     11        0.8400       \u001b[32m0.6560\u001b[0m        0.8290  0.1605\n",
      "     12        0.8575       0.5340        0.8886  0.1590\n",
      "     13        0.8435       0.6540        0.8345  0.1640\n",
      "     14        \u001b[36m0.8377\u001b[0m       0.6530        0.8379  0.1685\n",
      "     15        \u001b[36m0.8353\u001b[0m       0.6000        0.8736  0.1660\n",
      "     16        0.8360       0.6440        0.8321  0.1551\n",
      "     17        \u001b[36m0.8307\u001b[0m       0.6470        0.8470  0.1615\n",
      "     18        0.8538       0.6410        0.8327  0.1590\n",
      "     19        0.8388       0.6150        0.8611  0.1575\n",
      "     20        0.8448       0.6560        0.8255  0.1640\n",
      "     21        0.8359       0.6550        0.8306  0.1630\n",
      "     22        \u001b[36m0.8305\u001b[0m       0.6530        0.8387  0.1585\n",
      "     23        0.8366       0.6490        0.8247  0.1627\n",
      "     24        0.8366       \u001b[32m0.6570\u001b[0m        0.8295  0.1851\n",
      "     25        0.8331       0.6550        0.8291  0.1580\n",
      "     26        0.8333       0.6510        0.8271  0.1565\n",
      "     27        0.8363       0.6530        0.8283  0.1610\n",
      "     28        0.8329       0.6550        0.8279  0.1585\n",
      "     29        0.8357       0.6510        0.8308  0.1600\n",
      "     30        \u001b[36m0.8299\u001b[0m       0.6570        0.8293  0.1560\n",
      "     31        0.8306       0.6540        0.8247  0.1635\n",
      "     32        0.8313       0.6550        0.8263  0.1490\n",
      "     33        \u001b[36m0.8298\u001b[0m       0.6540        0.8212  0.1585\n",
      "     34        0.8299       0.6540        0.8216  0.1550\n",
      "     35        0.8309       0.6570        0.8286  0.1545\n",
      "     36        0.8314       0.6540        0.8231  0.1556\n",
      "     37        \u001b[36m0.8290\u001b[0m       0.6560        0.8276  0.1520\n",
      "     38        0.8314       0.6540        0.8250  0.1545\n",
      "     39        0.8304       0.6560        0.8277  0.1570\n",
      "     40        0.8394       0.6530        0.8297  0.1585\n",
      "     41        0.8321       0.6540        0.8300  0.1600\n",
      "     42        0.8333       0.6540        0.8249  0.1569\n",
      "     43        0.8319       0.6560        0.8266  0.1585\n",
      "     44        0.8323       0.6540        0.8239  0.1540\n",
      "     45        0.8309       0.6570        0.8259  0.1535\n",
      "     46        0.8348       0.6560        0.8311  0.1590\n",
      "     47        0.8388       0.6570        0.8312  0.1585\n",
      "     48        0.8332       0.6560        0.8310  0.1537\n",
      "     49        0.8330       \u001b[32m0.6600\u001b[0m        0.8204  0.1579\n",
      "     50        0.8336       0.6580        0.8257  0.1685\n",
      "     51        0.8352       0.6560        0.8302  0.1560\n",
      "     52        0.8313       0.6560        0.8290  0.1565\n",
      "     53        0.8292       0.6570        0.8272  0.1520\n",
      "     54        0.8474       0.6510        0.8421  0.1620\n",
      "     55        0.8382       0.6580        0.8227  0.1622\n",
      "     56        0.8655       0.6520        0.8286  0.1560\n",
      "     57        0.8408       0.6510        0.8442  0.1535\n",
      "     58        0.8424       0.6400        0.8611  0.1590\n",
      "     59        0.8488       0.6520        0.8207  0.1510\n",
      "     60        0.8544       0.6570        0.8329  0.1585\n",
      "     61        0.8386       0.6530        0.8295  0.1570\n",
      "     62        0.8386       0.6570        0.8273  0.1636\n",
      "     63        0.8340       0.6480        0.8473  0.1610\n",
      "     64        0.8325       0.6570        0.8321  0.1570\n",
      "     65        0.8356       0.6570        0.8321  0.1655\n",
      "     66        0.8366       0.6450        0.8359  0.1600\n",
      "     67        0.8425       0.6550        0.8340  0.1555\n",
      "     68        0.8414       0.6530        0.8317  0.1620\n",
      "     69        0.8367       0.6550        0.8302  0.1550\n",
      "     70        0.8414       0.6520        0.8324  0.1605\n",
      "     71        0.8375       0.6550        0.8289  0.1540\n",
      "     72        0.8368       0.6570        0.8317  0.1624\n",
      "     73        0.8554       0.6530        0.8393  0.1605\n",
      "     74        0.8363       0.6550        0.8248  0.1590\n",
      "     75        0.8418       0.6500        0.8291  0.1525\n",
      "     76        0.8337       0.6570        0.8240  0.1560\n",
      "     77        0.8343       0.6550        0.8238  0.1575\n",
      "     78        0.8382       0.6540        0.8268  0.1470\n",
      "     79        0.8389       0.6570        0.8289  0.1630\n",
      "     80        0.8346       0.6550        0.8306  0.1765\n",
      "     81        0.8361       0.6530        0.8262  0.1650\n",
      "     82        0.8373       0.6550        0.8247  0.1540\n",
      "     83        0.8384       0.6470        0.8306  0.1735\n",
      "     84        0.8508       0.6540        0.8243  0.1630\n",
      "     85        0.8381       0.6560        0.8255  0.1518\n",
      "     86        0.8434       0.6570        0.8313  0.1635\n",
      "     87        0.8370       0.6450        0.8315  0.1590\n",
      "     88        0.8342       0.6600        0.8242  0.1586\n",
      "     89        0.8317       \u001b[32m0.6610\u001b[0m        0.8258  0.1610\n",
      "     90        0.8394       0.6570        0.8222  0.1530\n",
      "     91        0.8363       0.6600        0.8225  0.1635\n",
      "     92        0.8303       0.6590        0.8296  0.1640\n",
      "     93        0.8341       0.6550        0.8225  0.1650\n",
      "     94        0.8338       0.6610        0.8243  0.1685\n",
      "     95        0.8549       0.6590        0.8240  0.1570\n",
      "     96        0.8377       0.6610        0.8264  0.1525\n",
      "     97        0.8358       0.6550        0.8264  0.1600\n",
      "     98        0.8320       0.6590        0.8229  0.1560\n",
      "     99        0.8403       0.6600        0.8219  0.1646\n",
      "    100        0.8340       0.6570        0.8255  0.1580\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8093\u001b[0m       \u001b[32m0.5260\u001b[0m        \u001b[35m0.9303\u001b[0m  0.1484\n",
      "      2        \u001b[36m0.7188\u001b[0m       \u001b[32m0.5520\u001b[0m        0.9820  0.1420\n",
      "      3        \u001b[36m0.6951\u001b[0m       \u001b[32m0.6220\u001b[0m        \u001b[35m0.7521\u001b[0m  0.1435\n",
      "      4        \u001b[36m0.6863\u001b[0m       \u001b[32m0.6290\u001b[0m        \u001b[35m0.7266\u001b[0m  0.1470\n",
      "      5        \u001b[36m0.6804\u001b[0m       \u001b[32m0.6430\u001b[0m        0.8250  0.1495\n",
      "      6        0.7026       \u001b[32m0.7120\u001b[0m        \u001b[35m0.6941\u001b[0m  0.1500\n",
      "      7        0.6808       0.6850        0.7529  0.1655\n",
      "      8        \u001b[36m0.6586\u001b[0m       0.7120        0.7172  0.1660\n",
      "      9        \u001b[36m0.6551\u001b[0m       0.6930        0.7360  0.1630\n",
      "     10        0.6559       \u001b[32m0.7370\u001b[0m        0.7043  0.1615\n",
      "     11        0.6579       0.7120        0.7348  0.1629\n",
      "     12        0.6605       0.6980        0.7761  0.1615\n",
      "     13        0.6883       0.6910        0.7399  0.1720\n",
      "     14        0.6972       0.7340        \u001b[35m0.6881\u001b[0m  0.1578\n",
      "     15        0.6592       0.6930        0.7001  0.1635\n",
      "     16        0.6567       0.6930        0.7210  0.1650\n",
      "     17        \u001b[36m0.6524\u001b[0m       0.7000        0.7298  0.1600\n",
      "     18        0.6562       0.6970        0.7285  0.1615\n",
      "     19        0.6576       0.7370        \u001b[35m0.6633\u001b[0m  0.1670\n",
      "     20        0.6624       0.6780        0.7955  0.1530\n",
      "     21        0.6787       0.7230        0.6998  0.1585\n",
      "     22        0.6694       \u001b[32m0.7470\u001b[0m        0.6817  0.1570\n",
      "     23        0.6761       0.6850        0.7952  0.1525\n",
      "     24        0.6599       0.7220        0.7222  0.1580\n",
      "     25        0.6795       0.7100        0.7190  0.1590\n",
      "     26        0.6533       0.6850        0.7218  0.1675\n",
      "     27        0.6695       \u001b[32m0.7500\u001b[0m        0.6847  0.1590\n",
      "     28        0.6763       0.7130        0.7052  0.1595\n",
      "     29        0.6657       0.7070        0.7092  0.1590\n",
      "     30        0.6879       0.7080        0.7352  0.1670\n",
      "     31        0.6805       0.6760        0.8166  0.1585\n",
      "     32        0.6922       0.6750        0.7876  0.1550\n",
      "     33        0.6653       0.7090        0.7280  0.1640\n",
      "     34        0.6730       0.7070        0.7393  0.1685\n",
      "     35        0.6649       0.7100        0.7220  0.1610\n",
      "     36        0.6676       0.6890        0.8004  0.1620\n",
      "     37        0.6770       0.6920        0.7399  0.1695\n",
      "     38        0.6863       0.7200        0.7102  0.1600\n",
      "     39        0.6840       0.7140        0.7524  0.1595\n",
      "     40        0.7185       0.6930        0.8238  0.1515\n",
      "     41        0.7154       0.7050        0.7892  0.1690\n",
      "     42        0.6610       0.6400        0.8096  0.1635\n",
      "     43        0.6849       0.7080        0.7124  0.1590\n",
      "     44        0.6839       0.6550        0.8668  0.1510\n",
      "     45        0.7050       0.6920        0.7358  0.1555\n",
      "     46        0.6968       0.7340        0.7249  0.1641\n",
      "     47        0.7026       0.7090        0.7604  0.1585\n",
      "     48        0.7083       0.5790        0.7880  0.1650\n",
      "     49        0.6911       0.7000        0.7313  0.1710\n",
      "     50        0.6884       0.6970        0.7703  0.1615\n",
      "     51        0.7333       0.7250        0.7167  0.1640\n",
      "     52        0.7090       0.7350        0.7221  0.1600\n",
      "     53        0.6917       0.7330        0.7203  0.1625\n",
      "     54        0.7225       0.7340        0.7016  0.1680\n",
      "     55        0.6898       0.5710        0.7530  0.1650\n",
      "     56        0.6909       0.5720        0.7829  0.1695\n",
      "     57        0.6941       0.7250        0.7331  0.1620\n",
      "     58        0.7015       0.7380        0.6945  0.1650\n",
      "     59        0.7055       0.7390        0.7107  0.1635\n",
      "     60        0.6853       0.7410        0.7100  0.1580\n",
      "     61        0.6884       0.7360        0.7246  0.1687\n",
      "     62        0.6873       0.5720        0.7581  0.1655\n",
      "     63        0.6935       0.7360        0.7062  0.1626\n",
      "     64        0.6846       0.5700        0.7267  0.1560\n",
      "     65        0.6927       0.7340        0.7211  0.1755\n",
      "     66        0.6873       0.7390        0.7131  0.1581\n",
      "     67        0.6869       0.5610        0.7684  0.1580\n",
      "     68        0.6957       0.7360        0.7274  0.1625\n",
      "     69        0.6894       0.5710        0.7347  0.1601\n",
      "     70        0.6932       0.5720        0.7553  0.1675\n",
      "     71        0.6907       0.5720        0.7249  0.1625\n",
      "     72        0.6829       0.7400        0.6934  0.1571\n",
      "     73        0.6910       0.7320        0.7283  0.1625\n",
      "     74        0.6954       0.7380        0.7151  0.1610\n",
      "     75        0.7361       0.7350        0.6910  0.1580\n",
      "     76        0.6838       0.7400        0.7152  0.1545\n",
      "     77        0.6878       0.7380        0.7174  0.1610\n",
      "     78        0.6894       0.7390        0.7031  0.1615\n",
      "     79        0.6930       0.4960        1.3376  0.1630\n",
      "     80        0.7176       0.7380        0.7048  0.1690\n",
      "     81        0.6828       0.5700        0.7527  0.1635\n",
      "     82        0.6844       0.7360        0.7220  0.1600\n",
      "     83        0.7320       0.7340        0.7297  0.1660\n",
      "     84        0.6870       0.5720        0.7231  0.1555\n",
      "     85        0.6849       0.7390        0.7140  0.1700\n",
      "     86        0.6854       0.7400        0.7166  0.1726\n",
      "     87        0.6845       0.5720        0.7640  0.1675\n",
      "     88        0.6848       0.5700        0.7432  0.1690\n",
      "     89        0.6853       0.7360        0.7369  0.1610\n",
      "     90        0.6880       0.5720        0.7495  0.1585\n",
      "     91        0.6857       0.5720        0.7290  0.1638\n",
      "     92        0.6842       0.5710        0.7379  0.1620\n",
      "     93        0.6828       0.7370        0.7139  0.1605\n",
      "     94        0.6815       0.5710        0.7345  0.1540\n",
      "     95        0.6868       0.5630        0.7307  0.1555\n",
      "     96        0.7257       0.5180        0.8739  0.1550\n",
      "     97        0.7456       0.7310        0.7402  0.1560\n",
      "     98        0.7035       0.7350        0.7241  0.1645\n",
      "     99        0.6863       0.5720        0.7470  0.1620\n",
      "    100        0.6935       0.7350        0.7344  0.1630\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.6171\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1320\n",
      "      2       10.6176       0.3340       10.6176  0.1383\n",
      "      3       10.6176       0.3340       10.6176  0.1310\n",
      "      4       10.6176       0.3340       10.6176  0.1345\n",
      "      5       10.6176       0.3340       10.6176  0.1335\n",
      "      6       10.6176       0.3340       10.6176  0.1290\n",
      "      7       10.6176       0.3340       10.6176  0.1325\n",
      "      8       10.6176       0.3340       10.6176  0.1365\n",
      "      9       10.6176       0.3340       10.6176  0.1340\n",
      "     10       10.6176       0.3340       10.6176  0.1325\n",
      "     11       10.6176       0.3340       10.6176  0.1365\n",
      "     12       10.6176       0.3340       10.6176  0.1390\n",
      "     13       10.6176       0.3340       10.6176  0.1325\n",
      "     14       10.6176       0.3340       10.6176  0.1345\n",
      "     15       10.6176       0.3340       10.6176  0.1360\n",
      "     16       10.6176       0.3340       10.6176  0.1335\n",
      "     17       10.6176       0.3340       10.6176  0.1341\n",
      "     18       10.6176       0.3340       10.6176  0.1355\n",
      "     19       10.6176       0.3340       10.6176  0.1345\n",
      "     20       10.6176       0.3340       10.6176  0.1280\n",
      "     21       10.6176       0.3340       10.6176  0.1325\n",
      "     22       10.6176       0.3340       10.6176  0.1305\n",
      "     23       10.6176       0.3340       10.6176  0.1360\n",
      "     24       10.6176       0.3340       10.6176  0.1315\n",
      "     25       10.6176       0.3340       10.6176  0.1295\n",
      "     26       10.6176       0.3340       10.6176  0.1290\n",
      "     27       10.6176       0.3340       10.6176  0.1295\n",
      "     28       10.6176       0.3340       10.6176  0.1305\n",
      "     29       10.6176       0.3340       10.6176  0.1380\n",
      "     30       10.6176       0.3340       10.6176  0.1335\n",
      "     31       10.6176       0.3340       10.6176  0.1355\n",
      "     32       10.6176       0.3340       10.6176  0.1350\n",
      "     33       10.6176       0.3340       10.6176  0.1295\n",
      "     34       10.6176       0.3340       10.6176  0.1305\n",
      "     35       10.6176       0.3340       10.6176  0.1392\n",
      "     36       10.6176       0.3340       10.6176  0.1325\n",
      "     37       10.6176       0.3340       10.6176  0.1275\n",
      "     38       10.6176       0.3340       10.6176  0.1480\n",
      "     39       10.6176       0.3340       10.6176  0.1325\n",
      "     40       10.6176       0.3340       10.6176  0.1576\n",
      "     41       10.6176       0.3340       10.6176  0.1325\n",
      "     42       10.6176       0.3340       10.6176  0.1315\n",
      "     43       10.6176       0.3340       10.6176  0.1431\n",
      "     44       10.6176       0.3340       10.6176  0.1335\n",
      "     45       10.6176       0.3340       10.6176  0.1415\n",
      "     46       10.6176       0.3340       10.6176  0.1345\n",
      "     47       10.6176       0.3340       10.6176  0.1460\n",
      "     48       10.6176       0.3340       10.6176  0.1355\n",
      "     49       10.6176       0.3340       10.6176  0.1441\n",
      "     50       10.6176       0.3340       10.6176  0.1310\n",
      "     51       10.6176       0.3340       10.6176  0.1345\n",
      "     52       10.6176       0.3340       10.6176  0.1510\n",
      "     53       10.6176       0.3340       10.6176  0.1445\n",
      "     54       10.6176       0.3340       10.6176  0.1355\n",
      "     55       10.6176       0.3340       10.6176  0.1360\n",
      "     56       10.6176       0.3340       10.6176  0.1385\n",
      "     57       10.6176       0.3340       10.6176  0.1460\n",
      "     58       10.6176       0.3340       10.6176  0.1520\n",
      "     59       10.6176       0.3340       10.6176  0.1450\n",
      "     60       10.6176       0.3340       10.6176  0.1545\n",
      "     61       10.6176       0.3340       10.6176  0.1410\n",
      "     62       10.6176       0.3340       10.6176  0.1505\n",
      "     63       10.6176       0.3340       10.6176  0.1426\n",
      "     64       10.6176       0.3340       10.6176  0.1435\n",
      "     65       10.6176       0.3340       10.6176  0.1550\n",
      "     66       10.6176       0.3340       10.6176  0.1511\n",
      "     67       10.6176       0.3340       10.6176  0.1360\n",
      "     68       10.6176       0.3340       10.6176  0.1505\n",
      "     69       10.6176       0.3340       10.6176  0.1540\n",
      "     70       10.6176       0.3340       10.6176  0.1455\n",
      "     71       10.6176       0.3340       10.6176  0.1420\n",
      "     72       10.6176       0.3340       10.6176  0.1475\n",
      "     73       10.6176       0.3340       10.6176  0.1455\n",
      "     74       10.6176       0.3340       10.6176  0.1435\n",
      "     75       10.6176       0.3340       10.6176  0.1515\n",
      "     76       10.6176       0.3340       10.6176  0.1490\n",
      "     77       10.6176       0.3340       10.6176  0.1445\n",
      "     78       10.6176       0.3340       10.6176  0.1480\n",
      "     79       10.6176       0.3340       10.6176  0.1475\n",
      "     80       10.6176       0.3340       10.6176  0.1470\n",
      "     81       10.6176       0.3340       10.6176  0.1485\n",
      "     82       10.6176       0.3340       10.6176  0.1610\n",
      "     83       10.6176       0.3340       10.6176  0.1415\n",
      "     84       10.6176       0.3340       10.6176  0.1485\n",
      "     85       10.6176       0.3340       10.6176  0.1485\n",
      "     86       10.6176       0.3340       10.6176  0.1445\n",
      "     87       10.6176       0.3340       10.6176  0.1465\n",
      "     88       10.6176       0.3340       10.6176  0.1410\n",
      "     89       10.6176       0.3340       10.6176  0.1405\n",
      "     90       10.6176       0.3340       10.6176  0.1480\n",
      "     91       10.6176       0.3340       10.6176  0.1635\n",
      "     92       10.6176       0.3340       10.6176  0.1490\n",
      "     93       10.6176       0.3340       10.6176  0.1385\n",
      "     94       10.6176       0.3340       10.6176  0.1500\n",
      "     95       10.6176       0.3340       10.6176  0.1505\n",
      "     96       10.6176       0.3340       10.6176  0.1570\n",
      "     97       10.6176       0.3340       10.6176  0.1550\n",
      "     98       10.6176       0.3340       10.6176  0.1435\n",
      "     99       10.6176       0.3340       10.6176  0.1485\n",
      "    100       10.6176       0.3340       10.6176  0.1530\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5667\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1305\n",
      "      2       10.6176       0.3340       10.6176  0.1255\n",
      "      3       10.6176       0.3340       10.6176  0.1270\n",
      "      4       10.6176       0.3340       10.6176  0.1375\n",
      "      5       10.6176       0.3340       10.6176  0.1315\n",
      "      6       10.6176       0.3340       10.6176  0.1340\n",
      "      7       10.6176       0.3340       10.6176  0.1275\n",
      "      8       10.6176       0.3340       10.6176  0.1345\n",
      "      9       10.6176       0.3340       10.6176  0.1370\n",
      "     10       10.6176       0.3340       10.6176  0.1355\n",
      "     11       10.6176       0.3340       10.6176  0.1320\n",
      "     12       10.6176       0.3340       10.6176  0.1335\n",
      "     13       10.6176       0.3340       10.6176  0.1375\n",
      "     14       10.6176       0.3340       10.6176  0.1430\n",
      "     15       10.6176       0.3340       10.6176  0.1385\n",
      "     16       10.6176       0.3340       10.6176  0.1330\n",
      "     17       10.6176       0.3340       10.6176  0.1425\n",
      "     18       10.6176       0.3340       10.6176  0.1385\n",
      "     19       10.6176       0.3340       10.6176  0.1420\n",
      "     20       10.6176       0.3340       10.6176  0.1395\n",
      "     21       10.6176       0.3340       10.6176  0.1380\n",
      "     22       10.6176       0.3340       10.6176  0.1395\n",
      "     23       10.6176       0.3340       10.6176  0.1355\n",
      "     24       10.6176       0.3340       10.6176  0.1300\n",
      "     25       10.6176       0.3340       10.6176  0.1365\n",
      "     26       10.6176       0.3340       10.6176  0.1335\n",
      "     27       10.6176       0.3340       10.6176  0.1350\n",
      "     28       10.6176       0.3340       10.6176  0.1285\n",
      "     29       10.6176       0.3340       10.6176  0.1360\n",
      "     30       10.6176       0.3340       10.6176  0.1355\n",
      "     31       10.6176       0.3340       10.6176  0.1265\n",
      "     32       10.6176       0.3340       10.6176  0.1350\n",
      "     33       10.6176       0.3340       10.6176  0.1475\n",
      "     34       10.6176       0.3340       10.6176  0.1355\n",
      "     35       10.6176       0.3340       10.6176  0.1380\n",
      "     36       10.6176       0.3340       10.6176  0.1305\n",
      "     37       10.6176       0.3340       10.6176  0.1345\n",
      "     38       10.6176       0.3340       10.6176  0.1360\n",
      "     39       10.6176       0.3340       10.6176  0.1365\n",
      "     40       10.6176       0.3340       10.6176  0.1300\n",
      "     41       10.6176       0.3340       10.6176  0.1355\n",
      "     42       10.6176       0.3340       10.6176  0.1335\n",
      "     43       10.6176       0.3340       10.6176  0.1506\n",
      "     44       10.6176       0.3340       10.6176  0.1365\n",
      "     45       10.6176       0.3340       10.6176  0.1391\n",
      "     46       10.6176       0.3340       10.6176  0.1365\n",
      "     47       10.6176       0.3340       10.6176  0.1355\n",
      "     48       10.6176       0.3340       10.6176  0.1466\n",
      "     49       10.6176       0.3340       10.6176  0.1535\n",
      "     50       10.6176       0.3340       10.6176  0.1400\n",
      "     51       10.6176       0.3340       10.6176  0.1405\n",
      "     52       10.6176       0.3340       10.6176  0.1460\n",
      "     53       10.6176       0.3340       10.6176  0.1405\n",
      "     54       10.6176       0.3340       10.6176  0.1431\n",
      "     55       10.6176       0.3340       10.6176  0.1515\n",
      "     56       10.6176       0.3340       10.6176  0.1430\n",
      "     57       10.6176       0.3340       10.6176  0.1485\n",
      "     58       10.6176       0.3340       10.6176  0.1385\n",
      "     59       10.6176       0.3340       10.6176  0.1510\n",
      "     60       10.6176       0.3340       10.6176  0.1435\n",
      "     61       10.6176       0.3340       10.6176  0.1500\n",
      "     62       10.6176       0.3340       10.6176  0.1435\n",
      "     63       10.6176       0.3340       10.6176  0.1419\n",
      "     64       10.6176       0.3340       10.6176  0.1455\n",
      "     65       10.6176       0.3340       10.6176  0.1440\n",
      "     66       10.6176       0.3340       10.6176  0.1425\n",
      "     67       10.6176       0.3340       10.6176  0.1420\n",
      "     68       10.6176       0.3340       10.6176  0.1425\n",
      "     69       10.6176       0.3340       10.6176  0.1450\n",
      "     70       10.6176       0.3340       10.6176  0.1405\n",
      "     71       10.6176       0.3340       10.6176  0.1435\n",
      "     72       10.6176       0.3340       10.6176  0.1450\n",
      "     73       10.6176       0.3340       10.6176  0.1445\n",
      "     74       10.6176       0.3340       10.6176  0.1470\n",
      "     75       10.6176       0.3340       10.6176  0.1395\n",
      "     76       10.6176       0.3340       10.6176  0.1540\n",
      "     77       10.6176       0.3340       10.6176  0.1455\n",
      "     78       10.6176       0.3340       10.6176  0.1490\n",
      "     79       10.6176       0.3340       10.6176  0.1495\n",
      "     80       10.6176       0.3340       10.6176  0.1450\n",
      "     81       10.6176       0.3340       10.6176  0.1455\n",
      "     82       10.6176       0.3340       10.6176  0.1460\n",
      "     83       10.6176       0.3340       10.6176  0.1485\n",
      "     84       10.6176       0.3340       10.6176  0.1490\n",
      "     85       10.6176       0.3340       10.6176  0.1435\n",
      "     86       10.6176       0.3340       10.6176  0.1510\n",
      "     87       10.6176       0.3340       10.6176  0.1455\n",
      "     88       10.6176       0.3340       10.6176  0.1490\n",
      "     89       10.6176       0.3340       10.6176  0.1485\n",
      "     90       10.6176       0.3340       10.6176  0.1450\n",
      "     91       10.6176       0.3340       10.6176  0.1475\n",
      "     92       10.6176       0.3340       10.6176  0.1460\n",
      "     93       10.6176       0.3340       10.6176  0.1525\n",
      "     94       10.6176       0.3340       10.6176  0.1450\n",
      "     95       10.6176       0.3340       10.6176  0.1515\n",
      "     96       10.6176       0.3340       10.6176  0.1450\n",
      "     97       10.6176       0.3340       10.6176  0.1415\n",
      "     98       10.6176       0.3340       10.6176  0.1570\n",
      "     99       10.6176       0.3340       10.6176  0.1375\n",
      "    100       10.6176       0.3340       10.6176  0.1385\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8232\u001b[0m       \u001b[32m0.6500\u001b[0m        \u001b[35m0.7348\u001b[0m  0.1055\n",
      "      2        \u001b[36m0.7032\u001b[0m       \u001b[32m0.6740\u001b[0m        \u001b[35m0.6955\u001b[0m  0.1110\n",
      "      3        \u001b[36m0.6672\u001b[0m       \u001b[32m0.6880\u001b[0m        \u001b[35m0.6769\u001b[0m  0.1065\n",
      "      4        \u001b[36m0.6477\u001b[0m       \u001b[32m0.6890\u001b[0m        \u001b[35m0.6762\u001b[0m  0.1015\n",
      "      5        \u001b[36m0.6347\u001b[0m       0.6890        \u001b[35m0.6735\u001b[0m  0.1055\n",
      "      6        \u001b[36m0.6261\u001b[0m       0.6860        \u001b[35m0.6696\u001b[0m  0.1015\n",
      "      7        \u001b[36m0.6184\u001b[0m       0.6860        \u001b[35m0.6564\u001b[0m  0.0955\n",
      "      8        \u001b[36m0.6118\u001b[0m       0.6820        0.6722  0.1055\n",
      "      9        \u001b[36m0.6103\u001b[0m       0.6850        0.6761  0.1075\n",
      "     10        \u001b[36m0.6077\u001b[0m       0.6820        0.6797  0.1025\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7949\u001b[0m       \u001b[32m0.6020\u001b[0m        \u001b[35m0.7914\u001b[0m  0.1055\n",
      "      2        \u001b[36m0.7015\u001b[0m       \u001b[32m0.6870\u001b[0m        \u001b[35m0.7014\u001b[0m  0.1045\n",
      "      3        \u001b[36m0.6566\u001b[0m       \u001b[32m0.7240\u001b[0m        \u001b[35m0.6631\u001b[0m  0.1065\n",
      "      4        \u001b[36m0.6383\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6318\u001b[0m  0.0985\n",
      "      5        \u001b[36m0.6257\u001b[0m       \u001b[32m0.7520\u001b[0m        \u001b[35m0.6170\u001b[0m  0.0985\n",
      "      6        \u001b[36m0.6192\u001b[0m       0.7440        \u001b[35m0.6122\u001b[0m  0.1035\n",
      "      7        \u001b[36m0.6150\u001b[0m       0.7500        \u001b[35m0.6051\u001b[0m  0.0965\n",
      "      8        \u001b[36m0.6116\u001b[0m       \u001b[32m0.7540\u001b[0m        \u001b[35m0.6026\u001b[0m  0.0985\n",
      "      9        \u001b[36m0.6059\u001b[0m       \u001b[32m0.7550\u001b[0m        \u001b[35m0.5995\u001b[0m  0.1025\n",
      "     10        \u001b[36m0.6013\u001b[0m       \u001b[32m0.7570\u001b[0m        \u001b[35m0.5984\u001b[0m  0.1065\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9388\u001b[0m       \u001b[32m0.6990\u001b[0m        \u001b[35m0.7289\u001b[0m  0.0965\n",
      "      2        \u001b[36m0.7057\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6761\u001b[0m  0.0935\n",
      "      3        \u001b[36m0.6631\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.6573\u001b[0m  0.0935\n",
      "      4        \u001b[36m0.6437\u001b[0m       \u001b[32m0.7170\u001b[0m        \u001b[35m0.6497\u001b[0m  0.1025\n",
      "      5        \u001b[36m0.6338\u001b[0m       0.7170        \u001b[35m0.6431\u001b[0m  0.0955\n",
      "      6        \u001b[36m0.6260\u001b[0m       0.7160        \u001b[35m0.6364\u001b[0m  0.0925\n",
      "      7        \u001b[36m0.6183\u001b[0m       \u001b[32m0.7260\u001b[0m        \u001b[35m0.6331\u001b[0m  0.0985\n",
      "      8        \u001b[36m0.6137\u001b[0m       \u001b[32m0.7280\u001b[0m        \u001b[35m0.6285\u001b[0m  0.0935\n",
      "      9        \u001b[36m0.6091\u001b[0m       \u001b[32m0.7300\u001b[0m        0.6296  0.0995\n",
      "     10        \u001b[36m0.6064\u001b[0m       0.7250        \u001b[35m0.6267\u001b[0m  0.0915\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9056\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.6084\u001b[0m  0.0915\n",
      "      2        \u001b[36m0.7229\u001b[0m       \u001b[32m0.5060\u001b[0m        \u001b[35m0.9344\u001b[0m  0.1005\n",
      "      3        \u001b[36m0.6655\u001b[0m       \u001b[32m0.5480\u001b[0m        \u001b[35m0.8922\u001b[0m  0.0915\n",
      "      4        \u001b[36m0.6502\u001b[0m       \u001b[32m0.5990\u001b[0m        \u001b[35m0.8351\u001b[0m  0.0985\n",
      "      5        \u001b[36m0.6383\u001b[0m       \u001b[32m0.6270\u001b[0m        \u001b[35m0.8161\u001b[0m  0.0955\n",
      "      6        \u001b[36m0.6318\u001b[0m       \u001b[32m0.6400\u001b[0m        \u001b[35m0.7891\u001b[0m  0.0985\n",
      "      7        \u001b[36m0.6260\u001b[0m       \u001b[32m0.6470\u001b[0m        \u001b[35m0.7805\u001b[0m  0.0945\n",
      "      8        \u001b[36m0.6226\u001b[0m       \u001b[32m0.6610\u001b[0m        \u001b[35m0.7639\u001b[0m  0.0915\n",
      "      9        \u001b[36m0.6185\u001b[0m       \u001b[32m0.6730\u001b[0m        \u001b[35m0.7598\u001b[0m  0.1015\n",
      "     10        \u001b[36m0.6154\u001b[0m       0.6670        0.7623  0.1005\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8331\u001b[0m       \u001b[32m0.6690\u001b[0m        \u001b[35m0.7338\u001b[0m  0.0995\n",
      "      2        \u001b[36m0.7020\u001b[0m       \u001b[32m0.6940\u001b[0m        \u001b[35m0.6835\u001b[0m  0.1005\n",
      "      3        \u001b[36m0.6673\u001b[0m       \u001b[32m0.7060\u001b[0m        \u001b[35m0.6678\u001b[0m  0.1025\n",
      "      4        \u001b[36m0.6468\u001b[0m       0.7050        \u001b[35m0.6509\u001b[0m  0.1035\n",
      "      5        \u001b[36m0.6335\u001b[0m       0.7040        \u001b[35m0.6409\u001b[0m  0.1035\n",
      "      6        \u001b[36m0.6226\u001b[0m       0.7040        0.6418  0.1035\n",
      "      7        \u001b[36m0.6172\u001b[0m       0.7030        0.6494  0.1025\n",
      "      8        \u001b[36m0.6120\u001b[0m       0.7050        0.6451  0.0975\n",
      "      9        \u001b[36m0.6078\u001b[0m       \u001b[32m0.7090\u001b[0m        0.6436  0.1115\n",
      "     10        \u001b[36m0.6019\u001b[0m       \u001b[32m0.7170\u001b[0m        0.6440  0.1040\n",
      "     11        \u001b[36m0.6014\u001b[0m       0.7070        0.6422  0.1125\n",
      "     12        \u001b[36m0.5974\u001b[0m       0.7070        0.6421  0.1025\n",
      "     13        \u001b[36m0.5957\u001b[0m       0.7070        0.6413  0.1115\n",
      "     14        \u001b[36m0.5919\u001b[0m       0.7060        0.6441  0.1225\n",
      "     15        \u001b[36m0.5905\u001b[0m       0.7100        0.6441  0.1065\n",
      "     16        \u001b[36m0.5879\u001b[0m       0.7090        0.6457  0.1085\n",
      "     17        \u001b[36m0.5863\u001b[0m       0.7130        0.6497  0.1125\n",
      "     18        \u001b[36m0.5852\u001b[0m       0.7070        0.6556  0.1080\n",
      "     19        0.5865       0.7120        0.6555  0.1095\n",
      "     20        \u001b[36m0.5836\u001b[0m       0.7070        0.6662  0.1055\n",
      "     21        \u001b[36m0.5823\u001b[0m       0.7060        0.6659  0.1055\n",
      "     22        \u001b[36m0.5798\u001b[0m       0.7030        0.6707  0.1015\n",
      "     23        0.5805       0.7100        0.6608  0.1075\n",
      "     24        \u001b[36m0.5737\u001b[0m       0.7130        0.6658  0.1055\n",
      "     25        0.5739       0.7100        0.6628  0.1025\n",
      "     26        \u001b[36m0.5724\u001b[0m       0.7070        0.6725  0.1025\n",
      "     27        0.5727       0.7080        0.6722  0.0995\n",
      "     28        \u001b[36m0.5694\u001b[0m       0.7170        0.6737  0.1025\n",
      "     29        \u001b[36m0.5674\u001b[0m       0.7120        0.6649  0.1075\n",
      "     30        \u001b[36m0.5672\u001b[0m       0.7140        0.6704  0.1015\n",
      "     31        \u001b[36m0.5655\u001b[0m       0.7110        0.6672  0.1055\n",
      "     32        \u001b[36m0.5651\u001b[0m       0.7100        0.6684  0.1045\n",
      "     33        \u001b[36m0.5635\u001b[0m       0.7050        0.6848  0.1045\n",
      "     34        \u001b[36m0.5624\u001b[0m       0.7030        0.6727  0.1055\n",
      "     35        0.5627       0.7030        0.6726  0.1040\n",
      "     36        0.5631       0.7010        0.6704  0.1135\n",
      "     37        0.5631       0.7050        0.6781  0.1104\n",
      "     38        \u001b[36m0.5566\u001b[0m       0.7010        0.6771  0.1035\n",
      "     39        \u001b[36m0.5548\u001b[0m       0.6910        0.6838  0.1035\n",
      "     40        \u001b[36m0.5532\u001b[0m       0.7030        0.6976  0.1065\n",
      "     41        \u001b[36m0.5497\u001b[0m       0.7030        0.6901  0.1065\n",
      "     42        \u001b[36m0.5480\u001b[0m       0.7080        0.6895  0.1105\n",
      "     43        0.5485       0.7110        0.6873  0.1085\n",
      "     44        0.5494       0.7100        0.6828  0.1190\n",
      "     45        \u001b[36m0.5478\u001b[0m       0.7030        0.6736  0.1115\n",
      "     46        \u001b[36m0.5464\u001b[0m       0.7120        0.6847  0.1145\n",
      "     47        \u001b[36m0.5438\u001b[0m       \u001b[32m0.7210\u001b[0m        0.6739  0.1005\n",
      "     48        \u001b[36m0.5431\u001b[0m       0.7210        0.6876  0.1125\n",
      "     49        \u001b[36m0.5418\u001b[0m       \u001b[32m0.7260\u001b[0m        0.6890  0.1085\n",
      "     50        \u001b[36m0.5415\u001b[0m       0.7220        0.6928  0.1125\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7848\u001b[0m       \u001b[32m0.6260\u001b[0m        \u001b[35m0.7749\u001b[0m  0.1055\n",
      "      2        \u001b[36m0.6997\u001b[0m       \u001b[32m0.6710\u001b[0m        \u001b[35m0.7233\u001b[0m  0.1035\n",
      "      3        \u001b[36m0.6664\u001b[0m       \u001b[32m0.7110\u001b[0m        \u001b[35m0.6809\u001b[0m  0.1055\n",
      "      4        \u001b[36m0.6469\u001b[0m       \u001b[32m0.7380\u001b[0m        \u001b[35m0.6505\u001b[0m  0.0955\n",
      "      5        \u001b[36m0.6344\u001b[0m       \u001b[32m0.7540\u001b[0m        \u001b[35m0.6203\u001b[0m  0.0975\n",
      "      6        \u001b[36m0.6236\u001b[0m       0.7470        \u001b[35m0.6191\u001b[0m  0.1045\n",
      "      7        \u001b[36m0.6224\u001b[0m       0.7500        \u001b[35m0.6121\u001b[0m  0.1005\n",
      "      8        \u001b[36m0.6152\u001b[0m       \u001b[32m0.7570\u001b[0m        0.6122  0.1015\n",
      "      9        \u001b[36m0.6107\u001b[0m       0.7550        \u001b[35m0.6103\u001b[0m  0.1075\n",
      "     10        \u001b[36m0.6072\u001b[0m       0.7490        \u001b[35m0.6076\u001b[0m  0.1035\n",
      "     11        \u001b[36m0.6027\u001b[0m       0.7510        \u001b[35m0.6028\u001b[0m  0.1035\n",
      "     12        \u001b[36m0.5993\u001b[0m       0.7540        \u001b[35m0.6007\u001b[0m  0.1080\n",
      "     13        \u001b[36m0.5962\u001b[0m       \u001b[32m0.7640\u001b[0m        \u001b[35m0.5914\u001b[0m  0.1085\n",
      "     14        \u001b[36m0.5923\u001b[0m       0.7610        0.5984  0.0995\n",
      "     15        \u001b[36m0.5905\u001b[0m       0.7610        0.5977  0.1145\n",
      "     16        \u001b[36m0.5880\u001b[0m       0.7550        0.5972  0.1055\n",
      "     17        \u001b[36m0.5870\u001b[0m       0.7540        0.5964  0.0955\n",
      "     18        \u001b[36m0.5840\u001b[0m       0.7520        0.6034  0.1075\n",
      "     19        \u001b[36m0.5834\u001b[0m       0.7420        0.6109  0.1035\n",
      "     20        \u001b[36m0.5812\u001b[0m       0.7630        0.5981  0.1055\n",
      "     21        \u001b[36m0.5791\u001b[0m       \u001b[32m0.7680\u001b[0m        0.5948  0.1215\n",
      "     22        0.5793       0.7660        \u001b[35m0.5903\u001b[0m  0.1005\n",
      "     23        \u001b[36m0.5769\u001b[0m       0.7640        0.5943  0.1015\n",
      "     24        \u001b[36m0.5741\u001b[0m       0.7650        0.5918  0.1105\n",
      "     25        \u001b[36m0.5732\u001b[0m       0.7600        0.5969  0.1055\n",
      "     26        \u001b[36m0.5698\u001b[0m       0.7580        0.6015  0.1095\n",
      "     27        \u001b[36m0.5689\u001b[0m       0.7660        0.6029  0.1105\n",
      "     28        \u001b[36m0.5654\u001b[0m       0.7590        0.6006  0.1135\n",
      "     29        0.5654       0.7580        0.5985  0.1025\n",
      "     30        0.5663       0.7590        0.5981  0.0955\n",
      "     31        \u001b[36m0.5632\u001b[0m       0.7650        0.5935  0.1015\n",
      "     32        \u001b[36m0.5614\u001b[0m       0.7520        0.5995  0.1125\n",
      "     33        \u001b[36m0.5602\u001b[0m       0.7560        0.5981  0.1125\n",
      "     34        \u001b[36m0.5582\u001b[0m       0.7620        0.5991  0.1065\n",
      "     35        \u001b[36m0.5540\u001b[0m       0.7510        0.6025  0.1055\n",
      "     36        \u001b[36m0.5529\u001b[0m       0.7590        0.6022  0.1035\n",
      "     37        \u001b[36m0.5516\u001b[0m       0.7430        0.6105  0.1055\n",
      "     38        \u001b[36m0.5514\u001b[0m       0.7500        0.6168  0.1065\n",
      "     39        \u001b[36m0.5461\u001b[0m       0.7410        0.6132  0.1135\n",
      "     40        0.5472       0.7410        0.6149  0.1035\n",
      "     41        0.5472       0.7480        0.6134  0.1135\n",
      "     42        0.5467       0.7410        0.6240  0.1065\n",
      "     43        \u001b[36m0.5438\u001b[0m       0.7420        0.6250  0.1055\n",
      "     44        0.5450       0.7450        0.6167  0.0985\n",
      "     45        0.5441       0.7380        0.6227  0.1075\n",
      "     46        \u001b[36m0.5437\u001b[0m       0.7440        0.6206  0.1112\n",
      "     47        \u001b[36m0.5393\u001b[0m       0.7290        0.6245  0.1015\n",
      "     48        \u001b[36m0.5359\u001b[0m       0.7410        0.6265  0.1065\n",
      "     49        \u001b[36m0.5336\u001b[0m       0.7300        0.6357  0.1050\n",
      "     50        \u001b[36m0.5316\u001b[0m       0.7350        0.6305  0.1085\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8917\u001b[0m       \u001b[32m0.7030\u001b[0m        \u001b[35m0.7191\u001b[0m  0.0956\n",
      "      2        \u001b[36m0.7004\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6846\u001b[0m  0.0935\n",
      "      3        \u001b[36m0.6697\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.6537\u001b[0m  0.0885\n",
      "      4        \u001b[36m0.6517\u001b[0m       \u001b[32m0.7170\u001b[0m        \u001b[35m0.6488\u001b[0m  0.0995\n",
      "      5        \u001b[36m0.6402\u001b[0m       \u001b[32m0.7190\u001b[0m        \u001b[35m0.6470\u001b[0m  0.1025\n",
      "      6        \u001b[36m0.6323\u001b[0m       \u001b[32m0.7270\u001b[0m        \u001b[35m0.6460\u001b[0m  0.0975\n",
      "      7        \u001b[36m0.6250\u001b[0m       0.7210        \u001b[35m0.6431\u001b[0m  0.1005\n",
      "      8        \u001b[36m0.6201\u001b[0m       0.7200        0.6441  0.0965\n",
      "      9        \u001b[36m0.6191\u001b[0m       0.7230        \u001b[35m0.6374\u001b[0m  0.0935\n",
      "     10        \u001b[36m0.6128\u001b[0m       0.7180        \u001b[35m0.6373\u001b[0m  0.0955\n",
      "     11        \u001b[36m0.6073\u001b[0m       \u001b[32m0.7300\u001b[0m        0.6422  0.0915\n",
      "     12        \u001b[36m0.6064\u001b[0m       0.7260        0.6412  0.0965\n",
      "     13        \u001b[36m0.6019\u001b[0m       0.7270        0.6503  0.1005\n",
      "     14        \u001b[36m0.5991\u001b[0m       0.7290        \u001b[35m0.6364\u001b[0m  0.1055\n",
      "     15        \u001b[36m0.5957\u001b[0m       0.7290        0.6386  0.0965\n",
      "     16        \u001b[36m0.5944\u001b[0m       \u001b[32m0.7330\u001b[0m        0.6460  0.0925\n",
      "     17        \u001b[36m0.5929\u001b[0m       0.7260        0.6434  0.0885\n",
      "     18        \u001b[36m0.5922\u001b[0m       \u001b[32m0.7370\u001b[0m        0.6450  0.0925\n",
      "     19        \u001b[36m0.5916\u001b[0m       0.7340        0.6383  0.0965\n",
      "     20        \u001b[36m0.5880\u001b[0m       0.7320        \u001b[35m0.6349\u001b[0m  0.0875\n",
      "     21        \u001b[36m0.5866\u001b[0m       0.7340        0.6412  0.1005\n",
      "     22        \u001b[36m0.5843\u001b[0m       \u001b[32m0.7380\u001b[0m        0.6399  0.1085\n",
      "     23        \u001b[36m0.5816\u001b[0m       \u001b[32m0.7390\u001b[0m        0.6436  0.0965\n",
      "     24        \u001b[36m0.5811\u001b[0m       0.7370        0.6484  0.0915\n",
      "     25        \u001b[36m0.5808\u001b[0m       0.7310        0.6557  0.0945\n",
      "     26        \u001b[36m0.5757\u001b[0m       0.7320        0.6488  0.0925\n",
      "     27        \u001b[36m0.5729\u001b[0m       0.7310        0.6558  0.0935\n",
      "     28        \u001b[36m0.5711\u001b[0m       0.7220        0.6507  0.0945\n",
      "     29        \u001b[36m0.5705\u001b[0m       0.7320        0.6495  0.0905\n",
      "     30        \u001b[36m0.5660\u001b[0m       0.7240        0.6619  0.1005\n",
      "     31        \u001b[36m0.5644\u001b[0m       0.7280        0.6550  0.0995\n",
      "     32        \u001b[36m0.5616\u001b[0m       0.7200        0.6502  0.0955\n",
      "     33        \u001b[36m0.5615\u001b[0m       0.7290        0.6550  0.0995\n",
      "     34        \u001b[36m0.5571\u001b[0m       0.7270        0.6705  0.0985\n",
      "     35        \u001b[36m0.5561\u001b[0m       0.7240        0.6553  0.0995\n",
      "     36        \u001b[36m0.5534\u001b[0m       0.7240        0.6631  0.0975\n",
      "     37        \u001b[36m0.5527\u001b[0m       0.7200        0.6615  0.0985\n",
      "     38        \u001b[36m0.5506\u001b[0m       0.7200        0.6612  0.0945\n",
      "     39        0.5509       0.7170        0.6658  0.0985\n",
      "     40        \u001b[36m0.5485\u001b[0m       0.7160        0.6606  0.0935\n",
      "     41        \u001b[36m0.5451\u001b[0m       0.7200        0.6662  0.1035\n",
      "     42        \u001b[36m0.5446\u001b[0m       0.7220        0.6633  0.0995\n",
      "     43        0.5462       0.7210        0.6653  0.0985\n",
      "     44        \u001b[36m0.5440\u001b[0m       0.7240        0.6710  0.1015\n",
      "     45        \u001b[36m0.5397\u001b[0m       0.7110        0.6818  0.0965\n",
      "     46        \u001b[36m0.5366\u001b[0m       0.7170        0.6839  0.0985\n",
      "     47        0.5402       0.7160        0.6830  0.1005\n",
      "     48        0.5388       0.7090        0.6957  0.0935\n",
      "     49        0.5380       0.7110        0.6944  0.0975\n",
      "     50        0.5377       0.7150        0.7013  0.0985\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8440\u001b[0m       \u001b[32m0.4910\u001b[0m        \u001b[35m1.0579\u001b[0m  0.0965\n",
      "      2        \u001b[36m0.7022\u001b[0m       \u001b[32m0.5460\u001b[0m        \u001b[35m0.9130\u001b[0m  0.1005\n",
      "      3        \u001b[36m0.6603\u001b[0m       \u001b[32m0.5890\u001b[0m        \u001b[35m0.8505\u001b[0m  0.0955\n",
      "      4        \u001b[36m0.6391\u001b[0m       \u001b[32m0.6370\u001b[0m        \u001b[35m0.8210\u001b[0m  0.0915\n",
      "      5        \u001b[36m0.6298\u001b[0m       \u001b[32m0.6610\u001b[0m        \u001b[35m0.7916\u001b[0m  0.0955\n",
      "      6        \u001b[36m0.6234\u001b[0m       \u001b[32m0.6730\u001b[0m        \u001b[35m0.7756\u001b[0m  0.1005\n",
      "      7        \u001b[36m0.6181\u001b[0m       \u001b[32m0.6790\u001b[0m        \u001b[35m0.7686\u001b[0m  0.0965\n",
      "      8        \u001b[36m0.6165\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m0.7626\u001b[0m  0.0915\n",
      "      9        \u001b[36m0.6122\u001b[0m       0.6760        \u001b[35m0.7585\u001b[0m  0.0945\n",
      "     10        \u001b[36m0.6080\u001b[0m       0.6810        \u001b[35m0.7504\u001b[0m  0.0985\n",
      "     11        \u001b[36m0.6049\u001b[0m       0.6820        \u001b[35m0.7475\u001b[0m  0.0995\n",
      "     12        \u001b[36m0.6030\u001b[0m       \u001b[32m0.6880\u001b[0m        \u001b[35m0.7391\u001b[0m  0.0955\n",
      "     13        \u001b[36m0.6008\u001b[0m       \u001b[32m0.6930\u001b[0m        \u001b[35m0.7280\u001b[0m  0.0935\n",
      "     14        \u001b[36m0.5982\u001b[0m       0.6750        0.7365  0.0915\n",
      "     15        \u001b[36m0.5953\u001b[0m       0.6850        0.7307  0.1015\n",
      "     16        \u001b[36m0.5941\u001b[0m       0.6910        \u001b[35m0.7257\u001b[0m  0.0985\n",
      "     17        \u001b[36m0.5910\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.7157\u001b[0m  0.0975\n",
      "     18        \u001b[36m0.5903\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.7066\u001b[0m  0.0975\n",
      "     19        \u001b[36m0.5890\u001b[0m       0.6940        0.7134  0.1035\n",
      "     20        0.5895       0.6870        0.7086  0.1005\n",
      "     21        \u001b[36m0.5849\u001b[0m       0.6960        \u001b[35m0.7050\u001b[0m  0.1045\n",
      "     22        \u001b[36m0.5832\u001b[0m       0.6890        0.7093  0.1145\n",
      "     23        0.5862       0.6740        0.7157  0.1005\n",
      "     24        \u001b[36m0.5808\u001b[0m       0.6930        0.7162  0.1045\n",
      "     25        \u001b[36m0.5779\u001b[0m       0.6910        0.7147  0.0945\n",
      "     26        0.5792       0.6960        0.7082  0.0995\n",
      "     27        \u001b[36m0.5774\u001b[0m       0.6900        0.7150  0.0955\n",
      "     28        \u001b[36m0.5751\u001b[0m       0.6980        0.7084  0.0945\n",
      "     29        0.5758       0.6910        0.7216  0.0965\n",
      "     30        \u001b[36m0.5721\u001b[0m       0.6830        0.7147  0.0955\n",
      "     31        \u001b[36m0.5701\u001b[0m       0.7020        0.7153  0.0855\n",
      "     32        0.5711       0.6800        0.7242  0.1015\n",
      "     33        \u001b[36m0.5694\u001b[0m       0.6700        0.7628  0.0945\n",
      "     34        0.5722       0.6910        0.7182  0.1015\n",
      "     35        \u001b[36m0.5662\u001b[0m       0.6870        0.7250  0.0975\n",
      "     36        0.5667       0.6690        0.7803  0.0945\n",
      "     37        0.5690       0.6890        0.7233  0.0925\n",
      "     38        \u001b[36m0.5635\u001b[0m       0.6860        0.7412  0.0925\n",
      "     39        0.5641       0.6980        0.7194  0.0905\n",
      "     40        \u001b[36m0.5593\u001b[0m       0.7050        0.7107  0.1005\n",
      "     41        0.5596       0.7010        \u001b[35m0.7020\u001b[0m  0.0975\n",
      "     42        0.5602       \u001b[32m0.7220\u001b[0m        \u001b[35m0.6886\u001b[0m  0.0985\n",
      "     43        \u001b[36m0.5584\u001b[0m       0.6990        0.7019  0.0975\n",
      "     44        \u001b[36m0.5548\u001b[0m       0.7190        0.6918  0.0975\n",
      "     45        0.5580       0.7000        0.6933  0.0985\n",
      "     46        0.5561       0.7210        0.6899  0.0985\n",
      "     47        \u001b[36m0.5508\u001b[0m       0.6940        0.7151  0.0995\n",
      "     48        0.5550       0.7200        \u001b[35m0.6862\u001b[0m  0.1025\n",
      "     49        0.5519       0.6950        0.7424  0.1005\n",
      "     50        0.5531       0.7100        \u001b[35m0.6819\u001b[0m  0.0925\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8405\u001b[0m       \u001b[32m0.6600\u001b[0m        \u001b[35m0.7353\u001b[0m  0.1035\n",
      "      2        \u001b[36m0.7009\u001b[0m       \u001b[32m0.6850\u001b[0m        \u001b[35m0.6936\u001b[0m  0.1095\n",
      "      3        \u001b[36m0.6688\u001b[0m       \u001b[32m0.6920\u001b[0m        \u001b[35m0.6754\u001b[0m  0.1095\n",
      "      4        \u001b[36m0.6507\u001b[0m       \u001b[32m0.6960\u001b[0m        \u001b[35m0.6678\u001b[0m  0.1005\n",
      "      5        \u001b[36m0.6381\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.6594\u001b[0m  0.1045\n",
      "      6        \u001b[36m0.6289\u001b[0m       0.6920        \u001b[35m0.6592\u001b[0m  0.1005\n",
      "      7        \u001b[36m0.6222\u001b[0m       0.6910        \u001b[35m0.6575\u001b[0m  0.1025\n",
      "      8        \u001b[36m0.6179\u001b[0m       0.6840        0.6726  0.1025\n",
      "      9        \u001b[36m0.6154\u001b[0m       0.6870        0.6719  0.1075\n",
      "     10        \u001b[36m0.6118\u001b[0m       0.6910        0.6815  0.1096\n",
      "     11        \u001b[36m0.6088\u001b[0m       0.6870        0.6841  0.1080\n",
      "     12        \u001b[36m0.6048\u001b[0m       0.6970        0.6774  0.1050\n",
      "     13        \u001b[36m0.6012\u001b[0m       0.6970        0.6774  0.1115\n",
      "     14        \u001b[36m0.5983\u001b[0m       \u001b[32m0.7100\u001b[0m        0.6758  0.1025\n",
      "     15        \u001b[36m0.5947\u001b[0m       \u001b[32m0.7110\u001b[0m        0.6741  0.1095\n",
      "     16        \u001b[36m0.5901\u001b[0m       0.7100        0.6609  0.1095\n",
      "     17        \u001b[36m0.5872\u001b[0m       0.7070        0.6689  0.1125\n",
      "     18        \u001b[36m0.5860\u001b[0m       0.7080        0.6633  0.1145\n",
      "     19        \u001b[36m0.5831\u001b[0m       0.7090        0.6651  0.1065\n",
      "     20        \u001b[36m0.5804\u001b[0m       0.7060        0.6641  0.1070\n",
      "     21        \u001b[36m0.5786\u001b[0m       \u001b[32m0.7120\u001b[0m        0.6634  0.1065\n",
      "     22        \u001b[36m0.5749\u001b[0m       0.7120        0.6727  0.1105\n",
      "     23        \u001b[36m0.5730\u001b[0m       \u001b[32m0.7170\u001b[0m        0.6667  0.1245\n",
      "     24        \u001b[36m0.5710\u001b[0m       0.7150        0.6786  0.1115\n",
      "     25        0.5711       \u001b[32m0.7220\u001b[0m        0.6744  0.1045\n",
      "     26        \u001b[36m0.5694\u001b[0m       \u001b[32m0.7260\u001b[0m        0.6858  0.1015\n",
      "     27        \u001b[36m0.5690\u001b[0m       0.7210        0.6747  0.1015\n",
      "     28        \u001b[36m0.5671\u001b[0m       0.7250        0.6694  0.1031\n",
      "     29        0.5674       0.7190        0.6877  0.1085\n",
      "     30        \u001b[36m0.5658\u001b[0m       0.7170        0.6809  0.1105\n",
      "     31        \u001b[36m0.5616\u001b[0m       0.7250        0.6839  0.1105\n",
      "     32        0.5643       0.7210        0.6895  0.1075\n",
      "     33        \u001b[36m0.5609\u001b[0m       0.7220        0.6812  0.1055\n",
      "     34        \u001b[36m0.5603\u001b[0m       0.7180        0.6767  0.1055\n",
      "     35        \u001b[36m0.5584\u001b[0m       0.7200        0.6732  0.1095\n",
      "     36        \u001b[36m0.5533\u001b[0m       0.7170        0.6841  0.1065\n",
      "     37        \u001b[36m0.5526\u001b[0m       0.7250        0.6818  0.1065\n",
      "     38        \u001b[36m0.5522\u001b[0m       0.7150        0.6700  0.1005\n",
      "     39        \u001b[36m0.5517\u001b[0m       0.7110        0.6764  0.1025\n",
      "     40        0.5523       0.7130        0.6750  0.1065\n",
      "     41        \u001b[36m0.5483\u001b[0m       0.7220        0.6689  0.1075\n",
      "     42        0.5486       0.7080        0.6654  0.1150\n",
      "     43        \u001b[36m0.5469\u001b[0m       0.7180        \u001b[35m0.6564\u001b[0m  0.1055\n",
      "     44        0.5473       0.7110        0.6827  0.1085\n",
      "     45        0.5507       0.7040        0.6706  0.1045\n",
      "     46        \u001b[36m0.5412\u001b[0m       0.7070        0.6938  0.1112\n",
      "     47        0.5419       0.7210        0.6726  0.1131\n",
      "     48        \u001b[36m0.5366\u001b[0m       0.7080        0.7068  0.1115\n",
      "     49        \u001b[36m0.5342\u001b[0m       0.7120        0.6909  0.1005\n",
      "     50        \u001b[36m0.5328\u001b[0m       0.7110        0.6990  0.1085\n",
      "     51        0.5330       0.7090        0.7000  0.1085\n",
      "     52        \u001b[36m0.5315\u001b[0m       0.7010        0.6949  0.1092\n",
      "     53        \u001b[36m0.5278\u001b[0m       0.7100        0.6940  0.1060\n",
      "     54        0.5291       0.7050        0.6924  0.1045\n",
      "     55        0.5296       0.7080        0.7009  0.1085\n",
      "     56        0.5336       0.7210        0.7097  0.1005\n",
      "     57        \u001b[36m0.5278\u001b[0m       0.7110        0.7085  0.1015\n",
      "     58        \u001b[36m0.5274\u001b[0m       0.7120        0.7050  0.1035\n",
      "     59        0.5303       0.7090        0.6966  0.1045\n",
      "     60        \u001b[36m0.5234\u001b[0m       0.6990        0.7284  0.1065\n",
      "     61        0.5268       0.7030        0.7085  0.1175\n",
      "     62        0.5238       0.6880        0.7103  0.1060\n",
      "     63        \u001b[36m0.5219\u001b[0m       0.7010        0.7396  0.1035\n",
      "     64        \u001b[36m0.5188\u001b[0m       0.6950        0.7102  0.1065\n",
      "     65        0.5195       0.7060        0.7335  0.1032\n",
      "     66        \u001b[36m0.5167\u001b[0m       0.6890        0.7158  0.1065\n",
      "     67        0.5199       0.7110        0.7416  0.1106\n",
      "     68        0.5219       0.7110        0.7318  0.1135\n",
      "     69        0.5217       0.7090        0.7202  0.1125\n",
      "     70        \u001b[36m0.5162\u001b[0m       0.6980        0.6940  0.1185\n",
      "     71        0.5198       0.7000        0.7038  0.1035\n",
      "     72        0.5219       0.7060        0.7114  0.1075\n",
      "     73        0.5183       0.7100        0.7316  0.1115\n",
      "     74        \u001b[36m0.5150\u001b[0m       0.7040        0.7387  0.1065\n",
      "     75        \u001b[36m0.5086\u001b[0m       0.7070        0.7784  0.1015\n",
      "     76        0.5108       0.7000        0.7769  0.1070\n",
      "     77        0.5243       0.6930        0.7190  0.0995\n",
      "     78        0.5168       0.7110        0.7042  0.1135\n",
      "     79        \u001b[36m0.5048\u001b[0m       0.7040        0.7128  0.0980\n",
      "     80        \u001b[36m0.5018\u001b[0m       0.7020        0.7224  0.1075\n",
      "     81        0.5035       0.7010        0.7409  0.1075\n",
      "     82        0.5033       0.6960        0.7297  0.1115\n",
      "     83        0.5042       0.6960        0.7133  0.1075\n",
      "     84        \u001b[36m0.5005\u001b[0m       0.6940        0.7382  0.1085\n",
      "     85        0.5052       0.7120        0.7591  0.1055\n",
      "     86        0.5016       0.7080        0.7494  0.1055\n",
      "     87        \u001b[36m0.4962\u001b[0m       0.6940        0.7529  0.1095\n",
      "     88        \u001b[36m0.4933\u001b[0m       0.6940        0.7639  0.1110\n",
      "     89        \u001b[36m0.4869\u001b[0m       0.6960        0.7583  0.1085\n",
      "     90        0.4910       0.7070        0.7329  0.1105\n",
      "     91        \u001b[36m0.4857\u001b[0m       0.6990        0.7320  0.1005\n",
      "     92        \u001b[36m0.4853\u001b[0m       0.7050        0.7634  0.1075\n",
      "     93        0.4911       0.6990        0.7800  0.1055\n",
      "     94        0.4900       0.7070        0.7623  0.1095\n",
      "     95        \u001b[36m0.4849\u001b[0m       0.6990        0.7572  0.1045\n",
      "     96        \u001b[36m0.4847\u001b[0m       0.7070        0.7588  0.0995\n",
      "     97        0.4913       0.7100        0.7692  0.1025\n",
      "     98        0.4892       0.7050        0.7910  0.1015\n",
      "     99        0.4862       0.7080        0.7913  0.1085\n",
      "    100        \u001b[36m0.4760\u001b[0m       0.7080        0.7810  0.1065\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8131\u001b[0m       \u001b[32m0.5220\u001b[0m        \u001b[35m0.8486\u001b[0m  0.1055\n",
      "      2        \u001b[36m0.6987\u001b[0m       \u001b[32m0.6960\u001b[0m        \u001b[35m0.7006\u001b[0m  0.1065\n",
      "      3        \u001b[36m0.6590\u001b[0m       \u001b[32m0.7330\u001b[0m        \u001b[35m0.6499\u001b[0m  0.0985\n",
      "      4        \u001b[36m0.6416\u001b[0m       \u001b[32m0.7430\u001b[0m        \u001b[35m0.6338\u001b[0m  0.1015\n",
      "      5        \u001b[36m0.6315\u001b[0m       \u001b[32m0.7490\u001b[0m        \u001b[35m0.6241\u001b[0m  0.1015\n",
      "      6        \u001b[36m0.6261\u001b[0m       0.7490        \u001b[35m0.6188\u001b[0m  0.1015\n",
      "      7        \u001b[36m0.6200\u001b[0m       \u001b[32m0.7590\u001b[0m        \u001b[35m0.6126\u001b[0m  0.0990\n",
      "      8        \u001b[36m0.6157\u001b[0m       0.7550        \u001b[35m0.6067\u001b[0m  0.0970\n",
      "      9        \u001b[36m0.6118\u001b[0m       0.7560        \u001b[35m0.6047\u001b[0m  0.1030\n",
      "     10        \u001b[36m0.6108\u001b[0m       0.7520        0.6056  0.1005\n",
      "     11        \u001b[36m0.6049\u001b[0m       0.7590        0.6056  0.1046\n",
      "     12        0.6056       0.7580        \u001b[35m0.6012\u001b[0m  0.1105\n",
      "     13        \u001b[36m0.6005\u001b[0m       0.7580        0.6022  0.1075\n",
      "     14        \u001b[36m0.5980\u001b[0m       0.7540        \u001b[35m0.6005\u001b[0m  0.1025\n",
      "     15        \u001b[36m0.5943\u001b[0m       \u001b[32m0.7610\u001b[0m        0.6055  0.1025\n",
      "     16        \u001b[36m0.5922\u001b[0m       0.7520        0.6046  0.1035\n",
      "     17        \u001b[36m0.5894\u001b[0m       0.7610        \u001b[35m0.5981\u001b[0m  0.1095\n",
      "     18        \u001b[36m0.5872\u001b[0m       0.7570        0.6038  0.1035\n",
      "     19        \u001b[36m0.5863\u001b[0m       \u001b[32m0.7640\u001b[0m        0.6027  0.1055\n",
      "     20        \u001b[36m0.5846\u001b[0m       0.7520        0.6071  0.1045\n",
      "     21        \u001b[36m0.5818\u001b[0m       0.7600        0.6037  0.1055\n",
      "     22        \u001b[36m0.5788\u001b[0m       0.7530        0.6055  0.1055\n",
      "     23        \u001b[36m0.5776\u001b[0m       0.7490        0.6021  0.1025\n",
      "     24        \u001b[36m0.5770\u001b[0m       0.7500        \u001b[35m0.5940\u001b[0m  0.1050\n",
      "     25        \u001b[36m0.5730\u001b[0m       0.7500        0.5970  0.1035\n",
      "     26        \u001b[36m0.5726\u001b[0m       0.7450        0.5993  0.1042\n",
      "     27        0.5730       0.7470        0.6003  0.0995\n",
      "     28        \u001b[36m0.5712\u001b[0m       0.7530        0.5981  0.1115\n",
      "     29        \u001b[36m0.5675\u001b[0m       0.7570        0.5971  0.1025\n",
      "     30        \u001b[36m0.5642\u001b[0m       0.7490        0.6049  0.1035\n",
      "     31        \u001b[36m0.5630\u001b[0m       0.7470        0.6080  0.1065\n",
      "     32        \u001b[36m0.5617\u001b[0m       0.7550        0.6011  0.1095\n",
      "     33        \u001b[36m0.5598\u001b[0m       0.7520        0.6059  0.1215\n",
      "     34        \u001b[36m0.5588\u001b[0m       0.7550        0.6026  0.1015\n",
      "     35        \u001b[36m0.5576\u001b[0m       0.7510        0.5982  0.1125\n",
      "     36        \u001b[36m0.5548\u001b[0m       0.7380        0.6139  0.1025\n",
      "     37        \u001b[36m0.5523\u001b[0m       0.7470        0.6007  0.1086\n",
      "     38        \u001b[36m0.5501\u001b[0m       0.7560        0.6063  0.1125\n",
      "     39        0.5503       0.7500        0.6230  0.1035\n",
      "     40        \u001b[36m0.5484\u001b[0m       0.7540        0.6081  0.1115\n",
      "     41        0.5488       \u001b[32m0.7660\u001b[0m        0.6119  0.1034\n",
      "     42        \u001b[36m0.5457\u001b[0m       0.7660        0.6117  0.1035\n",
      "     43        \u001b[36m0.5445\u001b[0m       0.7440        0.6153  0.1095\n",
      "     44        \u001b[36m0.5422\u001b[0m       0.7560        0.6121  0.1105\n",
      "     45        \u001b[36m0.5367\u001b[0m       0.7540        0.6251  0.1005\n",
      "     46        0.5368       0.7490        0.6285  0.1035\n",
      "     47        \u001b[36m0.5361\u001b[0m       0.7510        0.6422  0.1075\n",
      "     48        0.5363       0.7500        0.6327  0.1045\n",
      "     49        \u001b[36m0.5337\u001b[0m       0.7490        0.6311  0.1160\n",
      "     50        \u001b[36m0.5302\u001b[0m       0.7500        0.6407  0.1175\n",
      "     51        \u001b[36m0.5296\u001b[0m       0.7570        0.6384  0.1016\n",
      "     52        0.5345       0.7630        0.6473  0.1170\n",
      "     53        0.5319       0.7540        0.6389  0.1121\n",
      "     54        0.5387       0.7520        0.6306  0.1015\n",
      "     55        0.5340       0.7570        0.6301  0.1035\n",
      "     56        \u001b[36m0.5290\u001b[0m       0.7550        0.6238  0.1114\n",
      "     57        \u001b[36m0.5245\u001b[0m       0.7560        0.6380  0.1225\n",
      "     58        0.5258       0.7600        0.6303  0.1105\n",
      "     59        0.5246       0.7580        0.6294  0.1105\n",
      "     60        0.5341       0.7660        0.6236  0.1133\n",
      "     61        0.5292       0.7460        0.6260  0.0995\n",
      "     62        0.5309       0.7510        0.6309  0.1173\n",
      "     63        0.5259       0.7560        0.6319  0.1000\n",
      "     64        \u001b[36m0.5187\u001b[0m       0.7520        0.6391  0.1115\n",
      "     65        \u001b[36m0.5172\u001b[0m       0.7410        0.6425  0.1095\n",
      "     66        \u001b[36m0.5110\u001b[0m       0.7500        0.6373  0.1155\n",
      "     67        0.5163       0.7460        0.6473  0.1125\n",
      "     68        0.5128       0.7360        0.6665  0.1095\n",
      "     69        \u001b[36m0.5081\u001b[0m       0.7470        0.6416  0.1045\n",
      "     70        0.5126       0.7420        0.6500  0.1155\n",
      "     71        \u001b[36m0.5063\u001b[0m       0.7490        0.6502  0.1060\n",
      "     72        \u001b[36m0.5016\u001b[0m       0.7460        0.6522  0.1061\n",
      "     73        0.5023       0.7300        0.6611  0.1144\n",
      "     74        0.5070       0.7390        0.6559  0.1110\n",
      "     75        0.5045       0.7430        0.6494  0.1161\n",
      "     76        \u001b[36m0.4974\u001b[0m       0.7410        0.6565  0.1073\n",
      "     77        0.4985       0.7390        0.6680  0.1105\n",
      "     78        0.4989       0.7330        0.6804  0.1151\n",
      "     79        \u001b[36m0.4921\u001b[0m       0.7400        0.6703  0.1120\n",
      "     80        0.4942       0.7400        0.6798  0.0995\n",
      "     81        0.4973       0.7280        0.7013  0.1045\n",
      "     82        \u001b[36m0.4915\u001b[0m       0.7260        0.7042  0.1320\n",
      "     83        \u001b[36m0.4912\u001b[0m       0.7330        0.7035  0.1131\n",
      "     84        \u001b[36m0.4879\u001b[0m       0.7240        0.7210  0.1110\n",
      "     85        0.5002       0.7380        0.7194  0.1175\n",
      "     86        0.4956       0.7280        0.7243  0.1145\n",
      "     87        0.4912       0.7320        0.7215  0.1121\n",
      "     88        0.4886       0.7340        0.7232  0.1080\n",
      "     89        \u001b[36m0.4861\u001b[0m       0.7130        0.7318  0.1025\n",
      "     90        0.4881       0.7170        0.7267  0.1305\n",
      "     91        0.4876       0.7200        0.7618  0.1075\n",
      "     92        \u001b[36m0.4854\u001b[0m       0.7310        0.7516  0.1045\n",
      "     93        \u001b[36m0.4821\u001b[0m       0.7300        0.7592  0.1045\n",
      "     94        0.4856       0.7270        0.7720  0.1095\n",
      "     95        0.4886       0.7150        0.7579  0.1025\n",
      "     96        0.4896       0.7260        0.7663  0.0986\n",
      "     97        \u001b[36m0.4778\u001b[0m       0.7220        0.7747  0.1071\n",
      "     98        0.4793       0.7290        0.7751  0.1055\n",
      "     99        0.4784       0.7280        0.7595  0.1055\n",
      "    100        \u001b[36m0.4734\u001b[0m       0.7270        0.7757  0.1050\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8935\u001b[0m       \u001b[32m0.6710\u001b[0m        \u001b[35m0.7421\u001b[0m  0.0895\n",
      "      2        \u001b[36m0.7151\u001b[0m       \u001b[32m0.6890\u001b[0m        \u001b[35m0.6878\u001b[0m  0.0855\n",
      "      3        \u001b[36m0.6712\u001b[0m       \u001b[32m0.7030\u001b[0m        \u001b[35m0.6576\u001b[0m  0.0885\n",
      "      4        \u001b[36m0.6498\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.6518\u001b[0m  0.0855\n",
      "      5        \u001b[36m0.6368\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6449\u001b[0m  0.0835\n",
      "      6        \u001b[36m0.6302\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.6408\u001b[0m  0.0845\n",
      "      7        \u001b[36m0.6258\u001b[0m       \u001b[32m0.7170\u001b[0m        \u001b[35m0.6401\u001b[0m  0.0850\n",
      "      8        \u001b[36m0.6242\u001b[0m       0.7150        \u001b[35m0.6390\u001b[0m  0.0905\n",
      "      9        \u001b[36m0.6209\u001b[0m       \u001b[32m0.7220\u001b[0m        \u001b[35m0.6357\u001b[0m  0.0825\n",
      "     10        \u001b[36m0.6183\u001b[0m       0.7170        0.6362  0.0865\n",
      "     11        \u001b[36m0.6168\u001b[0m       \u001b[32m0.7240\u001b[0m        \u001b[35m0.6348\u001b[0m  0.0875\n",
      "     12        \u001b[36m0.6148\u001b[0m       \u001b[32m0.7260\u001b[0m        \u001b[35m0.6346\u001b[0m  0.0906\n",
      "     13        \u001b[36m0.6133\u001b[0m       0.7230        \u001b[35m0.6328\u001b[0m  0.0895\n",
      "     14        \u001b[36m0.6122\u001b[0m       0.7210        0.6332  0.0865\n",
      "     15        \u001b[36m0.6110\u001b[0m       0.7240        \u001b[35m0.6320\u001b[0m  0.0885\n",
      "     16        \u001b[36m0.6099\u001b[0m       0.7210        0.6345  0.0905\n",
      "     17        \u001b[36m0.6083\u001b[0m       0.7250        0.6349  0.0880\n",
      "     18        \u001b[36m0.6079\u001b[0m       0.7210        0.6326  0.0855\n",
      "     19        \u001b[36m0.6063\u001b[0m       0.7220        \u001b[35m0.6311\u001b[0m  0.0845\n",
      "     20        \u001b[36m0.6049\u001b[0m       0.7200        \u001b[35m0.6309\u001b[0m  0.0855\n",
      "     21        \u001b[36m0.6023\u001b[0m       0.7210        0.6311  0.0925\n",
      "     22        0.6031       0.7200        \u001b[35m0.6304\u001b[0m  0.0805\n",
      "     23        \u001b[36m0.6006\u001b[0m       0.7200        0.6320  0.0895\n",
      "     24        \u001b[36m0.6001\u001b[0m       0.7180        0.6324  0.0915\n",
      "     25        \u001b[36m0.5992\u001b[0m       0.7140        0.6332  0.0875\n",
      "     26        \u001b[36m0.5978\u001b[0m       0.7160        0.6349  0.0900\n",
      "     27        \u001b[36m0.5968\u001b[0m       0.7130        0.6324  0.0925\n",
      "     28        0.5974       0.7180        \u001b[35m0.6299\u001b[0m  0.0885\n",
      "     29        \u001b[36m0.5966\u001b[0m       0.7180        0.6341  0.0875\n",
      "     30        \u001b[36m0.5953\u001b[0m       0.7170        0.6333  0.0845\n",
      "     31        \u001b[36m0.5948\u001b[0m       0.7190        0.6365  0.1065\n",
      "     32        \u001b[36m0.5932\u001b[0m       0.7190        0.6363  0.0885\n",
      "     33        0.5932       0.7230        0.6397  0.0865\n",
      "     34        \u001b[36m0.5916\u001b[0m       0.7230        0.6357  0.0915\n",
      "     35        \u001b[36m0.5915\u001b[0m       \u001b[32m0.7300\u001b[0m        0.6399  0.0905\n",
      "     36        \u001b[36m0.5904\u001b[0m       0.7220        0.6417  0.1001\n",
      "     37        \u001b[36m0.5892\u001b[0m       0.7180        0.6377  0.0985\n",
      "     38        \u001b[36m0.5886\u001b[0m       0.7140        0.6367  0.0935\n",
      "     39        0.5890       0.7120        0.6518  0.0915\n",
      "     40        \u001b[36m0.5883\u001b[0m       0.7270        0.6419  0.0945\n",
      "     41        \u001b[36m0.5863\u001b[0m       0.7140        0.6530  0.0945\n",
      "     42        \u001b[36m0.5863\u001b[0m       0.7150        0.6529  0.0890\n",
      "     43        0.5868       0.7250        0.6460  0.0875\n",
      "     44        \u001b[36m0.5856\u001b[0m       0.7230        0.6460  0.0925\n",
      "     45        \u001b[36m0.5851\u001b[0m       0.7200        0.6533  0.0875\n",
      "     46        \u001b[36m0.5843\u001b[0m       0.7240        0.6520  0.0885\n",
      "     47        0.5850       0.7300        0.6465  0.0895\n",
      "     48        \u001b[36m0.5834\u001b[0m       0.7280        0.6399  0.1105\n",
      "     49        \u001b[36m0.5830\u001b[0m       0.7170        0.6503  0.0885\n",
      "     50        \u001b[36m0.5816\u001b[0m       0.7180        0.6468  0.0945\n",
      "     51        \u001b[36m0.5808\u001b[0m       0.7180        0.6518  0.0975\n",
      "     52        0.5828       0.7090        0.6555  0.0965\n",
      "     53        \u001b[36m0.5806\u001b[0m       0.7230        0.6510  0.1015\n",
      "     54        0.5816       0.7210        0.6454  0.0975\n",
      "     55        \u001b[36m0.5794\u001b[0m       0.7150        0.6548  0.0945\n",
      "     56        0.5800       0.7120        0.6638  0.0925\n",
      "     57        0.5797       0.7150        0.6643  0.0955\n",
      "     58        0.5798       0.7120        0.6677  0.0875\n",
      "     59        \u001b[36m0.5791\u001b[0m       0.7140        0.6612  0.0905\n",
      "     60        0.5795       0.7120        0.6656  0.1015\n",
      "     61        0.5806       0.7200        0.6577  0.0921\n",
      "     62        \u001b[36m0.5784\u001b[0m       0.7240        0.6613  0.0974\n",
      "     63        \u001b[36m0.5779\u001b[0m       0.7160        0.6704  0.0902\n",
      "     64        0.5779       0.7140        0.6694  0.0900\n",
      "     65        \u001b[36m0.5776\u001b[0m       0.7250        0.6610  0.0903\n",
      "     66        0.5791       0.7240        0.6604  0.0865\n",
      "     67        \u001b[36m0.5766\u001b[0m       0.7230        0.6604  0.0905\n",
      "     68        0.5767       0.7250        0.6693  0.0995\n",
      "     69        0.5774       0.7250        0.6707  0.0865\n",
      "     70        0.5777       0.7270        0.6593  0.0855\n",
      "     71        \u001b[36m0.5742\u001b[0m       0.7170        0.6665  0.0865\n",
      "     72        0.5766       0.7220        0.6658  0.0835\n",
      "     73        0.5766       0.7240        0.6675  0.0875\n",
      "     74        \u001b[36m0.5738\u001b[0m       0.7200        0.6645  0.0935\n",
      "     75        0.5762       0.7260        0.6669  0.0850\n",
      "     76        0.5757       0.7270        0.6614  0.0905\n",
      "     77        0.5744       0.7270        0.6598  0.0865\n",
      "     78        0.5744       0.7250        0.6707  0.0955\n",
      "     79        0.5740       0.7250        0.6616  0.0875\n",
      "     80        \u001b[36m0.5733\u001b[0m       0.7280        0.6665  0.0915\n",
      "     81        \u001b[36m0.5724\u001b[0m       0.7250        0.6651  0.0885\n",
      "     82        0.5725       0.7220        0.6672  0.0945\n",
      "     83        0.5764       0.7300        0.6573  0.0955\n",
      "     84        0.5736       0.7240        0.6648  0.0985\n",
      "     85        0.5730       \u001b[32m0.7310\u001b[0m        0.6579  0.0975\n",
      "     86        0.5750       \u001b[32m0.7330\u001b[0m        0.6487  0.0995\n",
      "     87        0.5728       0.7300        0.6569  0.1005\n",
      "     88        \u001b[36m0.5723\u001b[0m       0.7280        0.6616  0.0925\n",
      "     89        \u001b[36m0.5718\u001b[0m       0.7230        0.6617  0.1065\n",
      "     90        0.5734       0.7190        0.6679  0.0915\n",
      "     91        0.5725       0.7260        0.6673  0.0915\n",
      "     92        \u001b[36m0.5713\u001b[0m       0.7180        0.6667  0.0865\n",
      "     93        0.5728       0.7150        0.6697  0.0894\n",
      "     94        0.5738       0.7270        0.6624  0.0900\n",
      "     95        0.5744       0.7210        0.6643  0.0925\n",
      "     96        0.5723       0.7170        0.6634  0.0925\n",
      "     97        0.5726       0.7210        0.6623  0.0965\n",
      "     98        0.5714       0.7240        0.6601  0.0855\n",
      "     99        \u001b[36m0.5706\u001b[0m       0.7170        0.6575  0.0845\n",
      "    100        0.5712       0.7250        0.6614  0.0916\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8790\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.4090\u001b[0m  0.0914\n",
      "      2        \u001b[36m0.7160\u001b[0m       0.4900        \u001b[35m1.0556\u001b[0m  0.0886\n",
      "      3        \u001b[36m0.6691\u001b[0m       \u001b[32m0.4930\u001b[0m        \u001b[35m0.9869\u001b[0m  0.0830\n",
      "      4        \u001b[36m0.6509\u001b[0m       \u001b[32m0.5050\u001b[0m        \u001b[35m0.9370\u001b[0m  0.0872\n",
      "      5        \u001b[36m0.6412\u001b[0m       \u001b[32m0.5180\u001b[0m        \u001b[35m0.9159\u001b[0m  0.0935\n",
      "      6        \u001b[36m0.6351\u001b[0m       \u001b[32m0.5360\u001b[0m        \u001b[35m0.8834\u001b[0m  0.0935\n",
      "      7        \u001b[36m0.6308\u001b[0m       \u001b[32m0.5470\u001b[0m        \u001b[35m0.8654\u001b[0m  0.1125\n",
      "      8        \u001b[36m0.6262\u001b[0m       \u001b[32m0.5650\u001b[0m        \u001b[35m0.8435\u001b[0m  0.0995\n",
      "      9        \u001b[36m0.6226\u001b[0m       \u001b[32m0.5880\u001b[0m        \u001b[35m0.8168\u001b[0m  0.0945\n",
      "     10        \u001b[36m0.6166\u001b[0m       0.5850        0.8238  0.0985\n",
      "     11        \u001b[36m0.6119\u001b[0m       0.5720        0.8511  0.0945\n",
      "     12        \u001b[36m0.6095\u001b[0m       \u001b[32m0.6020\u001b[0m        \u001b[35m0.8052\u001b[0m  0.0975\n",
      "     13        \u001b[36m0.6070\u001b[0m       \u001b[32m0.6150\u001b[0m        \u001b[35m0.7989\u001b[0m  0.1005\n",
      "     14        \u001b[36m0.6035\u001b[0m       \u001b[32m0.6320\u001b[0m        \u001b[35m0.7685\u001b[0m  0.0875\n",
      "     15        \u001b[36m0.6004\u001b[0m       0.6210        0.7861  0.0941\n",
      "     16        \u001b[36m0.5968\u001b[0m       0.6100        0.7970  0.1125\n",
      "     17        \u001b[36m0.5964\u001b[0m       0.6300        0.7780  0.0895\n",
      "     18        \u001b[36m0.5935\u001b[0m       0.6170        0.7935  0.0935\n",
      "     19        \u001b[36m0.5923\u001b[0m       \u001b[32m0.6340\u001b[0m        0.7759  0.0865\n",
      "     20        \u001b[36m0.5906\u001b[0m       \u001b[32m0.6350\u001b[0m        \u001b[35m0.7680\u001b[0m  0.0932\n",
      "     21        \u001b[36m0.5895\u001b[0m       \u001b[32m0.6400\u001b[0m        0.7774  0.0885\n",
      "     22        \u001b[36m0.5882\u001b[0m       0.6400        \u001b[35m0.7615\u001b[0m  0.0977\n",
      "     23        \u001b[36m0.5869\u001b[0m       \u001b[32m0.6410\u001b[0m        \u001b[35m0.7611\u001b[0m  0.0915\n",
      "     24        \u001b[36m0.5861\u001b[0m       0.6260        0.7773  0.0905\n",
      "     25        \u001b[36m0.5833\u001b[0m       0.6300        0.7646  0.0842\n",
      "     26        \u001b[36m0.5826\u001b[0m       0.6360        0.7615  0.0831\n",
      "     27        \u001b[36m0.5806\u001b[0m       0.6130        0.7824  0.0844\n",
      "     28        0.5817       0.6220        0.7693  0.0845\n",
      "     29        \u001b[36m0.5793\u001b[0m       0.5960        0.8020  0.0845\n",
      "     30        \u001b[36m0.5791\u001b[0m       0.5870        0.8011  0.0835\n",
      "     31        \u001b[36m0.5768\u001b[0m       0.6090        0.7717  0.0835\n",
      "     32        \u001b[36m0.5742\u001b[0m       0.6120        0.7718  0.0895\n",
      "     33        \u001b[36m0.5731\u001b[0m       0.6060        0.7798  0.0895\n",
      "     34        \u001b[36m0.5721\u001b[0m       0.5990        0.7963  0.0927\n",
      "     35        \u001b[36m0.5716\u001b[0m       0.6140        0.7783  0.0911\n",
      "     36        \u001b[36m0.5702\u001b[0m       0.6060        0.8168  0.0874\n",
      "     37        \u001b[36m0.5685\u001b[0m       0.6160        0.7804  0.0887\n",
      "     38        \u001b[36m0.5666\u001b[0m       0.6180        0.7847  0.0877\n",
      "     39        \u001b[36m0.5657\u001b[0m       0.6370        \u001b[35m0.7578\u001b[0m  0.0905\n",
      "     40        \u001b[36m0.5642\u001b[0m       0.6220        0.7821  0.0895\n",
      "     41        0.5650       0.6100        0.8065  0.0885\n",
      "     42        0.5644       0.6340        0.7661  0.0885\n",
      "     43        \u001b[36m0.5602\u001b[0m       0.6170        0.8016  0.0886\n",
      "     44        \u001b[36m0.5599\u001b[0m       0.6140        0.8088  0.0925\n",
      "     45        \u001b[36m0.5583\u001b[0m       0.6310        0.7910  0.0906\n",
      "     46        \u001b[36m0.5554\u001b[0m       0.6230        0.8064  0.0927\n",
      "     47        0.5569       \u001b[32m0.6430\u001b[0m        0.7752  0.0920\n",
      "     48        \u001b[36m0.5512\u001b[0m       0.6320        0.7951  0.0955\n",
      "     49        0.5522       0.6330        0.7969  0.0906\n",
      "     50        \u001b[36m0.5508\u001b[0m       0.6320        0.7892  0.0926\n",
      "     51        0.5529       0.6120        0.8129  0.0945\n",
      "     52        0.5517       0.6280        0.8085  0.0865\n",
      "     53        \u001b[36m0.5481\u001b[0m       0.6300        0.7757  0.0945\n",
      "     54        \u001b[36m0.5440\u001b[0m       0.6040        0.8400  0.0945\n",
      "     55        0.5457       0.6390        0.7838  0.0895\n",
      "     56        0.5441       0.6350        0.7831  0.0945\n",
      "     57        0.5464       0.6400        0.7962  0.0915\n",
      "     58        0.5442       \u001b[32m0.6460\u001b[0m        0.7662  0.0925\n",
      "     59        \u001b[36m0.5397\u001b[0m       0.6220        0.8240  0.0915\n",
      "     60        0.5422       \u001b[32m0.6470\u001b[0m        0.7828  0.0945\n",
      "     61        \u001b[36m0.5348\u001b[0m       0.6300        0.8133  0.0945\n",
      "     62        0.5408       0.6440        0.7828  0.0925\n",
      "     63        0.5389       0.6320        0.8170  0.0925\n",
      "     64        0.5396       0.6150        0.8403  0.0955\n",
      "     65        0.5383       0.6390        0.7999  0.0957\n",
      "     66        0.5349       0.6360        0.8109  0.0899\n",
      "     67        0.5355       0.6380        0.8193  0.0935\n",
      "     68        0.5351       0.6300        0.8143  0.0945\n",
      "     69        0.5348       0.6400        0.8246  0.0895\n",
      "     70        \u001b[36m0.5318\u001b[0m       0.6230        0.8350  0.0902\n",
      "     71        0.5329       0.6410        0.8141  0.0955\n",
      "     72        \u001b[36m0.5309\u001b[0m       0.6260        0.8368  0.0935\n",
      "     73        0.5314       0.6430        0.8154  0.0955\n",
      "     74        \u001b[36m0.5282\u001b[0m       0.6460        0.8250  0.0935\n",
      "     75        \u001b[36m0.5264\u001b[0m       0.6150        0.8557  0.0985\n",
      "     76        0.5277       \u001b[32m0.6540\u001b[0m        0.8414  0.0925\n",
      "     77        0.5312       \u001b[32m0.6570\u001b[0m        0.7773  0.1025\n",
      "     78        \u001b[36m0.5253\u001b[0m       0.6520        0.7725  0.0976\n",
      "     79        \u001b[36m0.5246\u001b[0m       0.6410        0.8474  0.1155\n",
      "     80        0.5256       \u001b[32m0.6620\u001b[0m        0.7603  0.1125\n",
      "     81        \u001b[36m0.5239\u001b[0m       0.6380        0.7894  0.1065\n",
      "     82        \u001b[36m0.5211\u001b[0m       0.6620        0.7738  0.0945\n",
      "     83        0.5238       0.6520        0.7717  0.1045\n",
      "     84        0.5240       0.6580        0.7614  0.0945\n",
      "     85        0.5223       0.6610        0.7930  0.0985\n",
      "     86        \u001b[36m0.5164\u001b[0m       0.6470        0.8187  0.0965\n",
      "     87        \u001b[36m0.5163\u001b[0m       \u001b[32m0.6640\u001b[0m        0.8061  0.1015\n",
      "     88        0.5194       \u001b[32m0.6670\u001b[0m        0.7761  0.0985\n",
      "     89        0.5177       0.6630        0.7818  0.1005\n",
      "     90        0.5191       0.6580        0.8185  0.1045\n",
      "     91        0.5188       0.6620        0.8128  0.0890\n",
      "     92        0.5169       \u001b[32m0.6780\u001b[0m        \u001b[35m0.7471\u001b[0m  0.1055\n",
      "     93        \u001b[36m0.5138\u001b[0m       0.6590        0.7896  0.1030\n",
      "     94        0.5163       0.6740        0.7531  0.1045\n",
      "     95        0.5164       0.6610        0.7975  0.1005\n",
      "     96        0.5151       0.6680        0.7990  0.0935\n",
      "     97        \u001b[36m0.5132\u001b[0m       \u001b[32m0.6810\u001b[0m        0.7841  0.0925\n",
      "     98        \u001b[36m0.5096\u001b[0m       0.6550        0.7928  0.0995\n",
      "     99        0.5147       0.6630        0.7729  0.0965\n",
      "    100        0.5121       0.6480        0.7920  0.0980\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8970\u001b[0m       \u001b[32m0.6540\u001b[0m        \u001b[35m0.7439\u001b[0m  0.1360\n",
      "      2        \u001b[36m0.7600\u001b[0m       \u001b[32m0.6610\u001b[0m        \u001b[35m0.7286\u001b[0m  0.1125\n",
      "      3        \u001b[36m0.7401\u001b[0m       \u001b[32m0.6730\u001b[0m        0.7336  0.1055\n",
      "      4        \u001b[36m0.7286\u001b[0m       0.6650        0.7424  0.1075\n",
      "      5        0.7309       0.6680        \u001b[35m0.7191\u001b[0m  0.1015\n",
      "      6        \u001b[36m0.7213\u001b[0m       \u001b[32m0.6800\u001b[0m        0.7249  0.1055\n",
      "      7        \u001b[36m0.7135\u001b[0m       \u001b[32m0.6810\u001b[0m        0.7271  0.1074\n",
      "      8        0.7195       0.6730        0.7267  0.1075\n",
      "      9        0.7173       0.6740        0.7273  0.0945\n",
      "     10        0.7151       0.6750        0.7265  0.1065\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8829\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m2.0849\u001b[0m  0.0935\n",
      "      2        \u001b[36m0.7724\u001b[0m       \u001b[32m0.6720\u001b[0m        \u001b[35m0.7969\u001b[0m  0.1025\n",
      "      3        \u001b[36m0.7048\u001b[0m       0.6670        \u001b[35m0.7862\u001b[0m  0.1025\n",
      "      4        0.7158       \u001b[32m0.7060\u001b[0m        \u001b[35m0.7277\u001b[0m  0.1055\n",
      "      5        \u001b[36m0.6848\u001b[0m       0.6460        0.7449  0.0985\n",
      "      6        \u001b[36m0.6788\u001b[0m       0.6440        \u001b[35m0.7261\u001b[0m  0.1041\n",
      "      7        0.6802       0.6580        0.7347  0.1015\n",
      "      8        0.6815       0.6460        0.7564  0.0965\n",
      "      9        \u001b[36m0.6721\u001b[0m       0.6710        \u001b[35m0.7163\u001b[0m  0.1054\n",
      "     10        0.6829       0.6990        0.7240  0.1015\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5768\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0955\n",
      "      2       10.6176       0.3340       10.6176  0.0945\n",
      "      3       10.6176       0.3340       10.6176  0.1055\n",
      "      4       10.6176       0.3340       10.6176  0.1095\n",
      "      5       10.6176       0.3340       10.6176  0.0955\n",
      "      6       10.6176       0.3340       10.6176  0.1005\n",
      "      7       10.6176       0.3340       10.6176  0.0945\n",
      "      8       10.6176       0.3340       10.6176  0.1230\n",
      "      9       10.6176       0.3340       10.6176  0.1012\n",
      "     10       10.6176       0.3340       10.6176  0.0991\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.9921\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m8.1306\u001b[0m  0.0920\n",
      "      2        8.1426       0.4900        8.1306  0.0915\n",
      "      3        8.1426       0.4900        8.1306  0.0941\n",
      "      4        8.1426       0.4900        8.1306  0.0975\n",
      "      5        8.1426       0.4900        8.1306  0.0955\n",
      "      6        8.1426       0.4900        8.1306  0.0945\n",
      "      7        8.1426       0.4900        8.1306  0.1165\n",
      "      8        8.1426       0.4900        8.1306  0.0945\n",
      "      9        8.1426       0.4900        8.1306  0.0995\n",
      "     10        8.1426       0.4900        8.1306  0.0982\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8890\u001b[0m       \u001b[32m0.6850\u001b[0m        \u001b[35m0.7095\u001b[0m  0.1055\n",
      "      2        \u001b[36m0.7539\u001b[0m       0.6470        0.7292  0.1047\n",
      "      3        \u001b[36m0.7075\u001b[0m       0.6810        \u001b[35m0.7073\u001b[0m  0.0947\n",
      "      4        \u001b[36m0.6958\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.7000\u001b[0m  0.1005\n",
      "      5        \u001b[36m0.6921\u001b[0m       0.6890        0.7024  0.1055\n",
      "      6        \u001b[36m0.6893\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.6908\u001b[0m  0.0975\n",
      "      7        \u001b[36m0.6796\u001b[0m       \u001b[32m0.7050\u001b[0m        0.6964  0.0956\n",
      "      8        0.6890       \u001b[32m0.7110\u001b[0m        \u001b[35m0.6798\u001b[0m  0.1025\n",
      "      9        0.7081       0.7080        0.6957  0.0952\n",
      "     10        0.6997       0.6870        0.7116  0.1015\n",
      "     11        0.6922       0.7010        0.7060  0.0976\n",
      "     12        0.6837       0.6850        0.7282  0.1136\n",
      "     13        0.7038       0.6970        0.6820  0.1086\n",
      "     14        0.6800       0.6880        0.7139  0.1075\n",
      "     15        0.6861       0.6990        0.7124  0.1155\n",
      "     16        0.6941       0.6790        0.7244  0.1045\n",
      "     17        0.6832       0.6930        0.7004  0.1055\n",
      "     18        \u001b[36m0.6772\u001b[0m       0.6930        0.7043  0.1121\n",
      "     19        0.6979       \u001b[32m0.7120\u001b[0m        0.6878  0.1155\n",
      "     20        \u001b[36m0.6750\u001b[0m       0.6980        0.7151  0.1250\n",
      "     21        \u001b[36m0.6734\u001b[0m       0.6910        0.7069  0.1125\n",
      "     22        0.6815       0.6870        0.7290  0.1075\n",
      "     23        0.6873       0.6940        0.7170  0.1075\n",
      "     24        0.6833       0.6800        0.7464  0.1075\n",
      "     25        0.6987       0.6910        0.7143  0.1055\n",
      "     26        0.6897       0.6980        0.7141  0.1095\n",
      "     27        0.6813       0.6910        0.6950  0.1015\n",
      "     28        0.6773       0.7010        0.6830  0.1135\n",
      "     29        \u001b[36m0.6711\u001b[0m       0.7020        0.7093  0.1140\n",
      "     30        0.6913       0.6970        0.6857  0.1055\n",
      "     31        \u001b[36m0.6673\u001b[0m       0.7090        \u001b[35m0.6772\u001b[0m  0.1154\n",
      "     32        0.6690       0.6800        0.7296  0.1285\n",
      "     33        0.6887       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6715\u001b[0m  0.1035\n",
      "     34        0.6682       0.7020        0.6883  0.1075\n",
      "     35        \u001b[36m0.6655\u001b[0m       0.7020        0.7035  0.1165\n",
      "     36        0.6758       0.6900        0.7014  0.1125\n",
      "     37        0.6753       0.7140        \u001b[35m0.6645\u001b[0m  0.1225\n",
      "     38        \u001b[36m0.6640\u001b[0m       0.7150        0.6670  0.1015\n",
      "     39        \u001b[36m0.6625\u001b[0m       0.7100        0.6728  0.1065\n",
      "     40        0.6672       0.6960        0.7202  0.1006\n",
      "     41        0.6799       \u001b[32m0.7160\u001b[0m        0.6701  0.0995\n",
      "     42        0.6681       0.7060        0.6815  0.1045\n",
      "     43        0.6691       0.6880        0.7156  0.1035\n",
      "     44        0.6864       0.6860        0.7366  0.1115\n",
      "     45        0.6841       0.7090        0.6828  0.1270\n",
      "     46        0.6780       0.7110        0.7061  0.1075\n",
      "     47        0.6721       0.7020        0.6977  0.1135\n",
      "     48        0.6666       \u001b[32m0.7220\u001b[0m        0.6763  0.1005\n",
      "     49        0.6699       0.7180        0.6678  0.1015\n",
      "     50        0.6655       0.7100        0.6777  0.1025\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9149\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m0.7773\u001b[0m  0.0955\n",
      "      2        \u001b[36m0.7023\u001b[0m       \u001b[32m0.6860\u001b[0m        \u001b[35m0.7123\u001b[0m  0.0955\n",
      "      3        \u001b[36m0.6905\u001b[0m       0.6660        0.7453  0.1025\n",
      "      4        0.6996       0.6750        0.7416  0.1075\n",
      "      5        0.7244       \u001b[32m0.7240\u001b[0m        \u001b[35m0.6772\u001b[0m  0.1035\n",
      "      6        0.6994       \u001b[32m0.7350\u001b[0m        \u001b[35m0.6695\u001b[0m  0.1025\n",
      "      7        0.6947       0.7290        0.6718  0.0975\n",
      "      8        0.6953       0.7340        0.6714  0.1005\n",
      "      9        0.6909       \u001b[32m0.7360\u001b[0m        0.6730  0.1015\n",
      "     10        0.6927       \u001b[32m0.7370\u001b[0m        \u001b[35m0.6692\u001b[0m  0.1025\n",
      "     11        \u001b[36m0.6886\u001b[0m       0.7340        \u001b[35m0.6674\u001b[0m  0.1005\n",
      "     12        0.6894       \u001b[32m0.7410\u001b[0m        \u001b[35m0.6595\u001b[0m  0.1095\n",
      "     13        0.6887       0.7330        \u001b[35m0.6573\u001b[0m  0.1045\n",
      "     14        \u001b[36m0.6879\u001b[0m       0.7340        \u001b[35m0.6570\u001b[0m  0.1105\n",
      "     15        \u001b[36m0.6834\u001b[0m       0.7360        \u001b[35m0.6547\u001b[0m  0.1065\n",
      "     16        0.6841       0.7320        \u001b[35m0.6518\u001b[0m  0.1065\n",
      "     17        \u001b[36m0.6802\u001b[0m       0.7400        0.6527  0.1100\n",
      "     18        0.6805       0.7380        \u001b[35m0.6496\u001b[0m  0.1085\n",
      "     19        0.6815       0.7410        \u001b[35m0.6490\u001b[0m  0.1135\n",
      "     20        0.6822       0.7390        \u001b[35m0.6483\u001b[0m  0.1375\n",
      "     21        \u001b[36m0.6790\u001b[0m       \u001b[32m0.7420\u001b[0m        0.6486  0.1145\n",
      "     22        0.6812       0.7380        \u001b[35m0.6477\u001b[0m  0.1110\n",
      "     23        0.6791       0.7420        0.6485  0.1152\n",
      "     24        0.6804       0.7420        \u001b[35m0.6477\u001b[0m  0.1093\n",
      "     25        \u001b[36m0.6775\u001b[0m       0.7380        0.6487  0.1134\n",
      "     26        0.6815       0.7390        \u001b[35m0.6471\u001b[0m  0.0998\n",
      "     27        0.6783       0.7420        0.6491  0.1061\n",
      "     28        0.6785       0.7410        0.6479  0.1030\n",
      "     29        0.6786       0.7420        0.6488  0.1050\n",
      "     30        0.6789       \u001b[32m0.7430\u001b[0m        0.6482  0.1041\n",
      "     31        0.6785       0.7420        0.6491  0.1135\n",
      "     32        0.6785       0.7420        0.6490  0.1062\n",
      "     33        0.6777       0.7360        0.6501  0.1027\n",
      "     34        0.6819       0.7430        0.6483  0.1057\n",
      "     35        \u001b[36m0.6773\u001b[0m       0.7280        0.6536  0.1303\n",
      "     36        \u001b[36m0.6770\u001b[0m       0.7290        0.6513  0.1185\n",
      "     37        \u001b[36m0.6766\u001b[0m       0.7340        0.6534  0.0968\n",
      "     38        0.6775       0.7310        0.6516  0.1179\n",
      "     39        0.6780       0.7300        0.6539  0.1123\n",
      "     40        0.6795       0.7370        0.6529  0.1067\n",
      "     41        \u001b[36m0.6763\u001b[0m       0.7240        0.6576  0.1058\n",
      "     42        0.6794       0.7350        0.6528  0.1174\n",
      "     43        0.6773       0.7380        0.6528  0.1043\n",
      "     44        0.6792       0.7410        0.6530  0.1102\n",
      "     45        \u001b[36m0.6734\u001b[0m       0.7260        0.6580  0.1057\n",
      "     46        0.6795       0.7380        0.6507  0.1064\n",
      "     47        0.6782       0.7300        0.6561  0.1057\n",
      "     48        0.6791       0.7360        0.6528  0.0987\n",
      "     49        0.6741       0.7170        0.6600  0.1126\n",
      "     50        0.6818       0.7370        0.6538  0.1255\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5764\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0945\n",
      "      2       10.6176       0.3340       10.6176  0.0932\n",
      "      3       10.6176       0.3340       10.6176  0.0944\n",
      "      4       10.6176       0.3340       10.6176  0.0898\n",
      "      5       10.6176       0.3340       10.6176  0.0857\n",
      "      6       10.6176       0.3340       10.6176  0.0938\n",
      "      7       10.6176       0.3340       10.6176  0.0916\n",
      "      8       10.6176       0.3340       10.6176  0.0966\n",
      "      9       10.6176       0.3340       10.6176  0.0940\n",
      "     10       10.6176       0.3340       10.6176  0.0950\n",
      "     11       10.6176       0.3340       10.6176  0.0924\n",
      "     12       10.6176       0.3340       10.6176  0.0968\n",
      "     13       10.6176       0.3340       10.6176  0.0968\n",
      "     14       10.6176       0.3340       10.6176  0.0965\n",
      "     15       10.6176       0.3340       10.6176  0.1043\n",
      "     16       10.6176       0.3340       10.6176  0.0879\n",
      "     17       10.6176       0.3340       10.6176  0.0902\n",
      "     18       10.6176       0.3340       10.6176  0.0881\n",
      "     19       10.6176       0.3340       10.6176  0.0870\n",
      "     20       10.6176       0.3340       10.6176  0.0903\n",
      "     21       10.6176       0.3340       10.6176  0.0882\n",
      "     22       10.6176       0.3340       10.6176  0.0900\n",
      "     23       10.6176       0.3340       10.6176  0.0893\n",
      "     24       10.6176       0.3340       10.6176  0.0932\n",
      "     25       10.6176       0.3340       10.6176  0.0928\n",
      "     26       10.6176       0.3340       10.6176  0.0911\n",
      "     27       10.6176       0.3340       10.6176  0.0880\n",
      "     28       10.6176       0.3340       10.6176  0.0901\n",
      "     29       10.6176       0.3340       10.6176  0.0913\n",
      "     30       10.6176       0.3340       10.6176  0.0968\n",
      "     31       10.6176       0.3340       10.6176  0.0878\n",
      "     32       10.6176       0.3340       10.6176  0.0856\n",
      "     33       10.6176       0.3340       10.6176  0.0904\n",
      "     34       10.6176       0.3340       10.6176  0.0901\n",
      "     35       10.6176       0.3340       10.6176  0.0947\n",
      "     36       10.6176       0.3340       10.6176  0.1025\n",
      "     37       10.6176       0.3340       10.6176  0.1150\n",
      "     38       10.6176       0.3340       10.6176  0.0889\n",
      "     39       10.6176       0.3340       10.6176  0.0914\n",
      "     40       10.6176       0.3340       10.6176  0.0868\n",
      "     41       10.6176       0.3340       10.6176  0.0898\n",
      "     42       10.6176       0.3340       10.6176  0.0903\n",
      "     43       10.6176       0.3340       10.6176  0.0931\n",
      "     44       10.6176       0.3340       10.6176  0.0937\n",
      "     45       10.6176       0.3340       10.6176  0.0925\n",
      "     46       10.6176       0.3340       10.6176  0.0894\n",
      "     47       10.6176       0.3340       10.6176  0.0928\n",
      "     48       10.6176       0.3340       10.6176  0.1013\n",
      "     49       10.6176       0.3340       10.6176  0.1105\n",
      "     50       10.6176       0.3340       10.6176  0.0885\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5160\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0884\n",
      "      2       10.6176       0.3340       10.6176  0.0938\n",
      "      3       10.6176       0.3340       10.6176  0.1061\n",
      "      4       10.6176       0.3340       10.6176  0.0968\n",
      "      5       10.6176       0.3340       10.6176  0.1022\n",
      "      6       10.6176       0.3340       10.6176  0.1001\n",
      "      7       10.6176       0.3340       10.6176  0.0916\n",
      "      8       10.6176       0.3340       10.6176  0.0926\n",
      "      9       10.6176       0.3340       10.6176  0.0924\n",
      "     10       10.6176       0.3340       10.6176  0.0968\n",
      "     11       10.6176       0.3340       10.6176  0.0963\n",
      "     12       10.6176       0.3340       10.6176  0.1016\n",
      "     13       10.6176       0.3340       10.6176  0.1002\n",
      "     14       10.6176       0.3340       10.6176  0.0966\n",
      "     15       10.6176       0.3340       10.6176  0.1044\n",
      "     16       10.6176       0.3340       10.6176  0.0916\n",
      "     17       10.6176       0.3340       10.6176  0.0953\n",
      "     18       10.6176       0.3340       10.6176  0.0955\n",
      "     19       10.6176       0.3340       10.6176  0.0917\n",
      "     20       10.6176       0.3340       10.6176  0.0946\n",
      "     21       10.6176       0.3340       10.6176  0.0963\n",
      "     22       10.6176       0.3340       10.6176  0.0920\n",
      "     23       10.6176       0.3340       10.6176  0.0898\n",
      "     24       10.6176       0.3340       10.6176  0.0951\n",
      "     25       10.6176       0.3340       10.6176  0.0903\n",
      "     26       10.6176       0.3340       10.6176  0.0937\n",
      "     27       10.6176       0.3340       10.6176  0.0948\n",
      "     28       10.6176       0.3340       10.6176  0.0900\n",
      "     29       10.6176       0.3340       10.6176  0.0915\n",
      "     30       10.6176       0.3340       10.6176  0.0952\n",
      "     31       10.6176       0.3340       10.6176  0.0947\n",
      "     32       10.6176       0.3340       10.6176  0.0905\n",
      "     33       10.6176       0.3340       10.6176  0.0954\n",
      "     34       10.6176       0.3340       10.6176  0.0863\n",
      "     35       10.6176       0.3340       10.6176  0.0957\n",
      "     36       10.6176       0.3340       10.6176  0.0947\n",
      "     37       10.6176       0.3340       10.6176  0.0911\n",
      "     38       10.6176       0.3340       10.6176  0.1115\n",
      "     39       10.6176       0.3340       10.6176  0.0933\n",
      "     40       10.6176       0.3340       10.6176  0.0977\n",
      "     41       10.6176       0.3340       10.6176  0.0964\n",
      "     42       10.6176       0.3340       10.6176  0.0909\n",
      "     43       10.6176       0.3340       10.6176  0.0927\n",
      "     44       10.6176       0.3340       10.6176  0.0961\n",
      "     45       10.6176       0.3340       10.6176  0.0918\n",
      "     46       10.6176       0.3340       10.6176  0.0913\n",
      "     47       10.6176       0.3340       10.6176  0.0932\n",
      "     48       10.6176       0.3340       10.6176  0.0896\n",
      "     49       10.6176       0.3340       10.6176  0.0920\n",
      "     50       10.6176       0.3340       10.6176  0.0930\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9746\u001b[0m       \u001b[32m0.6640\u001b[0m        \u001b[35m0.7298\u001b[0m  0.0961\n",
      "      2        \u001b[36m0.7429\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6979\u001b[0m  0.0958\n",
      "      3        \u001b[36m0.7357\u001b[0m       0.6670        0.7251  0.1036\n",
      "      4        \u001b[36m0.7331\u001b[0m       0.6550        0.7629  0.0962\n",
      "      5        \u001b[36m0.7210\u001b[0m       0.6620        0.7361  0.1001\n",
      "      6        \u001b[36m0.7184\u001b[0m       0.6680        0.7188  0.0980\n",
      "      7        \u001b[36m0.6962\u001b[0m       0.6640        0.7236  0.0997\n",
      "      8        0.6963       0.6890        0.7018  0.1050\n",
      "      9        \u001b[36m0.6893\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.6947\u001b[0m  0.0982\n",
      "     10        \u001b[36m0.6847\u001b[0m       0.6670        0.7266  0.1029\n",
      "     11        0.7123       0.6920        0.6968  0.1057\n",
      "     12        \u001b[36m0.6795\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.6886\u001b[0m  0.1041\n",
      "     13        0.6805       0.7020        \u001b[35m0.6877\u001b[0m  0.1064\n",
      "     14        \u001b[36m0.6794\u001b[0m       0.6940        0.6884  0.1096\n",
      "     15        0.6830       \u001b[32m0.7060\u001b[0m        \u001b[35m0.6838\u001b[0m  0.1141\n",
      "     16        0.6807       0.7030        0.6875  0.1057\n",
      "     17        0.6817       0.6920        0.7023  0.1111\n",
      "     18        0.6831       0.7040        \u001b[35m0.6819\u001b[0m  0.1006\n",
      "     19        \u001b[36m0.6793\u001b[0m       0.6860        0.7067  0.1061\n",
      "     20        0.6799       0.6930        0.7000  0.1014\n",
      "     21        0.6883       0.6890        0.7091  0.1103\n",
      "     22        0.6815       0.6930        0.6983  0.1041\n",
      "     23        0.6868       0.6970        0.6921  0.1082\n",
      "     24        0.6854       \u001b[32m0.7070\u001b[0m        \u001b[35m0.6775\u001b[0m  0.0981\n",
      "     25        0.6848       0.7010        0.6877  0.1058\n",
      "     26        0.6835       0.6860        0.7087  0.1098\n",
      "     27        0.6842       0.7060        \u001b[35m0.6763\u001b[0m  0.1079\n",
      "     28        0.6795       0.7020        0.6903  0.1090\n",
      "     29        0.6832       0.7040        0.6823  0.1169\n",
      "     30        0.6847       0.7000        0.6875  0.1048\n",
      "     31        0.6826       0.6900        0.6894  0.1085\n",
      "     32        0.6904       0.7030        0.6887  0.1118\n",
      "     33        0.6818       0.7050        0.6850  0.1152\n",
      "     34        0.6864       0.7030        0.6887  0.1014\n",
      "     35        0.6810       0.7030        0.6832  0.1038\n",
      "     36        0.6886       0.7020        0.6935  0.1013\n",
      "     37        0.6806       0.7060        0.6846  0.1028\n",
      "     38        0.6824       0.7070        0.6828  0.1073\n",
      "     39        \u001b[36m0.6780\u001b[0m       0.6980        0.6911  0.1041\n",
      "     40        0.6895       \u001b[32m0.7090\u001b[0m        0.6835  0.1037\n",
      "     41        0.6840       0.7030        0.6855  0.1016\n",
      "     42        0.6826       0.7070        0.6856  0.1242\n",
      "     43        0.6843       0.7020        0.6998  0.1005\n",
      "     44        0.6828       \u001b[32m0.7110\u001b[0m        0.6817  0.0994\n",
      "     45        0.6860       \u001b[32m0.7140\u001b[0m        \u001b[35m0.6741\u001b[0m  0.1021\n",
      "     46        0.6789       0.7070        0.6800  0.0960\n",
      "     47        0.6892       0.6950        0.6942  0.1015\n",
      "     48        0.6857       0.7080        0.6828  0.1061\n",
      "     49        0.6795       0.7010        0.6954  0.1012\n",
      "     50        0.6893       0.7120        0.6833  0.1018\n",
      "     51        0.6786       0.7010        0.6941  0.1145\n",
      "     52        0.6905       0.7080        0.6844  0.1048\n",
      "     53        0.6808       0.7020        0.6895  0.1040\n",
      "     54        0.6869       0.7060        0.6856  0.1129\n",
      "     55        0.6802       0.6990        0.6861  0.1072\n",
      "     56        0.6833       0.7080        0.6822  0.1059\n",
      "     57        0.6800       0.7060        0.6839  0.1079\n",
      "     58        0.6831       0.7120        0.6775  0.1077\n",
      "     59        0.6788       0.7040        0.6851  0.1093\n",
      "     60        0.6857       0.7050        0.6877  0.1025\n",
      "     61        0.6791       0.7020        0.6855  0.1048\n",
      "     62        0.6911       0.7120        0.6829  0.1042\n",
      "     63        0.6814       0.7070        0.6860  0.1053\n",
      "     64        0.6881       0.7080        0.6904  0.1037\n",
      "     65        0.6811       0.7020        0.6864  0.1053\n",
      "     66        0.6901       0.7050        0.6865  0.1050\n",
      "     67        0.6802       0.7030        0.6838  0.1035\n",
      "     68        0.6855       0.7040        0.6842  0.1102\n",
      "     69        0.6834       0.7070        0.6777  0.1096\n",
      "     70        0.6809       0.7050        0.6873  0.1082\n",
      "     71        0.6838       \u001b[32m0.7170\u001b[0m        0.6751  0.1177\n",
      "     72        0.6812       0.7160        0.6780  0.1027\n",
      "     73        0.6792       0.7170        0.6766  0.1181\n",
      "     74        0.6852       0.7050        0.6836  0.1070\n",
      "     75        0.6839       0.7160        0.6749  0.1005\n",
      "     76        0.6833       0.6970        0.6993  0.1122\n",
      "     77        0.6866       0.7170        \u001b[35m0.6734\u001b[0m  0.1049\n",
      "     78        0.6809       \u001b[32m0.7190\u001b[0m        \u001b[35m0.6723\u001b[0m  0.1023\n",
      "     79        0.6814       0.7160        0.6775  0.1080\n",
      "     80        0.6808       0.7090        0.6876  0.1079\n",
      "     81        0.6849       0.7160        0.6780  0.1054\n",
      "     82        0.6864       0.7170        0.6736  0.1094\n",
      "     83        0.6796       0.7080        0.6887  0.1271\n",
      "     84        0.6839       0.7020        0.6983  0.1109\n",
      "     85        0.6865       0.7030        0.6894  0.1059\n",
      "     86        0.6881       0.7110        0.6732  0.1116\n",
      "     87        0.6802       0.7030        0.6883  0.1002\n",
      "     88        0.6859       0.7120        0.6825  0.1079\n",
      "     89        0.6901       0.7120        \u001b[35m0.6710\u001b[0m  0.1058\n",
      "     90        0.6810       0.7100        0.6835  0.1044\n",
      "     91        0.6888       0.7120        \u001b[35m0.6705\u001b[0m  0.1046\n",
      "     92        0.6834       0.7110        0.6818  0.1015\n",
      "     93        0.6894       0.7030        0.6992  0.1190\n",
      "     94        0.6813       0.7090        0.6775  0.1059\n",
      "     95        0.6854       \u001b[32m0.7200\u001b[0m        0.6715  0.1016\n",
      "     96        0.6821       0.7200        \u001b[35m0.6696\u001b[0m  0.1037\n",
      "     97        0.6824       0.7100        0.6717  0.1049\n",
      "     98        0.6833       0.7070        0.6853  0.1125\n",
      "     99        0.6880       0.7110        \u001b[35m0.6677\u001b[0m  0.1074\n",
      "    100        0.6840       0.7190        0.6749  0.1060\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8875\u001b[0m       \u001b[32m0.6510\u001b[0m        \u001b[35m0.7341\u001b[0m  0.1150\n",
      "      2        \u001b[36m0.6834\u001b[0m       \u001b[32m0.6860\u001b[0m        0.7715  0.1008\n",
      "      3        \u001b[36m0.6832\u001b[0m       \u001b[32m0.7180\u001b[0m        \u001b[35m0.7185\u001b[0m  0.1012\n",
      "      4        \u001b[36m0.6750\u001b[0m       0.6670        0.7441  0.0971\n",
      "      5        0.6998       0.6000        0.7927  0.1074\n",
      "      6        0.6948       \u001b[32m0.7230\u001b[0m        \u001b[35m0.7133\u001b[0m  0.0992\n",
      "      7        \u001b[36m0.6742\u001b[0m       0.6870        0.7383  0.0998\n",
      "      8        0.6844       \u001b[32m0.7310\u001b[0m        \u001b[35m0.7027\u001b[0m  0.0968\n",
      "      9        \u001b[36m0.6624\u001b[0m       0.7290        0.7068  0.1027\n",
      "     10        0.6872       0.6420        0.7889  0.0991\n",
      "     11        0.6822       \u001b[32m0.7340\u001b[0m        \u001b[35m0.6934\u001b[0m  0.1013\n",
      "     12        \u001b[36m0.6584\u001b[0m       \u001b[32m0.7510\u001b[0m        \u001b[35m0.6687\u001b[0m  0.1049\n",
      "     13        0.6616       0.7420        \u001b[35m0.6579\u001b[0m  0.1116\n",
      "     14        0.6626       0.7470        \u001b[35m0.6498\u001b[0m  0.1118\n",
      "     15        0.6596       0.7460        0.6560  0.1099\n",
      "     16        \u001b[36m0.6565\u001b[0m       0.7450        0.6524  0.1086\n",
      "     17        0.6591       0.7490        \u001b[35m0.6424\u001b[0m  0.1076\n",
      "     18        0.6570       0.7400        0.6581  0.1067\n",
      "     19        0.6589       0.7390        0.6815  0.1045\n",
      "     20        0.6619       0.7480        0.6566  0.1024\n",
      "     21        \u001b[36m0.6517\u001b[0m       0.7500        0.6536  0.1039\n",
      "     22        0.6549       0.7460        0.6528  0.1007\n",
      "     23        0.6579       0.7380        0.6843  0.1015\n",
      "     24        0.6678       0.7490        0.6600  0.1083\n",
      "     25        0.6552       0.7390        0.6608  0.1030\n",
      "     26        0.6676       0.5940        0.7590  0.1021\n",
      "     27        0.6737       0.5560        0.7626  0.1030\n",
      "     28        0.6750       0.6710        0.7369  0.1077\n",
      "     29        0.6832       0.5320        0.7978  0.1085\n",
      "     30        0.6823       0.7110        0.6994  0.1052\n",
      "     31        0.6740       0.6980        0.7181  0.1045\n",
      "     32        0.6853       0.6370        0.7487  0.0993\n",
      "     33        0.6788       0.6400        0.7551  0.0998\n",
      "     34        0.6728       0.6960        0.7118  0.1126\n",
      "     35        0.6744       0.7030        0.7017  0.0979\n",
      "     36        0.6698       0.7010        0.7135  0.1064\n",
      "     37        0.6762       0.6810        0.7176  0.1007\n",
      "     38        0.6710       0.6170        0.7647  0.1074\n",
      "     39        0.6797       0.7040        0.7039  0.1054\n",
      "     40        0.6700       0.7030        0.7083  0.1201\n",
      "     41        0.6805       0.6660        0.7456  0.1041\n",
      "     42        0.6773       0.6720        0.7274  0.1163\n",
      "     43        0.6669       0.7030        0.7034  0.1147\n",
      "     44        0.6709       0.6310        0.7546  0.1055\n",
      "     45        0.6723       0.7020        0.7174  0.1451\n",
      "     46        0.6684       0.7040        0.7028  0.1060\n",
      "     47        0.6684       0.6870        0.7192  0.1116\n",
      "     48        0.6804       0.6400        0.7586  0.1083\n",
      "     49        0.6687       0.6830        0.7197  0.1162\n",
      "     50        0.6721       0.6600        0.7357  0.1149\n",
      "     51        0.6706       0.6970        0.7079  0.1140\n",
      "     52        0.6699       0.6830        0.7219  0.1123\n",
      "     53        0.6751       0.6860        0.7192  0.1187\n",
      "     54        0.6735       0.6510        0.7419  0.1122\n",
      "     55        0.6701       0.7030        0.7003  0.1231\n",
      "     56        0.6672       0.7000        0.7096  0.1181\n",
      "     57        0.6686       0.6720        0.7275  0.1122\n",
      "     58        0.6646       0.7110        0.6978  0.1091\n",
      "     59        0.6672       0.5520        0.7680  0.1066\n",
      "     60        0.6706       0.7150        0.6936  0.1016\n",
      "     61        0.6653       0.6990        0.7134  0.1090\n",
      "     62        0.6763       0.6670        0.7273  0.1168\n",
      "     63        0.6686       0.6980        0.7158  0.1078\n",
      "     64        0.6710       0.5550        0.7751  0.1125\n",
      "     65        0.6738       0.6940        0.7127  0.1085\n",
      "     66        0.6715       0.6030        0.7686  0.1145\n",
      "     67        0.6736       0.6870        0.7261  0.1131\n",
      "     68        0.6709       0.6010        0.7535  0.1153\n",
      "     69        0.6687       0.7040        0.7039  0.1129\n",
      "     70        0.6669       0.5850        0.7560  0.1089\n",
      "     71        0.6696       0.6870        0.7223  0.1045\n",
      "     72        0.6729       0.6060        0.7645  0.1170\n",
      "     73        0.6742       0.7130        0.7061  0.1088\n",
      "     74        0.6699       0.6180        0.7480  0.1142\n",
      "     75        0.6751       0.7070        0.7116  0.1335\n",
      "     76        0.6698       0.5940        0.7547  0.1137\n",
      "     77        0.6680       0.6940        0.7163  0.1118\n",
      "     78        0.6681       0.5960        0.7572  0.1164\n",
      "     79        0.6715       0.6730        0.7336  0.1136\n",
      "     80        0.6685       0.6200        0.7645  0.1155\n",
      "     81        0.6690       0.6860        0.7197  0.1130\n",
      "     82        0.6723       0.5720        0.7765  0.1110\n",
      "     83        0.6731       0.7080        0.7060  0.1181\n",
      "     84        0.6680       0.6330        0.7565  0.1079\n",
      "     85        0.6704       0.7140        0.6964  0.1161\n",
      "     86        0.6646       0.6460        0.7512  0.1123\n",
      "     87        0.6698       0.6710        0.7339  0.1134\n",
      "     88        0.6625       0.5800        0.7598  0.1061\n",
      "     89        0.6649       0.7080        0.7049  0.1057\n",
      "     90        0.6670       0.5510        0.7747  0.1099\n",
      "     91        0.6719       0.7070        0.7045  0.1076\n",
      "     92        0.6696       0.6530        0.7508  0.1067\n",
      "     93        0.6652       0.6960        0.7181  0.1095\n",
      "     94        0.6665       0.6540        0.7437  0.1131\n",
      "     95        0.6631       0.7270        0.6853  0.1120\n",
      "     96        0.6629       0.7020        0.7141  0.1126\n",
      "     97        0.6711       0.7040        0.7063  0.1079\n",
      "     98        0.6718       0.6950        0.7171  0.1068\n",
      "     99        0.6701       0.6980        0.7199  0.1014\n",
      "    100        0.6806       0.6700        0.7311  0.1083\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5753\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0911\n",
      "      2       10.6176       0.3340       10.6176  0.0888\n",
      "      3       10.6176       0.3340       10.6176  0.0915\n",
      "      4       10.6176       0.3340       10.6176  0.0930\n",
      "      5       10.6176       0.3340       10.6176  0.0971\n",
      "      6       10.6176       0.3340       10.6176  0.1048\n",
      "      7       10.6176       0.3340       10.6176  0.1038\n",
      "      8       10.6176       0.3340       10.6176  0.1011\n",
      "      9       10.6176       0.3340       10.6176  0.0990\n",
      "     10       10.6176       0.3340       10.6176  0.0956\n",
      "     11       10.6176       0.3340       10.6176  0.1004\n",
      "     12       10.6176       0.3340       10.6176  0.1113\n",
      "     13       10.6176       0.3340       10.6176  0.0927\n",
      "     14       10.6176       0.3340       10.6176  0.0902\n",
      "     15       10.6176       0.3340       10.6176  0.0896\n",
      "     16       10.6176       0.3340       10.6176  0.0966\n",
      "     17       10.6176       0.3340       10.6176  0.0867\n",
      "     18       10.6176       0.3340       10.6176  0.0952\n",
      "     19       10.6176       0.3340       10.6176  0.0937\n",
      "     20       10.6176       0.3340       10.6176  0.1019\n",
      "     21       10.6176       0.3340       10.6176  0.0918\n",
      "     22       10.6176       0.3340       10.6176  0.1023\n",
      "     23       10.6176       0.3340       10.6176  0.0979\n",
      "     24       10.6176       0.3340       10.6176  0.0940\n",
      "     25       10.6176       0.3340       10.6176  0.0934\n",
      "     26       10.6176       0.3340       10.6176  0.1115\n",
      "     27       10.6176       0.3340       10.6176  0.0988\n",
      "     28       10.6176       0.3340       10.6176  0.0940\n",
      "     29       10.6176       0.3340       10.6176  0.0909\n",
      "     30       10.6176       0.3340       10.6176  0.0958\n",
      "     31       10.6176       0.3340       10.6176  0.0927\n",
      "     32       10.6176       0.3340       10.6176  0.0957\n",
      "     33       10.6176       0.3340       10.6176  0.0899\n",
      "     34       10.6176       0.3340       10.6176  0.1017\n",
      "     35       10.6176       0.3340       10.6176  0.0881\n",
      "     36       10.6176       0.3340       10.6176  0.0921\n",
      "     37       10.6176       0.3340       10.6176  0.0949\n",
      "     38       10.6176       0.3340       10.6176  0.0945\n",
      "     39       10.6176       0.3340       10.6176  0.0919\n",
      "     40       10.6176       0.3340       10.6176  0.0887\n",
      "     41       10.6176       0.3340       10.6176  0.0975\n",
      "     42       10.6176       0.3340       10.6176  0.0889\n",
      "     43       10.6176       0.3340       10.6176  0.0902\n",
      "     44       10.6176       0.3340       10.6176  0.0939\n",
      "     45       10.6176       0.3340       10.6176  0.0936\n",
      "     46       10.6176       0.3340       10.6176  0.0882\n",
      "     47       10.6176       0.3340       10.6176  0.0928\n",
      "     48       10.6176       0.3340       10.6176  0.0909\n",
      "     49       10.6176       0.3340       10.6176  0.0874\n",
      "     50       10.6176       0.3340       10.6176  0.0917\n",
      "     51       10.6176       0.3340       10.6176  0.0854\n",
      "     52       10.6176       0.3340       10.6176  0.0967\n",
      "     53       10.6176       0.3340       10.6176  0.1086\n",
      "     54       10.6176       0.3340       10.6176  0.0903\n",
      "     55       10.6176       0.3340       10.6176  0.0896\n",
      "     56       10.6176       0.3340       10.6176  0.0910\n",
      "     57       10.6176       0.3340       10.6176  0.0970\n",
      "     58       10.6176       0.3340       10.6176  0.0931\n",
      "     59       10.6176       0.3340       10.6176  0.0948\n",
      "     60       10.6176       0.3340       10.6176  0.0912\n",
      "     61       10.6176       0.3340       10.6176  0.0913\n",
      "     62       10.6176       0.3340       10.6176  0.1125\n",
      "     63       10.6176       0.3340       10.6176  0.0915\n",
      "     64       10.6176       0.3340       10.6176  0.0939\n",
      "     65       10.6176       0.3340       10.6176  0.0885\n",
      "     66       10.6176       0.3340       10.6176  0.0890\n",
      "     67       10.6176       0.3340       10.6176  0.0847\n",
      "     68       10.6176       0.3340       10.6176  0.0903\n",
      "     69       10.6176       0.3340       10.6176  0.0931\n",
      "     70       10.6176       0.3340       10.6176  0.0907\n",
      "     71       10.6176       0.3340       10.6176  0.0917\n",
      "     72       10.6176       0.3340       10.6176  0.0916\n",
      "     73       10.6176       0.3340       10.6176  0.0885\n",
      "     74       10.6176       0.3340       10.6176  0.0921\n",
      "     75       10.6176       0.3340       10.6176  0.0959\n",
      "     76       10.6176       0.3340       10.6176  0.0881\n",
      "     77       10.6176       0.3340       10.6176  0.0906\n",
      "     78       10.6176       0.3340       10.6176  0.0969\n",
      "     79       10.6176       0.3340       10.6176  0.0903\n",
      "     80       10.6176       0.3340       10.6176  0.0915\n",
      "     81       10.6176       0.3340       10.6176  0.1072\n",
      "     82       10.6176       0.3340       10.6176  0.0928\n",
      "     83       10.6176       0.3340       10.6176  0.0981\n",
      "     84       10.6176       0.3340       10.6176  0.0930\n",
      "     85       10.6176       0.3340       10.6176  0.0897\n",
      "     86       10.6176       0.3340       10.6176  0.0908\n",
      "     87       10.6176       0.3340       10.6176  0.0940\n",
      "     88       10.6176       0.3340       10.6176  0.0940\n",
      "     89       10.6176       0.3340       10.6176  0.0844\n",
      "     90       10.6176       0.3340       10.6176  0.0983\n",
      "     91       10.6176       0.3340       10.6176  0.0908\n",
      "     92       10.6176       0.3340       10.6176  0.0906\n",
      "     93       10.6176       0.3340       10.6176  0.0937\n",
      "     94       10.6176       0.3340       10.6176  0.0891\n",
      "     95       10.6176       0.3340       10.6176  0.0911\n",
      "     96       10.6176       0.3340       10.6176  0.0940\n",
      "     97       10.6176       0.3340       10.6176  0.0951\n",
      "     98       10.6176       0.3340       10.6176  0.0930\n",
      "     99       10.6176       0.3340       10.6176  0.0865\n",
      "    100       10.6176       0.3340       10.6176  0.0986\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5152\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.0907\n",
      "      2       10.6176       0.3340       10.6176  0.0885\n",
      "      3       10.6176       0.3340       10.6176  0.0925\n",
      "      4       10.6176       0.3340       10.6176  0.0887\n",
      "      5       10.6176       0.3340       10.6176  0.1056\n",
      "      6       10.6176       0.3340       10.6176  0.1038\n",
      "      7       10.6176       0.3340       10.6176  0.0960\n",
      "      8       10.6176       0.3340       10.6176  0.0904\n",
      "      9       10.6176       0.3340       10.6176  0.0936\n",
      "     10       10.6176       0.3340       10.6176  0.0926\n",
      "     11       10.6176       0.3340       10.6176  0.0928\n",
      "     12       10.6176       0.3340       10.6176  0.0921\n",
      "     13       10.6176       0.3340       10.6176  0.0924\n",
      "     14       10.6176       0.3340       10.6176  0.0941\n",
      "     15       10.6176       0.3340       10.6176  0.0951\n",
      "     16       10.6176       0.3340       10.6176  0.0974\n",
      "     17       10.6176       0.3340       10.6176  0.1010\n",
      "     18       10.6176       0.3340       10.6176  0.0887\n",
      "     19       10.6176       0.3340       10.6176  0.0915\n",
      "     20       10.6176       0.3340       10.6176  0.0970\n",
      "     21       10.6176       0.3340       10.6176  0.0872\n",
      "     22       10.6176       0.3340       10.6176  0.0952\n",
      "     23       10.6176       0.3340       10.6176  0.0894\n",
      "     24       10.6176       0.3340       10.6176  0.0912\n",
      "     25       10.6176       0.3340       10.6176  0.1021\n",
      "     26       10.6176       0.3340       10.6176  0.0943\n",
      "     27       10.6176       0.3340       10.6176  0.0882\n",
      "     28       10.6176       0.3340       10.6176  0.0869\n",
      "     29       10.6176       0.3340       10.6176  0.0849\n",
      "     30       10.6176       0.3340       10.6176  0.0866\n",
      "     31       10.6176       0.3340       10.6176  0.0865\n",
      "     32       10.6176       0.3340       10.6176  0.0926\n",
      "     33       10.6176       0.3340       10.6176  0.0849\n",
      "     34       10.6176       0.3340       10.6176  0.0841\n",
      "     35       10.6176       0.3340       10.6176  0.1087\n",
      "     36       10.6176       0.3340       10.6176  0.0906\n",
      "     37       10.6176       0.3340       10.6176  0.0944\n",
      "     38       10.6176       0.3340       10.6176  0.0856\n",
      "     39       10.6176       0.3340       10.6176  0.0877\n",
      "     40       10.6176       0.3340       10.6176  0.0882\n",
      "     41       10.6176       0.3340       10.6176  0.0917\n",
      "     42       10.6176       0.3340       10.6176  0.0888\n",
      "     43       10.6176       0.3340       10.6176  0.0932\n",
      "     44       10.6176       0.3340       10.6176  0.0864\n",
      "     45       10.6176       0.3340       10.6176  0.0857\n",
      "     46       10.6176       0.3340       10.6176  0.0837\n",
      "     47       10.6176       0.3340       10.6176  0.0956\n",
      "     48       10.6176       0.3340       10.6176  0.0916\n",
      "     49       10.6176       0.3340       10.6176  0.0939\n",
      "     50       10.6176       0.3340       10.6176  0.0928\n",
      "     51       10.6176       0.3340       10.6176  0.0876\n",
      "     52       10.6176       0.3340       10.6176  0.1043\n",
      "     53       10.6176       0.3340       10.6176  0.0933\n",
      "     54       10.6176       0.3340       10.6176  0.0898\n",
      "     55       10.6176       0.3340       10.6176  0.0811\n",
      "     56       10.6176       0.3340       10.6176  0.0961\n",
      "     57       10.6176       0.3340       10.6176  0.0894\n",
      "     58       10.6176       0.3340       10.6176  0.1007\n",
      "     59       10.6176       0.3340       10.6176  0.0885\n",
      "     60       10.6176       0.3340       10.6176  0.0931\n",
      "     61       10.6176       0.3340       10.6176  0.0932\n",
      "     62       10.6176       0.3340       10.6176  0.0898\n",
      "     63       10.6176       0.3340       10.6176  0.0888\n",
      "     64       10.6176       0.3340       10.6176  0.0977\n",
      "     65       10.6176       0.3340       10.6176  0.0936\n",
      "     66       10.6176       0.3340       10.6176  0.0887\n",
      "     67       10.6176       0.3340       10.6176  0.0924\n",
      "     68       10.6176       0.3340       10.6176  0.0927\n",
      "     69       10.6176       0.3340       10.6176  0.0919\n",
      "     70       10.6176       0.3340       10.6176  0.0915\n",
      "     71       10.6176       0.3340       10.6176  0.0887\n",
      "     72       10.6176       0.3340       10.6176  0.0898\n",
      "     73       10.6176       0.3340       10.6176  0.0911\n",
      "     74       10.6176       0.3340       10.6176  0.0937\n",
      "     75       10.6176       0.3340       10.6176  0.0958\n",
      "     76       10.6176       0.3340       10.6176  0.0999\n",
      "     77       10.6176       0.3340       10.6176  0.1041\n",
      "     78       10.6176       0.3340       10.6176  0.0978\n",
      "     79       10.6176       0.3340       10.6176  0.0902\n",
      "     80       10.6176       0.3340       10.6176  0.1030\n",
      "     81       10.6176       0.3340       10.6176  0.0980\n",
      "     82       10.6176       0.3340       10.6176  0.0898\n",
      "     83       10.6176       0.3340       10.6176  0.1115\n",
      "     84       10.6176       0.3340       10.6176  0.0955\n",
      "     85       10.6176       0.3340       10.6176  0.0906\n",
      "     86       10.6176       0.3340       10.6176  0.0940\n",
      "     87       10.6176       0.3340       10.6176  0.0888\n",
      "     88       10.6176       0.3340       10.6176  0.0937\n",
      "     89       10.6176       0.3340       10.6176  0.0895\n",
      "     90       10.6176       0.3340       10.6176  0.0919\n",
      "     91       10.6176       0.3340       10.6176  0.0953\n",
      "     92       10.6176       0.3340       10.6176  0.0852\n",
      "     93       10.6176       0.3340       10.6176  0.0897\n",
      "     94       10.6176       0.3340       10.6176  0.0911\n",
      "     95       10.6176       0.3340       10.6176  0.0913\n",
      "     96       10.6176       0.3340       10.6176  0.0942\n",
      "     97       10.6176       0.3340       10.6176  0.0978\n",
      "     98       10.6176       0.3340       10.6176  0.1004\n",
      "     99       10.6176       0.3340       10.6176  0.0987\n",
      "    100       10.6176       0.3340       10.6176  0.0950\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7343\u001b[0m       \u001b[32m0.6640\u001b[0m        \u001b[35m0.7265\u001b[0m  0.2778\n",
      "      2        \u001b[36m0.6514\u001b[0m       \u001b[32m0.6645\u001b[0m        0.7267  0.2723\n",
      "      3        \u001b[36m0.6344\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.7194\u001b[0m  0.3004\n",
      "      4        \u001b[36m0.6252\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.6741\u001b[0m  0.3189\n",
      "      5        \u001b[36m0.6195\u001b[0m       0.6950        0.6899  0.3130\n",
      "      6        \u001b[36m0.6138\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.6674\u001b[0m  0.3219\n",
      "      7        \u001b[36m0.6103\u001b[0m       \u001b[32m0.7315\u001b[0m        \u001b[35m0.6526\u001b[0m  0.2987\n",
      "      8        \u001b[36m0.6054\u001b[0m       \u001b[32m0.7380\u001b[0m        \u001b[35m0.6402\u001b[0m  0.3024\n",
      "      9        \u001b[36m0.6020\u001b[0m       0.7265        0.6465  0.3047\n",
      "     10        \u001b[36m0.6015\u001b[0m       0.7315        \u001b[35m0.6371\u001b[0m  0.3095\n",
      "     11        \u001b[36m0.5968\u001b[0m       0.7270        \u001b[35m0.6361\u001b[0m  0.3079\n",
      "     12        0.5984       0.7240        \u001b[35m0.6320\u001b[0m  0.2985\n",
      "     13        \u001b[36m0.5956\u001b[0m       0.7275        0.6386  0.2938\n",
      "     14        \u001b[36m0.5938\u001b[0m       0.7320        \u001b[35m0.6263\u001b[0m  0.3189\n",
      "     15        \u001b[36m0.5922\u001b[0m       0.7290        0.6344  0.3132\n",
      "     16        \u001b[36m0.5911\u001b[0m       \u001b[32m0.7425\u001b[0m        \u001b[35m0.6235\u001b[0m  0.2990\n",
      "     17        0.5922       0.7325        \u001b[35m0.6235\u001b[0m  0.2881\n",
      "     18        \u001b[36m0.5894\u001b[0m       0.7355        0.6254  0.2910\n",
      "     19        \u001b[36m0.5893\u001b[0m       0.7305        \u001b[35m0.6204\u001b[0m  0.3060\n",
      "     20        \u001b[36m0.5866\u001b[0m       0.7380        0.6237  0.2982\n",
      "     21        \u001b[36m0.5866\u001b[0m       0.7365        \u001b[35m0.6155\u001b[0m  0.3117\n",
      "     22        \u001b[36m0.5834\u001b[0m       0.7305        0.6183  0.3067\n",
      "     23        \u001b[36m0.5832\u001b[0m       0.7380        0.6184  0.2933\n",
      "     24        \u001b[36m0.5818\u001b[0m       0.7410        0.6187  0.3010\n",
      "     25        0.5819       0.7405        0.6179  0.2967\n",
      "     26        \u001b[36m0.5817\u001b[0m       0.7370        0.6193  0.3082\n",
      "     27        \u001b[36m0.5787\u001b[0m       0.7300        0.6212  0.3137\n",
      "     28        0.5787       0.7395        \u001b[35m0.6136\u001b[0m  0.3330\n",
      "     29        \u001b[36m0.5757\u001b[0m       0.7400        0.6155  0.3103\n",
      "     30        0.5784       0.7370        0.6247  0.3220\n",
      "     31        0.5769       0.7390        0.6188  0.2995\n",
      "     32        0.5768       0.7320        0.6155  0.3228\n",
      "     33        \u001b[36m0.5754\u001b[0m       0.7370        \u001b[35m0.6134\u001b[0m  0.3152\n",
      "     34        0.5756       0.7340        0.6249  0.3117\n",
      "     35        \u001b[36m0.5737\u001b[0m       0.7360        0.6242  0.3069\n",
      "     36        0.5739       0.7345        0.6274  0.3143\n",
      "     37        0.5737       0.7315        0.6214  0.3197\n",
      "     38        \u001b[36m0.5726\u001b[0m       0.7375        0.6246  0.3120\n",
      "     39        \u001b[36m0.5702\u001b[0m       0.7400        0.6265  0.3247\n",
      "     40        \u001b[36m0.5690\u001b[0m       0.7340        0.6308  0.3303\n",
      "     41        0.5697       0.7365        0.6405  0.3158\n",
      "     42        \u001b[36m0.5676\u001b[0m       0.7335        0.6425  0.3046\n",
      "     43        0.5676       0.7320        0.6372  0.3134\n",
      "     44        0.5682       0.7380        0.6325  0.3070\n",
      "     45        \u001b[36m0.5672\u001b[0m       0.7310        0.6396  0.3080\n",
      "     46        0.5679       0.7340        0.6432  0.3185\n",
      "     47        \u001b[36m0.5667\u001b[0m       \u001b[32m0.7435\u001b[0m        0.6316  0.3209\n",
      "     48        \u001b[36m0.5645\u001b[0m       0.7410        0.6438  0.3012\n",
      "     49        0.5666       0.7360        0.6455  0.3151\n",
      "     50        0.5655       0.7415        0.6400  0.3242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;dtf&#x27;,\n",
       "                                        &lt;__main__.Data_Transformer object at 0x000001D697FC1F10&gt;),\n",
       "                                       (&#x27;rescale&#x27;,\n",
       "                                        &lt;__main__.CustomScaler object at 0x000001D6978A1090&gt;),\n",
       "                                       (&#x27;nn_model&#x27;,\n",
       "                                        &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       "))]),\n",
       "             param_grid={&#x27;nn_model__batch_size&#x27;: [32, 64],\n",
       "                         &#x27;nn_model__lr&#x27;: [0.01, 0.1],\n",
       "                         &#x27;nn_model__max_epochs&#x27;: [10, 50, 100],\n",
       "                         &#x27;nn_model__optimizer&#x27;: [&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;,\n",
       "                                                 &lt;class &#x27;torch.optim.rmsprop.RMSprop&#x27;&gt;]},\n",
       "             scoring=make_scorer(f1_score, average=macro))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;dtf&#x27;,\n",
       "                                        &lt;__main__.Data_Transformer object at 0x000001D697FC1F10&gt;),\n",
       "                                       (&#x27;rescale&#x27;,\n",
       "                                        &lt;__main__.CustomScaler object at 0x000001D6978A1090&gt;),\n",
       "                                       (&#x27;nn_model&#x27;,\n",
       "                                        &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       "))]),\n",
       "             param_grid={&#x27;nn_model__batch_size&#x27;: [32, 64],\n",
       "                         &#x27;nn_model__lr&#x27;: [0.01, 0.1],\n",
       "                         &#x27;nn_model__max_epochs&#x27;: [10, 50, 100],\n",
       "                         &#x27;nn_model__optimizer&#x27;: [&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;,\n",
       "                                                 &lt;class &#x27;torch.optim.rmsprop.RMSprop&#x27;&gt;]},\n",
       "             scoring=make_scorer(f1_score, average=macro))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;dtf&#x27;,\n",
       "                 &lt;__main__.Data_Transformer object at 0x000001D697FC1F10&gt;),\n",
       "                (&#x27;rescale&#x27;,\n",
       "                 &lt;__main__.CustomScaler object at 0x000001D6978A1090&gt;),\n",
       "                (&#x27;nn_model&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Data_Transformer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.Data_Transformer object at 0x000001D697FC1F10&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomScaler</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.CustomScaler object at 0x000001D6978A1090&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('dtf',\n",
       "                                        <__main__.Data_Transformer object at 0x000001D697FC1F10>),\n",
       "                                       ('rescale',\n",
       "                                        <__main__.CustomScaler object at 0x000001D6978A1090>),\n",
       "                                       ('nn_model',\n",
       "                                        <class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=<class '__main__.NeuralNetwork'>,\n",
       "))]),\n",
       "             param_grid={'nn_model__batch_size': [32, 64],\n",
       "                         'nn_model__lr': [0.01, 0.1],\n",
       "                         'nn_model__max_epochs': [10, 50, 100],\n",
       "                         'nn_model__optimizer': [<class 'torch.optim.adam.Adam'>,\n",
       "                                                 <class 'torch.optim.rmsprop.RMSprop'>]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gsv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn_model__batch_size': 32,\n",
       " 'nn_model__lr': 0.01,\n",
       " 'nn_model__max_epochs': 50,\n",
       " 'nn_model__optimizer': torch.optim.adam.Adam}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gsv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_nn_model__batch_size</th>\n",
       "      <th>param_nn_model__lr</th>\n",
       "      <th>param_nn_model__max_epochs</th>\n",
       "      <th>param_nn_model__optimizer</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.696215</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.628627</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.705811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.677249</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.691088</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.690415</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.469806</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.597987</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.696065</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.666128</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.681718</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.681421</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.696730</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.642764</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.660353</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.192988</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.702666</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.677972</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_nn_model__batch_size param_nn_model__lr param_nn_model__max_epochs  \\\n",
       "0                          32               0.01                         10   \n",
       "1                          32               0.01                         10   \n",
       "2                          32               0.01                         50   \n",
       "3                          32               0.01                         50   \n",
       "4                          32               0.01                        100   \n",
       "5                          32               0.01                        100   \n",
       "6                          32                0.1                         10   \n",
       "7                          32                0.1                         10   \n",
       "8                          32                0.1                         50   \n",
       "9                          32                0.1                         50   \n",
       "10                         32                0.1                        100   \n",
       "11                         32                0.1                        100   \n",
       "12                         64               0.01                         10   \n",
       "13                         64               0.01                         10   \n",
       "14                         64               0.01                         50   \n",
       "15                         64               0.01                         50   \n",
       "16                         64               0.01                        100   \n",
       "17                         64               0.01                        100   \n",
       "18                         64                0.1                         10   \n",
       "19                         64                0.1                         10   \n",
       "20                         64                0.1                         50   \n",
       "21                         64                0.1                         50   \n",
       "22                         64                0.1                        100   \n",
       "23                         64                0.1                        100   \n",
       "\n",
       "                param_nn_model__optimizer  mean_test_score  rank_test_score  \n",
       "0         <class 'torch.optim.adam.Adam'>         0.696215                4  \n",
       "1   <class 'torch.optim.rmsprop.RMSprop'>         0.628627               16  \n",
       "2         <class 'torch.optim.adam.Adam'>         0.705811                1  \n",
       "3   <class 'torch.optim.rmsprop.RMSprop'>         0.677249               11  \n",
       "4         <class 'torch.optim.adam.Adam'>         0.675912               12  \n",
       "5   <class 'torch.optim.rmsprop.RMSprop'>         0.691088                6  \n",
       "6         <class 'torch.optim.adam.Adam'>         0.690415                7  \n",
       "7   <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  \n",
       "8         <class 'torch.optim.adam.Adam'>         0.469806               18  \n",
       "9   <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  \n",
       "10        <class 'torch.optim.adam.Adam'>         0.597987               17  \n",
       "11  <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  \n",
       "12        <class 'torch.optim.adam.Adam'>         0.696065                5  \n",
       "13  <class 'torch.optim.rmsprop.RMSprop'>         0.666128               13  \n",
       "14        <class 'torch.optim.adam.Adam'>         0.681718                8  \n",
       "15  <class 'torch.optim.rmsprop.RMSprop'>         0.681421                9  \n",
       "16        <class 'torch.optim.adam.Adam'>         0.696730                3  \n",
       "17  <class 'torch.optim.rmsprop.RMSprop'>         0.642764               15  \n",
       "18        <class 'torch.optim.adam.Adam'>         0.660353               14  \n",
       "19  <class 'torch.optim.rmsprop.RMSprop'>         0.192988               19  \n",
       "20        <class 'torch.optim.adam.Adam'>         0.702666                2  \n",
       "21  <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  \n",
       "22        <class 'torch.optim.adam.Adam'>         0.677972               10  \n",
       "23  <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model_gsv.cv_results_\n",
    "result = pd.DataFrame(result)[['param_nn_model__batch_size', 'param_nn_model__lr','param_nn_model__max_epochs', 'param_nn_model__optimizer', 'mean_test_score', 'rank_test_score']]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model_gsv.predict(X_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75       822\n",
      "           1       0.73      0.85      0.79      1217\n",
      "           2       0.70      0.57      0.62       461\n",
      "\n",
      "    accuracy                           0.75      2500\n",
      "   macro avg       0.75      0.71      0.72      2500\n",
      "weighted avg       0.75      0.75      0.74      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 577,  212,   33],\n",
       "       [ 104, 1032,   81],\n",
       "       [  32,  168,  261]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02417962, 0.9703993 , 0.00542107],\n",
       "       [0.05330379, 0.9400862 , 0.00661001],\n",
       "       [0.20553866, 0.45774844, 0.336713  ],\n",
       "       ...,\n",
       "       [0.02704881, 0.95887786, 0.01407323],\n",
       "       [0.10293044, 0.89289486, 0.00417472],\n",
       "       [0.01580616, 0.15460268, 0.8295912 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_proba = model_gsv.predict_proba(X_test)\n",
    "y_test_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Receiver Operating Characteristic - NeuralNetworkClassifier (PyTorch)')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for class_idx in range(len(model_gsv.best_estimator_.classes_)):\n",
    "    y_true = (y_test == model_gsv.best_estimator_.classes_[class_idx]).astype(int)\n",
    "    y_pred_proba = y_test_pred_proba[:, class_idx]\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'Class {model_gsv.best_estimator_.classes_[class_idx]} (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - NeuralNetworkClassifier (PyTorch)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
