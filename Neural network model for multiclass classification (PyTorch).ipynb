{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df.dropna(subset=['Credit_Score'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = df.columns.tolist()\n",
    "x_columns.remove('Credit_Score')\n",
    "X = df[x_columns]\n",
    "y = df['Credit_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class Data_Transformer(object):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.mean_age = X[\"Age\"].mean()\n",
    "        self.occu_le = LabelEncoder() # create label-encoder\n",
    "        encoded_occupation = pd.Series(self.occu_le.fit_transform(X[\"Occupation\"])) # fit and transform occupation with label-encoder\n",
    "        self.majority_occupation = encoded_occupation.mode()[0] # obtain majority occupation code\n",
    "        self.mean_annual_income = X[\"Annual_Income\"].mean()\n",
    "        self.mean_monthly_inhand_salary = X[\"Monthly_Inhand_Salary\"].mean()\n",
    "        self.mean_num_bank_accounts = X[\"Num_Bank_Accounts\"].mean()\n",
    "        self.mean_num_creadit_card = X[\"Num_Credit_Card\"].mean()\n",
    "        self.mean_num_interest_rate = X['Interest_Rate'].mean()\n",
    "        self.mean_num_of_loan = X['Num_of_Loan'].mean()\n",
    "        self.mean_delay_from_due_date = X['Delay_from_due_date'].mean()\n",
    "        self.mean_num_of_delayed_payment = X['Num_of_Delayed_Payment'].mean()\n",
    "        self.mean_changed_credit_limit = X['Changed_Credit_Limit'].mean()\n",
    "        self.mean_num_credit_inquiries = X['Num_Credit_Inquiries'].mean()\n",
    "        self.cm_le = LabelEncoder() # create label-encoder\n",
    "        encoded_credit_mix = pd.Series(self.cm_le.fit_transform(X[\"Credit_Mix\"])) # fit and transform credit mix with label-encoder\n",
    "        self.majority_credit_mix = encoded_credit_mix.mode()[0] # obtain majority credit mix code\n",
    "        self.mean_outstanding_debt = X['Outstanding_Debt'].mean()\n",
    "        self.mean_credit_history_age = X['Credit_History_Age'].mean()\n",
    "        self.pma_le = LabelEncoder() # create label-encoder\n",
    "        encoded_payment_of_min_amount = pd.Series(self.pma_le.fit_transform(X[\"Payment_of_Min_Amount\"])) # fit and transform payment of min amount with label-encoder\n",
    "        self.majority_payment_of_min_amount = encoded_payment_of_min_amount.mode()[0] # obtain majority payment of min amount\n",
    "        self.mean_total_EMI_per_month = X['Total_EMI_per_month'].mean()\n",
    "        self.mean_amount_invested_monthly = X['Amount_invested_monthly'].mean()\n",
    "        self.pb_le = LabelEncoder() # create label-encoder\n",
    "        encoded_payment_behaviour = pd.Series(self.pb_le.fit_transform(X[\"Payment_Behaviour\"])) # fit and transform payment behaviour with label-encoder\n",
    "        self.majority_payment_behaviour = encoded_payment_behaviour.mode()[0] # obtain majority payment behaviour\n",
    "        self.mean_monthly_balance = X['Monthly_Balance'].mean()\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        new_df = pd.DataFrame()\n",
    "        new_df[\"Age\"] = X[\"Age\"]\n",
    "        new_df[\"Age\"].fillna(self.mean_age,inplace=True)\n",
    "        new_df[\"Occupation\"] = self.occu_le.transform(X[\"Occupation\"])\n",
    "        new_df[\"Occupation\"].fillna(self.majority_occupation,inplace=True)\n",
    "        new_df[\"Annual_Income\"] = X[\"Annual_Income\"]\n",
    "        new_df[\"Annual_Income\"].fillna(self.mean_annual_income,inplace=True)\n",
    "        new_df[\"Monthly_Inhand_Salary\"] = X[\"Monthly_Inhand_Salary\"]\n",
    "        new_df[\"Monthly_Inhand_Salary\"].fillna(self.mean_monthly_inhand_salary,inplace=True)\n",
    "        new_df[\"Num_Bank_Accounts\"] = X[\"Num_Bank_Accounts\"]\n",
    "        new_df[\"Num_Bank_Accounts\"].fillna(self.mean_num_bank_accounts,inplace=True)\n",
    "        new_df[\"Num_Credit_Card\"] = X[\"Num_Credit_Card\"]\n",
    "        new_df[\"Num_Credit_Card\"].fillna(self.mean_num_creadit_card,inplace=True)\n",
    "        new_df[\"Interest_Rate\"] = X[\"Interest_Rate\"]\n",
    "        new_df[\"Interest_Rate\"].fillna(self.mean_num_interest_rate,inplace=True)\n",
    "        new_df[\"Num_of_Loan\"] = X[\"Num_of_Loan\"]\n",
    "        new_df[\"Num_of_Loan\"].fillna(self.mean_num_of_loan,inplace=True)\n",
    "        new_df[\"Delay_from_due_date\"] = X[\"Delay_from_due_date\"]\n",
    "        new_df[\"Delay_from_due_date\"].fillna(self.mean_delay_from_due_date,inplace=True)\n",
    "        new_df[\"Num_of_Delayed_Payment\"] = X[\"Num_of_Delayed_Payment\"]\n",
    "        new_df[\"Num_of_Delayed_Payment\"].fillna(self.mean_num_of_delayed_payment,inplace=True)\n",
    "        new_df[\"Changed_Credit_Limit\"] = X[\"Changed_Credit_Limit\"]\n",
    "        new_df[\"Changed_Credit_Limit\"].fillna(self.mean_changed_credit_limit,inplace=True)\n",
    "        new_df[\"Num_Credit_Inquiries\"] = X[\"Num_Credit_Inquiries\"]\n",
    "        new_df[\"Num_Credit_Inquiries\"].fillna(self.mean_num_credit_inquiries,inplace=True)\n",
    "        new_df[\"Credit_Mix\"] = self.cm_le.transform(X[\"Credit_Mix\"])\n",
    "        new_df[\"Credit_Mix\"].fillna(self.majority_credit_mix,inplace=True)\n",
    "        new_df[\"Outstanding_Debt\"] = X[\"Outstanding_Debt\"]\n",
    "        new_df[\"Outstanding_Debt\"].fillna(self.mean_outstanding_debt,inplace=True)\n",
    "        new_df[\"Credit_History_Age\"] = X[\"Credit_History_Age\"]\n",
    "        new_df[\"Credit_History_Age\"].fillna(self.mean_credit_history_age,inplace=True)\n",
    "        new_df[\"Payment_of_Min_Amount\"] = self.pma_le.transform(X[\"Payment_of_Min_Amount\"])\n",
    "        new_df[\"Payment_of_Min_Amount\"].fillna(self.majority_payment_of_min_amount,inplace=True)\n",
    "        new_df[\"Total_EMI_per_month\"] = X[\"Total_EMI_per_month\"]\n",
    "        new_df[\"Total_EMI_per_month\"].fillna(self.mean_total_EMI_per_month,inplace=True)\n",
    "        new_df[\"Amount_invested_monthly\"] = X[\"Amount_invested_monthly\"]\n",
    "        new_df[\"Amount_invested_monthly\"].fillna(self.mean_amount_invested_monthly,inplace=True)\n",
    "        new_df[\"Payment_Behaviour\"] = self.pb_le.transform(X[\"Payment_Behaviour\"])\n",
    "        new_df[\"Payment_Behaviour\"].fillna(self.majority_payment_behaviour,inplace=True)\n",
    "        new_df[\"Monthly_Balance\"] = X[\"Monthly_Balance\"]\n",
    "        new_df[\"Monthly_Balance\"].fillna(self.mean_monthly_balance,inplace=True)\n",
    "        return new_df\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch.classifier import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 3)\n",
    "        #If binary classification, last layer outputs 2 values\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.softmax(self.fc3(x), dim=1)\n",
    "        #If binary classification, last layer uses nn.functional.sigmoid\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler():\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = self.scaler.transform(X)\n",
    "        return torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps =[('dtf', Data_Transformer()),\n",
    "        ('rescale', CustomScaler()),\n",
    "        ('nn_model', NeuralNetClassifier(module=NeuralNetwork, device='cuda' if torch.cuda.is_available() else 'cpu'))]\n",
    "        #If binary classification, nn_model uses NeuralNetBinaryClassifier \n",
    "model = Pipeline(steps)\n",
    "param_grid = {'nn_model__batch_size': [32, 64],\n",
    "                'nn_model__max_epochs': [10, 50, 100],\n",
    "                'nn_model__lr': [0.01, 0.1],\n",
    "                'nn_model__optimizer': [optim.Adam, optim.RMSprop]}\n",
    "model_gsv = GridSearchCV(estimator=model, param_grid=param_grid, cv=2, scoring=make_scorer(f1_score, average='macro', greater_is_better=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8243\u001b[0m       \u001b[32m0.6500\u001b[0m        \u001b[35m0.7636\u001b[0m  1.2503\n",
      "      2        \u001b[36m0.7086\u001b[0m       \u001b[32m0.6890\u001b[0m        \u001b[35m0.6817\u001b[0m  0.2868\n",
      "      3        \u001b[36m0.6649\u001b[0m       \u001b[32m0.6930\u001b[0m        0.6854  0.2595\n",
      "      4        \u001b[36m0.6536\u001b[0m       0.6860        0.6818  0.2533\n",
      "      5        \u001b[36m0.6418\u001b[0m       \u001b[32m0.7030\u001b[0m        \u001b[35m0.6680\u001b[0m  0.2661\n",
      "      6        \u001b[36m0.6338\u001b[0m       0.7030        0.6698  0.2614\n",
      "      7        \u001b[36m0.6282\u001b[0m       0.6970        0.6703  0.2722\n",
      "      8        \u001b[36m0.6227\u001b[0m       0.7030        \u001b[35m0.6645\u001b[0m  0.2529\n",
      "      9        \u001b[36m0.6161\u001b[0m       \u001b[32m0.7040\u001b[0m        \u001b[35m0.6583\u001b[0m  0.2645\n",
      "     10        \u001b[36m0.6123\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6517\u001b[0m  0.2736\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7716\u001b[0m       \u001b[32m0.6180\u001b[0m        \u001b[35m0.7977\u001b[0m  0.3030\n",
      "      2        \u001b[36m0.6811\u001b[0m       \u001b[32m0.6770\u001b[0m        \u001b[35m0.7180\u001b[0m  0.2893\n",
      "      3        \u001b[36m0.6466\u001b[0m       \u001b[32m0.7410\u001b[0m        \u001b[35m0.6428\u001b[0m  0.2824\n",
      "      4        \u001b[36m0.6289\u001b[0m       0.7370        0.6460  0.2797\n",
      "      5        \u001b[36m0.6225\u001b[0m       \u001b[32m0.7430\u001b[0m        \u001b[35m0.6376\u001b[0m  0.2729\n",
      "      6        \u001b[36m0.6174\u001b[0m       \u001b[32m0.7520\u001b[0m        \u001b[35m0.6287\u001b[0m  0.2846\n",
      "      7        0.6175       \u001b[32m0.7540\u001b[0m        \u001b[35m0.6230\u001b[0m  0.2726\n",
      "      8        \u001b[36m0.6126\u001b[0m       0.7490        0.6254  0.3052\n",
      "      9        \u001b[36m0.6120\u001b[0m       0.7490        0.6232  0.2806\n",
      "     10        \u001b[36m0.6113\u001b[0m       \u001b[32m0.7560\u001b[0m        \u001b[35m0.6195\u001b[0m  0.2997\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7897\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.6696\u001b[0m  0.2914\n",
      "      2        \u001b[36m0.6548\u001b[0m       0.7110        \u001b[35m0.6504\u001b[0m  0.2765\n",
      "      3        \u001b[36m0.6357\u001b[0m       0.7150        \u001b[35m0.6449\u001b[0m  0.3480\n",
      "      4        \u001b[36m0.6299\u001b[0m       \u001b[32m0.7210\u001b[0m        \u001b[35m0.6409\u001b[0m  0.3023\n",
      "      5        \u001b[36m0.6237\u001b[0m       \u001b[32m0.7220\u001b[0m        \u001b[35m0.6355\u001b[0m  0.2944\n",
      "      6        \u001b[36m0.6204\u001b[0m       \u001b[32m0.7280\u001b[0m        0.6355  0.3116\n",
      "      7        \u001b[36m0.6158\u001b[0m       0.7220        \u001b[35m0.6318\u001b[0m  0.2863\n",
      "      8        \u001b[36m0.6098\u001b[0m       \u001b[32m0.7340\u001b[0m        0.6369  0.2931\n",
      "      9        \u001b[36m0.6062\u001b[0m       0.7280        0.6341  0.2752\n",
      "     10        \u001b[36m0.6009\u001b[0m       0.7290        \u001b[35m0.6303\u001b[0m  0.2719\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8156\u001b[0m       \u001b[32m0.5010\u001b[0m        \u001b[35m1.0817\u001b[0m  0.2848\n",
      "      2        \u001b[36m0.7016\u001b[0m       \u001b[32m0.5740\u001b[0m        \u001b[35m0.9093\u001b[0m  0.2674\n",
      "      3        \u001b[36m0.6664\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.8574\u001b[0m  0.2701\n",
      "      4        \u001b[36m0.6444\u001b[0m       0.5920        \u001b[35m0.8494\u001b[0m  0.2708\n",
      "      5        \u001b[36m0.6346\u001b[0m       \u001b[32m0.6380\u001b[0m        \u001b[35m0.8106\u001b[0m  0.2825\n",
      "      6        \u001b[36m0.6276\u001b[0m       \u001b[32m0.6490\u001b[0m        \u001b[35m0.7966\u001b[0m  0.2749\n",
      "      7        \u001b[36m0.6219\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.7941\u001b[0m  0.2696\n",
      "      8        \u001b[36m0.6186\u001b[0m       0.6590        0.7972  0.2796\n",
      "      9        \u001b[36m0.6136\u001b[0m       \u001b[32m0.6780\u001b[0m        \u001b[35m0.7897\u001b[0m  0.2779\n",
      "     10        \u001b[36m0.6101\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m0.7865\u001b[0m  0.2807\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8157\u001b[0m       \u001b[32m0.6260\u001b[0m        \u001b[35m0.7529\u001b[0m  0.3138\n",
      "      2        \u001b[36m0.7088\u001b[0m       \u001b[32m0.6730\u001b[0m        \u001b[35m0.7141\u001b[0m  0.3221\n",
      "      3        \u001b[36m0.6751\u001b[0m       \u001b[32m0.6810\u001b[0m        \u001b[35m0.6951\u001b[0m  0.3204\n",
      "      4        \u001b[36m0.6573\u001b[0m       \u001b[32m0.6870\u001b[0m        \u001b[35m0.6910\u001b[0m  0.3315\n",
      "      5        \u001b[36m0.6486\u001b[0m       \u001b[32m0.6970\u001b[0m        \u001b[35m0.6831\u001b[0m  0.3180\n",
      "      6        \u001b[36m0.6377\u001b[0m       \u001b[32m0.7110\u001b[0m        \u001b[35m0.6722\u001b[0m  0.3176\n",
      "      7        \u001b[36m0.6287\u001b[0m       0.7080        \u001b[35m0.6675\u001b[0m  0.3532\n",
      "      8        \u001b[36m0.6240\u001b[0m       0.6950        0.6680  0.2734\n",
      "      9        \u001b[36m0.6218\u001b[0m       0.6960        0.6691  0.2679\n",
      "     10        \u001b[36m0.6162\u001b[0m       0.6930        \u001b[35m0.6590\u001b[0m  0.2946\n",
      "     11        \u001b[36m0.6124\u001b[0m       0.6940        0.6595  0.2904\n",
      "     12        \u001b[36m0.6102\u001b[0m       0.6990        0.6637  0.3379\n",
      "     13        \u001b[36m0.6091\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6521\u001b[0m  0.2759\n",
      "     14        \u001b[36m0.6052\u001b[0m       0.7120        0.6551  0.2699\n",
      "     15        \u001b[36m0.6035\u001b[0m       0.7070        \u001b[35m0.6484\u001b[0m  0.2724\n",
      "     16        \u001b[36m0.5999\u001b[0m       0.7080        0.6556  0.2770\n",
      "     17        0.6000       0.7140        0.6492  0.2851\n",
      "     18        \u001b[36m0.5986\u001b[0m       0.7110        0.6497  0.2933\n",
      "     19        \u001b[36m0.5943\u001b[0m       \u001b[32m0.7160\u001b[0m        0.6576  0.3001\n",
      "     20        0.5967       0.7090        0.6493  0.2957\n",
      "     21        0.5952       0.7100        0.6500  0.3132\n",
      "     22        \u001b[36m0.5939\u001b[0m       0.7050        0.6493  0.3005\n",
      "     23        \u001b[36m0.5917\u001b[0m       0.7110        \u001b[35m0.6468\u001b[0m  0.3115\n",
      "     24        \u001b[36m0.5886\u001b[0m       0.7020        0.6621  0.2990\n",
      "     25        0.5898       0.6960        0.6604  0.2903\n",
      "     26        0.5890       0.7030        0.6548  0.3031\n",
      "     27        \u001b[36m0.5868\u001b[0m       0.6960        0.6583  0.3209\n",
      "     28        \u001b[36m0.5846\u001b[0m       0.7060        0.6481  0.3229\n",
      "     29        \u001b[36m0.5830\u001b[0m       0.7020        0.6676  0.3276\n",
      "     30        0.5835       0.7120        0.6563  0.3336\n",
      "     31        \u001b[36m0.5805\u001b[0m       0.7070        0.6564  0.3488\n",
      "     32        \u001b[36m0.5802\u001b[0m       0.7110        0.6577  0.3364\n",
      "     33        \u001b[36m0.5774\u001b[0m       \u001b[32m0.7170\u001b[0m        0.6511  0.3138\n",
      "     34        \u001b[36m0.5765\u001b[0m       0.7050        0.6598  0.3145\n",
      "     35        \u001b[36m0.5764\u001b[0m       0.7130        0.6719  0.3166\n",
      "     36        \u001b[36m0.5753\u001b[0m       0.7150        0.6736  0.3131\n",
      "     37        \u001b[36m0.5729\u001b[0m       \u001b[32m0.7210\u001b[0m        0.6737  0.3243\n",
      "     38        0.5741       0.7190        0.6736  0.3319\n",
      "     39        \u001b[36m0.5720\u001b[0m       0.7200        0.6939  0.3676\n",
      "     40        0.5804       0.7180        0.6809  0.3636\n",
      "     41        0.5784       0.7170        0.6603  0.2926\n",
      "     42        0.5725       0.7170        0.6610  0.2987\n",
      "     43        0.5734       \u001b[32m0.7220\u001b[0m        0.6530  0.3311\n",
      "     44        0.5724       0.7160        0.6636  0.2781\n",
      "     45        0.5738       0.7210        0.6627  0.2838\n",
      "     46        \u001b[36m0.5698\u001b[0m       0.7210        0.6711  0.2626\n",
      "     47        0.5712       0.7150        0.6659  0.2875\n",
      "     48        \u001b[36m0.5684\u001b[0m       0.7110        0.6855  0.2887\n",
      "     49        0.5690       0.7140        0.6724  0.2904\n",
      "     50        0.5693       0.7050        0.6808  0.2723\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7696\u001b[0m       \u001b[32m0.6570\u001b[0m        \u001b[35m0.7647\u001b[0m  0.2894\n",
      "      2        \u001b[36m0.6664\u001b[0m       \u001b[32m0.7220\u001b[0m        \u001b[35m0.6815\u001b[0m  0.2593\n",
      "      3        \u001b[36m0.6393\u001b[0m       \u001b[32m0.7410\u001b[0m        \u001b[35m0.6444\u001b[0m  0.2519\n",
      "      4        \u001b[36m0.6288\u001b[0m       \u001b[32m0.7520\u001b[0m        \u001b[35m0.6192\u001b[0m  0.2662\n",
      "      5        \u001b[36m0.6218\u001b[0m       0.7520        \u001b[35m0.6128\u001b[0m  0.2765\n",
      "      6        \u001b[36m0.6172\u001b[0m       0.7520        0.6144  0.2725\n",
      "      7        \u001b[36m0.6132\u001b[0m       0.7470        0.6259  0.2899\n",
      "      8        \u001b[36m0.6126\u001b[0m       0.7480        0.6171  0.2937\n",
      "      9        \u001b[36m0.6084\u001b[0m       0.7480        0.6184  0.2876\n",
      "     10        \u001b[36m0.6070\u001b[0m       0.7500        0.6278  0.2968\n",
      "     11        \u001b[36m0.6045\u001b[0m       0.7500        0.6321  0.3207\n",
      "     12        \u001b[36m0.6034\u001b[0m       0.7480        0.6421  0.3156\n",
      "     13        \u001b[36m0.6031\u001b[0m       0.7510        0.6308  0.2989\n",
      "     14        \u001b[36m0.6029\u001b[0m       \u001b[32m0.7530\u001b[0m        0.6397  0.3156\n",
      "     15        \u001b[36m0.6002\u001b[0m       0.7510        0.6356  0.3084\n",
      "     16        \u001b[36m0.5983\u001b[0m       0.7460        0.6459  0.3000\n",
      "     17        \u001b[36m0.5961\u001b[0m       0.7510        0.6302  0.3093\n",
      "     18        \u001b[36m0.5913\u001b[0m       0.7440        0.6326  0.3315\n",
      "     19        \u001b[36m0.5895\u001b[0m       0.7440        0.6422  0.3453\n",
      "     20        0.5900       0.7500        0.6201  0.3623\n",
      "     21        \u001b[36m0.5878\u001b[0m       0.7490        0.6443  0.3459\n",
      "     22        \u001b[36m0.5876\u001b[0m       0.7390        0.6357  0.3372\n",
      "     23        \u001b[36m0.5860\u001b[0m       0.7530        0.6277  0.3560\n",
      "     24        \u001b[36m0.5833\u001b[0m       \u001b[32m0.7570\u001b[0m        0.6247  0.2839\n",
      "     25        \u001b[36m0.5786\u001b[0m       0.7450        0.6254  0.2634\n",
      "     26        0.5859       \u001b[32m0.7580\u001b[0m        0.6207  0.2615\n",
      "     27        0.5803       \u001b[32m0.7620\u001b[0m        \u001b[35m0.6122\u001b[0m  0.2779\n",
      "     28        \u001b[36m0.5772\u001b[0m       0.7550        0.6256  0.3040\n",
      "     29        0.5806       0.7570        0.6179  0.2816\n",
      "     30        0.5801       0.7620        0.6149  0.3007\n",
      "     31        \u001b[36m0.5737\u001b[0m       0.7590        0.6172  0.2853\n",
      "     32        0.5740       0.7480        0.6211  0.2836\n",
      "     33        \u001b[36m0.5734\u001b[0m       0.7510        0.6164  0.2798\n",
      "     34        \u001b[36m0.5687\u001b[0m       \u001b[32m0.7630\u001b[0m        \u001b[35m0.6089\u001b[0m  0.2983\n",
      "     35        \u001b[36m0.5670\u001b[0m       0.7530        0.6198  0.2806\n",
      "     36        0.5678       0.7620        0.6135  0.2857\n",
      "     37        \u001b[36m0.5636\u001b[0m       0.7630        0.6195  0.2939\n",
      "     38        \u001b[36m0.5631\u001b[0m       0.7570        0.6174  0.3113\n",
      "     39        0.5649       0.7550        0.6279  0.2866\n",
      "     40        0.5635       \u001b[32m0.7640\u001b[0m        0.6224  0.3085\n",
      "     41        \u001b[36m0.5570\u001b[0m       0.7570        0.6402  0.2836\n",
      "     42        0.5636       0.7610        0.6312  0.3163\n",
      "     43        \u001b[36m0.5556\u001b[0m       \u001b[32m0.7660\u001b[0m        0.6338  0.4245\n",
      "     44        \u001b[36m0.5531\u001b[0m       0.7660        0.6273  0.3080\n",
      "     45        0.5554       0.7540        0.6369  0.3020\n",
      "     46        0.5628       0.7640        0.6263  0.2943\n",
      "     47        0.5540       \u001b[32m0.7710\u001b[0m        0.6215  0.3108\n",
      "     48        \u001b[36m0.5498\u001b[0m       0.7600        0.6280  0.3034\n",
      "     49        0.5506       0.7660        0.6355  0.3121\n",
      "     50        0.5551       0.7680        0.6359  0.3000\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8121\u001b[0m       \u001b[32m0.6970\u001b[0m        \u001b[35m0.6944\u001b[0m  0.2880\n",
      "      2        \u001b[36m0.6744\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6675\u001b[0m  0.2910\n",
      "      3        \u001b[36m0.6483\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m0.6583\u001b[0m  0.3113\n",
      "      4        \u001b[36m0.6364\u001b[0m       0.7140        \u001b[35m0.6566\u001b[0m  0.3504\n",
      "      5        \u001b[36m0.6298\u001b[0m       0.7090        \u001b[35m0.6552\u001b[0m  0.2696\n",
      "      6        \u001b[36m0.6251\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6513\u001b[0m  0.2654\n",
      "      7        \u001b[36m0.6209\u001b[0m       \u001b[32m0.7190\u001b[0m        \u001b[35m0.6492\u001b[0m  0.2813\n",
      "      8        \u001b[36m0.6178\u001b[0m       0.7130        0.6518  0.2681\n",
      "      9        \u001b[36m0.6135\u001b[0m       0.7130        \u001b[35m0.6492\u001b[0m  0.2809\n",
      "     10        \u001b[36m0.6097\u001b[0m       0.7160        \u001b[35m0.6461\u001b[0m  0.3377\n",
      "     11        \u001b[36m0.6054\u001b[0m       0.7070        0.6523  0.2769\n",
      "     12        \u001b[36m0.6028\u001b[0m       0.7140        \u001b[35m0.6413\u001b[0m  0.3075\n",
      "     13        \u001b[36m0.5980\u001b[0m       0.7180        0.6473  0.2762\n",
      "     14        \u001b[36m0.5936\u001b[0m       0.7140        0.6516  0.2850\n",
      "     15        \u001b[36m0.5915\u001b[0m       \u001b[32m0.7210\u001b[0m        0.6513  0.2695\n",
      "     16        \u001b[36m0.5892\u001b[0m       \u001b[32m0.7280\u001b[0m        0.6529  0.2693\n",
      "     17        \u001b[36m0.5864\u001b[0m       0.7250        0.6509  0.2742\n",
      "     18        \u001b[36m0.5834\u001b[0m       0.7230        0.6420  0.3537\n",
      "     19        0.5835       0.7250        0.6421  0.3097\n",
      "     20        \u001b[36m0.5806\u001b[0m       0.7240        0.6481  0.2766\n",
      "     21        \u001b[36m0.5777\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.6406\u001b[0m  0.2834\n",
      "     22        \u001b[36m0.5743\u001b[0m       \u001b[32m0.7310\u001b[0m        0.6539  0.2679\n",
      "     23        0.5746       0.7310        0.6446  0.3433\n",
      "     24        \u001b[36m0.5711\u001b[0m       0.7260        0.6597  0.2659\n",
      "     25        0.5723       0.7280        0.6511  0.2571\n",
      "     26        \u001b[36m0.5700\u001b[0m       0.7190        0.6540  0.2623\n",
      "     27        0.5702       0.7270        0.6619  0.2559\n",
      "     28        \u001b[36m0.5691\u001b[0m       0.7270        0.6624  0.2634\n",
      "     29        \u001b[36m0.5681\u001b[0m       0.7260        0.6631  0.2828\n",
      "     30        0.5691       0.7280        0.6630  0.2715\n",
      "     31        0.5701       0.7210        0.6738  0.2729\n",
      "     32        \u001b[36m0.5639\u001b[0m       0.7170        0.6704  0.2669\n",
      "     33        0.5641       0.7190        0.6635  0.2765\n",
      "     34        \u001b[36m0.5622\u001b[0m       0.7180        0.6641  0.2690\n",
      "     35        0.5633       0.7190        0.6682  0.2666\n",
      "     36        0.5627       0.7160        0.6657  0.2650\n",
      "     37        \u001b[36m0.5608\u001b[0m       0.7220        0.6753  0.2612\n",
      "     38        0.5615       0.7140        0.6795  0.2714\n",
      "     39        0.5618       0.7090        0.6733  0.2704\n",
      "     40        \u001b[36m0.5592\u001b[0m       0.7110        0.6755  0.2681\n",
      "     41        \u001b[36m0.5581\u001b[0m       0.7230        0.6722  0.2803\n",
      "     42        0.5600       0.7000        0.6889  0.2807\n",
      "     43        0.5606       0.7240        0.6811  0.4035\n",
      "     44        \u001b[36m0.5553\u001b[0m       0.7180        0.6712  0.2762\n",
      "     45        0.5583       0.7040        0.6776  0.3297\n",
      "     46        0.5561       0.7220        0.6707  0.3077\n",
      "     47        0.5591       0.7210        0.6861  0.2772\n",
      "     48        \u001b[36m0.5538\u001b[0m       0.7100        0.6820  0.2984\n",
      "     49        0.5555       0.7070        0.6960  0.2492\n",
      "     50        0.5541       0.7190        0.6994  0.2934\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7893\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.2722\u001b[0m  0.3024\n",
      "      2        \u001b[36m0.6699\u001b[0m       \u001b[32m0.5360\u001b[0m        \u001b[35m0.9559\u001b[0m  0.2689\n",
      "      3        \u001b[36m0.6461\u001b[0m       \u001b[32m0.5430\u001b[0m        \u001b[35m0.9240\u001b[0m  0.3738\n",
      "      4        \u001b[36m0.6380\u001b[0m       \u001b[32m0.5670\u001b[0m        \u001b[35m0.8685\u001b[0m  0.3064\n",
      "      5        \u001b[36m0.6334\u001b[0m       \u001b[32m0.5960\u001b[0m        \u001b[35m0.8367\u001b[0m  0.2800\n",
      "      6        \u001b[36m0.6278\u001b[0m       \u001b[32m0.6210\u001b[0m        \u001b[35m0.8077\u001b[0m  0.2899\n",
      "      7        \u001b[36m0.6236\u001b[0m       \u001b[32m0.6370\u001b[0m        \u001b[35m0.7860\u001b[0m  0.2953\n",
      "      8        \u001b[36m0.6194\u001b[0m       \u001b[32m0.6580\u001b[0m        \u001b[35m0.7686\u001b[0m  0.2717\n",
      "      9        \u001b[36m0.6162\u001b[0m       0.6560        \u001b[35m0.7614\u001b[0m  0.2592\n",
      "     10        \u001b[36m0.6144\u001b[0m       \u001b[32m0.6590\u001b[0m        \u001b[35m0.7502\u001b[0m  0.2608\n",
      "     11        \u001b[36m0.6115\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.7476\u001b[0m  0.3201\n",
      "     12        \u001b[36m0.6093\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m0.7331\u001b[0m  0.2786\n",
      "     13        \u001b[36m0.6058\u001b[0m       \u001b[32m0.6910\u001b[0m        \u001b[35m0.7314\u001b[0m  0.2767\n",
      "     14        \u001b[36m0.6030\u001b[0m       \u001b[32m0.7030\u001b[0m        \u001b[35m0.7242\u001b[0m  0.2759\n",
      "     15        \u001b[36m0.5991\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.7237\u001b[0m  0.3801\n",
      "     16        \u001b[36m0.5971\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.7108\u001b[0m  0.2738\n",
      "     17        \u001b[36m0.5950\u001b[0m       \u001b[32m0.7210\u001b[0m        0.7163  0.2562\n",
      "     18        \u001b[36m0.5923\u001b[0m       0.7180        \u001b[35m0.7038\u001b[0m  0.2702\n",
      "     19        \u001b[36m0.5892\u001b[0m       0.7190        \u001b[35m0.7013\u001b[0m  0.2937\n",
      "     20        \u001b[36m0.5872\u001b[0m       0.7120        0.7181  0.3004\n",
      "     21        \u001b[36m0.5844\u001b[0m       0.7140        0.7149  0.2653\n",
      "     22        \u001b[36m0.5842\u001b[0m       \u001b[32m0.7250\u001b[0m        0.7159  0.2700\n",
      "     23        \u001b[36m0.5825\u001b[0m       \u001b[32m0.7280\u001b[0m        \u001b[35m0.7000\u001b[0m  0.2712\n",
      "     24        \u001b[36m0.5789\u001b[0m       0.7210        \u001b[35m0.6981\u001b[0m  0.2785\n",
      "     25        0.5795       0.7200        0.7001  0.3246\n",
      "     26        \u001b[36m0.5771\u001b[0m       0.7190        0.7046  0.3592\n",
      "     27        \u001b[36m0.5759\u001b[0m       0.7260        0.7037  0.2417\n",
      "     28        \u001b[36m0.5735\u001b[0m       0.7250        0.7063  0.2634\n",
      "     29        0.5763       0.7220        \u001b[35m0.6974\u001b[0m  0.2596\n",
      "     30        \u001b[36m0.5715\u001b[0m       0.7120        0.7098  0.2641\n",
      "     31        0.5739       0.7220        0.6978  0.2534\n",
      "     32        \u001b[36m0.5689\u001b[0m       0.7250        \u001b[35m0.6923\u001b[0m  0.2444\n",
      "     33        \u001b[36m0.5673\u001b[0m       0.7140        0.6996  0.2425\n",
      "     34        \u001b[36m0.5651\u001b[0m       0.6980        0.7085  0.2561\n",
      "     35        0.5673       0.7080        0.7026  0.2477\n",
      "     36        \u001b[36m0.5606\u001b[0m       0.7140        0.7063  0.2518\n",
      "     37        \u001b[36m0.5599\u001b[0m       0.7070        0.7083  0.2476\n",
      "     38        0.5625       0.7190        0.7052  0.2435\n",
      "     39        0.5600       0.7180        \u001b[35m0.6764\u001b[0m  0.2665\n",
      "     40        0.5614       0.7090        0.7092  0.2573\n",
      "     41        \u001b[36m0.5584\u001b[0m       0.7050        0.7128  0.2556\n",
      "     42        \u001b[36m0.5583\u001b[0m       0.6910        0.7244  0.2618\n",
      "     43        \u001b[36m0.5554\u001b[0m       0.6980        0.7207  0.3491\n",
      "     44        0.5572       0.7000        0.7042  0.3100\n",
      "     45        0.5556       0.7100        0.7018  0.2969\n",
      "     46        \u001b[36m0.5545\u001b[0m       0.7150        0.7006  0.2995\n",
      "     47        \u001b[36m0.5538\u001b[0m       0.7070        0.7261  0.2750\n",
      "     48        0.5581       0.7160        0.7042  0.2626\n",
      "     49        \u001b[36m0.5519\u001b[0m       0.7180        0.7158  0.2900\n",
      "     50        \u001b[36m0.5506\u001b[0m       0.7140        0.7037  0.2867\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8114\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m0.7673\u001b[0m  0.3217\n",
      "      2        \u001b[36m0.7128\u001b[0m       \u001b[32m0.6780\u001b[0m        \u001b[35m0.7026\u001b[0m  0.3094\n",
      "      3        \u001b[36m0.6761\u001b[0m       \u001b[32m0.6980\u001b[0m        \u001b[35m0.6853\u001b[0m  0.2981\n",
      "      4        \u001b[36m0.6562\u001b[0m       0.6910        0.6916  0.3024\n",
      "      5        \u001b[36m0.6500\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.6742\u001b[0m  0.2801\n",
      "      6        \u001b[36m0.6395\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.6653\u001b[0m  0.3270\n",
      "      7        \u001b[36m0.6315\u001b[0m       0.7040        0.6737  0.3106\n",
      "      8        \u001b[36m0.6260\u001b[0m       0.6970        0.6844  0.2812\n",
      "      9        \u001b[36m0.6210\u001b[0m       0.7030        0.6670  0.2783\n",
      "     10        \u001b[36m0.6186\u001b[0m       0.7110        0.6717  0.2821\n",
      "     11        \u001b[36m0.6134\u001b[0m       \u001b[32m0.7140\u001b[0m        0.6724  0.2829\n",
      "     12        \u001b[36m0.6105\u001b[0m       \u001b[32m0.7240\u001b[0m        0.6712  0.2941\n",
      "     13        \u001b[36m0.6070\u001b[0m       0.7090        0.6864  0.3754\n",
      "     14        0.6098       0.7130        \u001b[35m0.6627\u001b[0m  0.2920\n",
      "     15        \u001b[36m0.6003\u001b[0m       0.7160        0.6646  0.2854\n",
      "     16        \u001b[36m0.5986\u001b[0m       0.7170        \u001b[35m0.6612\u001b[0m  0.2790\n",
      "     17        \u001b[36m0.5978\u001b[0m       0.7220        \u001b[35m0.6584\u001b[0m  0.4015\n",
      "     18        \u001b[36m0.5946\u001b[0m       0.7200        0.6637  0.3032\n",
      "     19        \u001b[36m0.5926\u001b[0m       0.7180        0.6638  0.3101\n",
      "     20        \u001b[36m0.5920\u001b[0m       \u001b[32m0.7310\u001b[0m        0.6599  0.3102\n",
      "     21        \u001b[36m0.5872\u001b[0m       0.7290        \u001b[35m0.6566\u001b[0m  0.3720\n",
      "     22        0.5896       0.7180        0.6598  0.3120\n",
      "     23        0.5885       0.7220        \u001b[35m0.6428\u001b[0m  0.3072\n",
      "     24        \u001b[36m0.5868\u001b[0m       0.7160        0.6616  0.2830\n",
      "     25        \u001b[36m0.5840\u001b[0m       0.7260        0.6599  0.2782\n",
      "     26        \u001b[36m0.5820\u001b[0m       0.7280        0.6549  0.2847\n",
      "     27        \u001b[36m0.5802\u001b[0m       0.7250        0.6653  0.2755\n",
      "     28        \u001b[36m0.5800\u001b[0m       0.7130        0.6591  0.2723\n",
      "     29        \u001b[36m0.5773\u001b[0m       0.7140        0.6701  0.2813\n",
      "     30        0.5774       0.7140        0.6616  0.2910\n",
      "     31        0.5773       0.7140        0.6622  0.3237\n",
      "     32        \u001b[36m0.5748\u001b[0m       0.7090        0.6666  0.3241\n",
      "     33        \u001b[36m0.5729\u001b[0m       0.7150        0.6515  0.3055\n",
      "     34        \u001b[36m0.5693\u001b[0m       0.7120        0.6542  0.2850\n",
      "     35        \u001b[36m0.5689\u001b[0m       0.7190        0.6561  0.2905\n",
      "     36        \u001b[36m0.5682\u001b[0m       0.7160        0.6607  0.2930\n",
      "     37        0.5695       0.7160        0.6803  0.3145\n",
      "     38        \u001b[36m0.5653\u001b[0m       0.7130        0.6681  0.3000\n",
      "     39        \u001b[36m0.5643\u001b[0m       0.7200        0.6539  0.2855\n",
      "     40        \u001b[36m0.5624\u001b[0m       0.7140        0.6597  0.2844\n",
      "     41        0.5641       0.7110        0.6649  0.2711\n",
      "     42        \u001b[36m0.5607\u001b[0m       0.7080        0.6632  0.2801\n",
      "     43        0.5636       0.7020        0.6660  0.3925\n",
      "     44        0.5635       0.7030        0.6715  0.3008\n",
      "     45        0.5635       0.6980        0.6797  0.2950\n",
      "     46        \u001b[36m0.5592\u001b[0m       0.7050        0.6767  0.3311\n",
      "     47        \u001b[36m0.5555\u001b[0m       0.6890        0.7023  0.2774\n",
      "     48        0.5555       0.7040        0.6931  0.2675\n",
      "     49        \u001b[36m0.5542\u001b[0m       0.7130        0.7071  0.2850\n",
      "     50        0.5570       0.7180        0.6919  0.3109\n",
      "     51        \u001b[36m0.5529\u001b[0m       0.7150        0.7398  0.4451\n",
      "     52        \u001b[36m0.5514\u001b[0m       0.7090        0.6969  0.3569\n",
      "     53        0.5535       0.7110        0.6947  0.2807\n",
      "     54        \u001b[36m0.5506\u001b[0m       0.7160        0.7014  0.2855\n",
      "     55        \u001b[36m0.5485\u001b[0m       0.7210        0.7080  0.2783\n",
      "     56        \u001b[36m0.5464\u001b[0m       0.7120        0.7262  0.2950\n",
      "     57        0.5511       0.7180        0.7320  0.2764\n",
      "     58        0.5468       \u001b[32m0.7320\u001b[0m        0.7200  0.3467\n",
      "     59        \u001b[36m0.5450\u001b[0m       0.7240        0.7340  0.3879\n",
      "     60        0.5466       0.7240        0.7568  0.3387\n",
      "     61        0.5555       0.7200        0.7381  0.3145\n",
      "     62        \u001b[36m0.5417\u001b[0m       0.7120        0.7420  0.3069\n",
      "     63        0.5441       0.7200        0.7621  0.2786\n",
      "     64        0.5421       0.7170        0.7472  0.3411\n",
      "     65        0.5419       0.7250        0.7225  0.3102\n",
      "     66        \u001b[36m0.5393\u001b[0m       0.7220        0.7543  0.3087\n",
      "     67        0.5403       0.7230        0.7391  0.2828\n",
      "     68        \u001b[36m0.5353\u001b[0m       0.7240        0.7641  0.3200\n",
      "     69        \u001b[36m0.5335\u001b[0m       0.7220        0.7592  0.3255\n",
      "     70        0.5399       \u001b[32m0.7350\u001b[0m        0.7855  0.3324\n",
      "     71        0.5366       0.7250        0.8100  0.2951\n",
      "     72        0.5385       0.7300        0.7916  0.2947\n",
      "     73        0.5340       0.7290        0.7867  0.3001\n",
      "     74        \u001b[36m0.5263\u001b[0m       0.7320        0.7893  0.3290\n",
      "     75        0.5368       0.7280        0.7949  0.3929\n",
      "     76        0.5373       0.7210        0.7768  0.2835\n",
      "     77        0.5308       0.7310        0.7856  0.2984\n",
      "     78        0.5362       0.7140        0.7557  0.2730\n",
      "     79        0.5307       0.7210        0.8257  0.2806\n",
      "     80        0.5265       0.7270        0.7986  0.2920\n",
      "     81        0.5317       0.7250        0.7953  0.2745\n",
      "     82        0.5267       0.7230        0.8185  0.3157\n",
      "     83        \u001b[36m0.5212\u001b[0m       0.7250        0.8096  0.3539\n",
      "     84        0.5227       0.7330        0.8586  0.2876\n",
      "     85        0.5335       0.7150        0.7707  0.3186\n",
      "     86        0.5241       0.7210        0.8064  0.2820\n",
      "     87        0.5258       0.7170        0.8281  0.2833\n",
      "     88        0.5231       0.7260        0.8281  0.2975\n",
      "     89        0.5220       0.7240        0.8587  0.4000\n",
      "     90        \u001b[36m0.5209\u001b[0m       0.7260        0.8485  0.2966\n",
      "     91        \u001b[36m0.5205\u001b[0m       0.7190        0.8225  0.2930\n",
      "     92        0.5236       0.7160        0.8208  0.2709\n",
      "     93        0.5213       0.7220        0.8514  0.2831\n",
      "     94        \u001b[36m0.5199\u001b[0m       0.7280        0.8632  0.2770\n",
      "     95        0.5218       0.7200        0.8479  0.3067\n",
      "     96        \u001b[36m0.5178\u001b[0m       0.7120        0.8715  0.3693\n",
      "     97        0.5191       0.7230        0.8309  0.2875\n",
      "     98        \u001b[36m0.5165\u001b[0m       0.7240        0.9037  0.2796\n",
      "     99        0.5170       0.7180        0.8333  0.2829\n",
      "    100        \u001b[36m0.5128\u001b[0m       0.7200        0.8494  0.2727\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7732\u001b[0m       \u001b[32m0.6670\u001b[0m        \u001b[35m0.7602\u001b[0m  0.6210\n",
      "      2        \u001b[36m0.6670\u001b[0m       \u001b[32m0.7390\u001b[0m        \u001b[35m0.6548\u001b[0m  0.5267\n",
      "      3        \u001b[36m0.6364\u001b[0m       \u001b[32m0.7520\u001b[0m        \u001b[35m0.6287\u001b[0m  0.3993\n",
      "      4        \u001b[36m0.6254\u001b[0m       0.7510        \u001b[35m0.6195\u001b[0m  0.3174\n",
      "      5        \u001b[36m0.6196\u001b[0m       0.7470        \u001b[35m0.6188\u001b[0m  0.2806\n",
      "      6        \u001b[36m0.6155\u001b[0m       0.7400        0.6341  0.2754\n",
      "      7        \u001b[36m0.6145\u001b[0m       0.7360        0.6345  0.2949\n",
      "      8        \u001b[36m0.6097\u001b[0m       0.7390        0.6273  0.2912\n",
      "      9        \u001b[36m0.6069\u001b[0m       0.7420        0.6332  0.3455\n",
      "     10        \u001b[36m0.6062\u001b[0m       0.7490        0.6236  0.3893\n",
      "     11        \u001b[36m0.6039\u001b[0m       0.7510        \u001b[35m0.6167\u001b[0m  0.2919\n",
      "     12        \u001b[36m0.6036\u001b[0m       \u001b[32m0.7560\u001b[0m        \u001b[35m0.6128\u001b[0m  0.3441\n",
      "     13        \u001b[36m0.6008\u001b[0m       0.7480        0.6194  0.3712\n",
      "     14        \u001b[36m0.5972\u001b[0m       0.7520        0.6192  0.3057\n",
      "     15        0.5989       0.7490        0.6200  0.3646\n",
      "     16        0.5985       0.7540        0.6140  0.3360\n",
      "     17        \u001b[36m0.5972\u001b[0m       0.7500        0.6154  0.2710\n",
      "     18        \u001b[36m0.5928\u001b[0m       0.7490        0.6190  0.2745\n",
      "     19        \u001b[36m0.5927\u001b[0m       0.7420        0.6185  0.2586\n",
      "     20        \u001b[36m0.5915\u001b[0m       0.7490        0.6301  0.3092\n",
      "     21        0.5950       0.7450        0.6167  0.2825\n",
      "     22        0.5941       0.7450        0.6207  0.2677\n",
      "     23        0.5922       0.7440        0.6177  0.2721\n",
      "     24        \u001b[36m0.5879\u001b[0m       0.7480        \u001b[35m0.6108\u001b[0m  0.2804\n",
      "     25        \u001b[36m0.5870\u001b[0m       0.7510        0.6141  0.2865\n",
      "     26        \u001b[36m0.5845\u001b[0m       0.7560        \u001b[35m0.6086\u001b[0m  0.2910\n",
      "     27        0.5864       0.7420        0.6121  0.4290\n",
      "     28        0.5865       0.7500        \u001b[35m0.6016\u001b[0m  0.3180\n",
      "     29        \u001b[36m0.5828\u001b[0m       0.7480        0.6020  0.3250\n",
      "     30        \u001b[36m0.5814\u001b[0m       0.7460        \u001b[35m0.6001\u001b[0m  0.2854\n",
      "     31        0.5824       0.7490        \u001b[35m0.5919\u001b[0m  0.3637\n",
      "     32        \u001b[36m0.5763\u001b[0m       0.7530        0.5944  0.3018\n",
      "     33        \u001b[36m0.5731\u001b[0m       0.7520        \u001b[35m0.5863\u001b[0m  0.3195\n",
      "     34        \u001b[36m0.5676\u001b[0m       0.7550        0.5892  0.3035\n",
      "     35        \u001b[36m0.5660\u001b[0m       0.7470        0.5944  0.2691\n",
      "     36        \u001b[36m0.5656\u001b[0m       0.7480        0.6021  0.2744\n",
      "     37        0.5661       0.7530        0.5901  0.2969\n",
      "     38        \u001b[36m0.5644\u001b[0m       0.7510        0.5911  0.3855\n",
      "     39        \u001b[36m0.5601\u001b[0m       0.7470        0.5922  0.5163\n",
      "     40        \u001b[36m0.5598\u001b[0m       0.7420        0.5985  0.4660\n",
      "     41        0.5614       0.7520        0.6044  0.2864\n",
      "     42        \u001b[36m0.5580\u001b[0m       0.7500        0.5988  0.2830\n",
      "     43        \u001b[36m0.5578\u001b[0m       0.7350        0.6144  0.2750\n",
      "     44        0.5649       0.7530        0.6052  0.2879\n",
      "     45        0.5617       \u001b[32m0.7640\u001b[0m        0.5958  0.2881\n",
      "     46        0.5604       0.7550        0.5982  0.2787\n",
      "     47        \u001b[36m0.5511\u001b[0m       0.7460        0.6156  0.4975\n",
      "     48        \u001b[36m0.5502\u001b[0m       0.7360        0.6204  0.5622\n",
      "     49        \u001b[36m0.5501\u001b[0m       0.7540        0.6144  0.2676\n",
      "     50        \u001b[36m0.5488\u001b[0m       0.7450        0.6124  0.2820\n",
      "     51        \u001b[36m0.5465\u001b[0m       0.7530        0.6200  0.2781\n",
      "     52        0.5478       0.7460        0.6193  0.2679\n",
      "     53        \u001b[36m0.5459\u001b[0m       0.7520        0.6220  0.2837\n",
      "     54        0.5466       0.7560        0.6208  0.2804\n",
      "     55        \u001b[36m0.5404\u001b[0m       0.7570        0.6189  0.4401\n",
      "     56        \u001b[36m0.5402\u001b[0m       0.7540        0.6157  0.5365\n",
      "     57        \u001b[36m0.5382\u001b[0m       0.7580        0.6145  0.5149\n",
      "     58        0.5418       0.7470        0.6203  0.5211\n",
      "     59        \u001b[36m0.5345\u001b[0m       0.7580        0.6190  0.5244\n",
      "     60        0.5351       0.7480        0.6227  0.5384\n",
      "     61        \u001b[36m0.5324\u001b[0m       0.7560        0.6197  0.5096\n",
      "     62        \u001b[36m0.5306\u001b[0m       0.7490        0.6286  0.4996\n",
      "     63        0.5330       0.7530        0.6284  0.5107\n",
      "     64        0.5328       0.7500        0.6131  0.4846\n",
      "     65        \u001b[36m0.5267\u001b[0m       0.7470        0.6275  0.2853\n",
      "     66        0.5277       0.7400        0.6350  0.2896\n",
      "     67        0.5271       0.7560        0.6352  0.2740\n",
      "     68        \u001b[36m0.5205\u001b[0m       0.7520        0.6366  0.2926\n",
      "     69        \u001b[36m0.5176\u001b[0m       0.7450        0.6499  0.3160\n",
      "     70        0.5209       0.7280        0.6525  0.3253\n",
      "     71        0.5263       0.7480        0.6312  0.4800\n",
      "     72        0.5219       0.7460        0.6387  0.2933\n",
      "     73        \u001b[36m0.5159\u001b[0m       0.7410        0.6541  0.2686\n",
      "     74        \u001b[36m0.5149\u001b[0m       0.7460        0.6568  0.3461\n",
      "     75        0.5173       0.7320        0.6581  0.2965\n",
      "     76        0.5156       0.7480        0.6411  0.3407\n",
      "     77        0.5154       0.7430        0.6590  0.4657\n",
      "     78        \u001b[36m0.5132\u001b[0m       0.7360        0.6828  0.2718\n",
      "     79        0.5142       0.7420        0.6615  0.2835\n",
      "     80        \u001b[36m0.5086\u001b[0m       0.7420        0.6652  0.2787\n",
      "     81        0.5093       0.7370        0.6587  0.2863\n",
      "     82        0.5105       0.7310        0.6555  0.2894\n",
      "     83        0.5098       0.7280        0.6690  0.3273\n",
      "     84        \u001b[36m0.5085\u001b[0m       0.7330        0.6819  0.5217\n",
      "     85        \u001b[36m0.5072\u001b[0m       0.7300        0.6771  0.5356\n",
      "     86        0.5136       0.7390        0.6707  0.5189\n",
      "     87        0.5091       0.7310        0.6999  0.4985\n",
      "     88        0.5078       0.7330        0.6780  0.4887\n",
      "     89        \u001b[36m0.5050\u001b[0m       0.7390        0.6992  0.5122\n",
      "     90        \u001b[36m0.5043\u001b[0m       0.7190        0.6994  0.3293\n",
      "     91        0.5052       0.7200        0.7248  0.2899\n",
      "     92        0.5106       0.7350        0.7050  0.2804\n",
      "     93        \u001b[36m0.5033\u001b[0m       0.7330        0.7153  0.3062\n",
      "     94        0.5171       0.7300        0.7060  0.3144\n",
      "     95        0.5115       0.7240        0.7184  0.4282\n",
      "     96        0.5050       0.7360        0.7061  0.3105\n",
      "     97        0.5047       0.7280        0.7171  0.3151\n",
      "     98        \u001b[36m0.5007\u001b[0m       0.7380        0.6909  0.2878\n",
      "     99        0.5078       0.7180        0.7119  0.2921\n",
      "    100        \u001b[36m0.4991\u001b[0m       0.7230        0.7266  0.2770\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8252\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.7309\u001b[0m  0.3630\n",
      "      2        \u001b[36m0.6839\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.6732\u001b[0m  0.3890\n",
      "      3        \u001b[36m0.6540\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m0.6603\u001b[0m  0.2905\n",
      "      4        \u001b[36m0.6369\u001b[0m       0.7120        0.6614  0.2885\n",
      "      5        \u001b[36m0.6291\u001b[0m       0.7070        \u001b[35m0.6575\u001b[0m  0.3347\n",
      "      6        \u001b[36m0.6230\u001b[0m       0.7100        \u001b[35m0.6568\u001b[0m  0.3348\n",
      "      7        \u001b[36m0.6156\u001b[0m       \u001b[32m0.7170\u001b[0m        \u001b[35m0.6547\u001b[0m  0.4250\n",
      "      8        \u001b[36m0.6106\u001b[0m       0.7170        \u001b[35m0.6542\u001b[0m  0.3538\n",
      "      9        \u001b[36m0.6063\u001b[0m       \u001b[32m0.7230\u001b[0m        0.6579  0.3266\n",
      "     10        \u001b[36m0.6031\u001b[0m       0.7190        \u001b[35m0.6459\u001b[0m  0.2565\n",
      "     11        \u001b[36m0.5978\u001b[0m       0.7230        \u001b[35m0.6457\u001b[0m  0.2689\n",
      "     12        \u001b[36m0.5947\u001b[0m       0.7210        \u001b[35m0.6446\u001b[0m  0.2658\n",
      "     13        \u001b[36m0.5926\u001b[0m       0.7190        0.6524  0.2726\n",
      "     14        \u001b[36m0.5896\u001b[0m       \u001b[32m0.7240\u001b[0m        0.6467  0.4091\n",
      "     15        \u001b[36m0.5879\u001b[0m       0.7220        0.6448  0.3173\n",
      "     16        \u001b[36m0.5861\u001b[0m       0.7200        0.6464  0.2973\n",
      "     17        \u001b[36m0.5851\u001b[0m       \u001b[32m0.7260\u001b[0m        0.6534  0.3064\n",
      "     18        \u001b[36m0.5830\u001b[0m       0.7160        0.6500  0.2983\n",
      "     19        \u001b[36m0.5823\u001b[0m       \u001b[32m0.7270\u001b[0m        0.6464  0.2864\n",
      "     20        \u001b[36m0.5810\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.6355\u001b[0m  0.4868\n",
      "     21        \u001b[36m0.5804\u001b[0m       \u001b[32m0.7330\u001b[0m        0.6423  0.2722\n",
      "     22        \u001b[36m0.5789\u001b[0m       0.7300        0.6360  0.2715\n",
      "     23        \u001b[36m0.5738\u001b[0m       0.7320        0.6449  0.2770\n",
      "     24        \u001b[36m0.5732\u001b[0m       \u001b[32m0.7350\u001b[0m        0.6415  0.3119\n",
      "     25        \u001b[36m0.5706\u001b[0m       0.7240        0.6423  0.2608\n",
      "     26        0.5716       0.7290        0.6385  0.2593\n",
      "     27        \u001b[36m0.5685\u001b[0m       0.7280        \u001b[35m0.6329\u001b[0m  0.2490\n",
      "     28        \u001b[36m0.5674\u001b[0m       0.7230        0.6443  0.2575\n",
      "     29        \u001b[36m0.5667\u001b[0m       0.7270        0.6489  0.2864\n",
      "     30        \u001b[36m0.5627\u001b[0m       0.7140        0.6622  0.3070\n",
      "     31        \u001b[36m0.5622\u001b[0m       0.7240        0.6524  0.2563\n",
      "     32        \u001b[36m0.5612\u001b[0m       0.7200        0.6527  0.2683\n",
      "     33        0.5636       0.7230        0.6546  0.2562\n",
      "     34        \u001b[36m0.5586\u001b[0m       0.7170        0.6469  0.2534\n",
      "     35        \u001b[36m0.5569\u001b[0m       0.7320        0.6480  0.2581\n",
      "     36        0.5625       0.7200        0.6515  0.2635\n",
      "     37        0.5620       0.7140        0.6638  0.2718\n",
      "     38        0.5585       0.7170        0.6493  0.2503\n",
      "     39        \u001b[36m0.5551\u001b[0m       0.7220        0.6534  0.2752\n",
      "     40        \u001b[36m0.5543\u001b[0m       0.7010        0.6773  0.2638\n",
      "     41        \u001b[36m0.5538\u001b[0m       0.7130        0.6679  0.2706\n",
      "     42        \u001b[36m0.5521\u001b[0m       0.7000        0.6634  0.3459\n",
      "     43        0.5532       0.7150        0.6696  0.3430\n",
      "     44        \u001b[36m0.5495\u001b[0m       0.7200        0.6767  0.3085\n",
      "     45        \u001b[36m0.5469\u001b[0m       0.7100        0.6759  0.3190\n",
      "     46        0.5488       0.7110        0.6730  0.2901\n",
      "     47        \u001b[36m0.5446\u001b[0m       0.7110        0.6722  0.2908\n",
      "     48        0.5463       0.7020        0.6703  0.3179\n",
      "     49        \u001b[36m0.5441\u001b[0m       0.7080        0.6765  0.2911\n",
      "     50        \u001b[36m0.5409\u001b[0m       0.7080        0.6770  0.2683\n",
      "     51        0.5474       0.7010        0.6981  0.2785\n",
      "     52        \u001b[36m0.5389\u001b[0m       0.6990        0.6822  0.4028\n",
      "     53        0.5400       0.7020        0.6797  0.2743\n",
      "     54        0.5432       0.7140        0.6815  0.2736\n",
      "     55        \u001b[36m0.5360\u001b[0m       0.7110        0.6927  0.2768\n",
      "     56        0.5378       0.7090        0.6842  0.2861\n",
      "     57        \u001b[36m0.5350\u001b[0m       0.7040        0.6919  0.2814\n",
      "     58        \u001b[36m0.5305\u001b[0m       0.6980        0.6789  0.2921\n",
      "     59        0.5369       0.7270        0.6757  0.4654\n",
      "     60        0.5347       0.7200        0.6717  0.2721\n",
      "     61        \u001b[36m0.5294\u001b[0m       0.7190        0.6728  0.2759\n",
      "     62        0.5334       0.7260        0.6832  0.2818\n",
      "     63        0.5466       0.7110        0.6863  0.2758\n",
      "     64        0.5327       0.7120        0.6806  0.2865\n",
      "     65        0.5296       0.7240        0.6735  0.2609\n",
      "     66        \u001b[36m0.5253\u001b[0m       0.7240        0.6673  0.4637\n",
      "     67        0.5272       0.7130        0.6656  0.5061\n",
      "     68        0.5281       0.7180        0.6821  0.4300\n",
      "     69        0.5267       0.7260        0.7193  0.2795\n",
      "     70        0.5277       0.7180        0.6945  0.2828\n",
      "     71        0.5348       0.7190        0.6958  0.3059\n",
      "     72        0.5272       0.7130        0.7069  0.3966\n",
      "     73        0.5310       0.7240        0.7341  0.3583\n",
      "     74        0.5272       0.7280        0.7098  0.2989\n",
      "     75        0.5269       0.7140        0.7071  0.2762\n",
      "     76        \u001b[36m0.5216\u001b[0m       0.7220        0.6831  0.2663\n",
      "     77        0.5218       0.7180        0.6904  0.2812\n",
      "     78        \u001b[36m0.5203\u001b[0m       0.7220        0.7158  0.2547\n",
      "     79        \u001b[36m0.5179\u001b[0m       0.7150        0.7171  0.2659\n",
      "     80        0.5252       0.7240        0.7057  0.2520\n",
      "     81        0.5211       0.7200        0.7466  0.2716\n",
      "     82        0.5199       0.7200        0.7182  0.2713\n",
      "     83        0.5188       0.7160        0.7115  0.2830\n",
      "     84        0.5181       0.7210        0.7484  0.2621\n",
      "     85        0.5243       0.7150        0.7280  0.2594\n",
      "     86        \u001b[36m0.5169\u001b[0m       0.7210        0.7569  0.2795\n",
      "     87        0.5208       0.7210        0.8185  0.2985\n",
      "     88        0.5175       0.7270        0.7504  0.2756\n",
      "     89        0.5199       0.7200        0.7356  0.2840\n",
      "     90        0.5176       0.7240        0.7174  0.2929\n",
      "     91        \u001b[36m0.5153\u001b[0m       0.7310        0.7528  0.2968\n",
      "     92        \u001b[36m0.5114\u001b[0m       0.7110        0.7341  0.3091\n",
      "     93        0.5114       0.7290        0.7188  0.2785\n",
      "     94        0.5135       0.7240        0.7194  0.2910\n",
      "     95        \u001b[36m0.5074\u001b[0m       0.7330        0.7237  0.3285\n",
      "     96        0.5088       0.7260        0.7106  0.3356\n",
      "     97        0.5153       0.7280        0.7777  0.2725\n",
      "     98        \u001b[36m0.5058\u001b[0m       0.7260        0.7488  0.2611\n",
      "     99        \u001b[36m0.5042\u001b[0m       0.7240        0.7780  0.2584\n",
      "    100        0.5094       0.7310        0.7673  0.2559\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7850\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.4678\u001b[0m  0.4390\n",
      "      2        \u001b[36m0.6844\u001b[0m       \u001b[32m0.5010\u001b[0m        \u001b[35m0.9254\u001b[0m  0.4822\n",
      "      3        \u001b[36m0.6489\u001b[0m       \u001b[32m0.5140\u001b[0m        0.9825  0.2668\n",
      "      4        \u001b[36m0.6378\u001b[0m       \u001b[32m0.5800\u001b[0m        \u001b[35m0.8417\u001b[0m  0.2883\n",
      "      5        \u001b[36m0.6280\u001b[0m       \u001b[32m0.6050\u001b[0m        \u001b[35m0.8221\u001b[0m  0.2710\n",
      "      6        \u001b[36m0.6209\u001b[0m       \u001b[32m0.6080\u001b[0m        \u001b[35m0.8212\u001b[0m  0.2484\n",
      "      7        \u001b[36m0.6164\u001b[0m       0.6070        \u001b[35m0.8092\u001b[0m  0.2797\n",
      "      8        \u001b[36m0.6127\u001b[0m       \u001b[32m0.6260\u001b[0m        \u001b[35m0.7873\u001b[0m  0.2988\n",
      "      9        \u001b[36m0.6089\u001b[0m       \u001b[32m0.6280\u001b[0m        \u001b[35m0.7842\u001b[0m  0.3717\n",
      "     10        \u001b[36m0.6068\u001b[0m       \u001b[32m0.6520\u001b[0m        \u001b[35m0.7541\u001b[0m  0.2684\n",
      "     11        \u001b[36m0.6063\u001b[0m       \u001b[32m0.6600\u001b[0m        \u001b[35m0.7497\u001b[0m  0.2726\n",
      "     12        \u001b[36m0.6039\u001b[0m       0.6530        0.7579  0.2743\n",
      "     13        \u001b[36m0.6023\u001b[0m       \u001b[32m0.6680\u001b[0m        \u001b[35m0.7434\u001b[0m  0.2783\n",
      "     14        \u001b[36m0.5980\u001b[0m       0.5540        0.9573  0.2889\n",
      "     15        0.6018       0.6520        0.7630  0.2527\n",
      "     16        \u001b[36m0.5958\u001b[0m       0.6440        0.7654  0.5784\n",
      "     17        0.5962       0.6310        0.7884  0.4223\n",
      "     18        \u001b[36m0.5950\u001b[0m       \u001b[32m0.6780\u001b[0m        0.7505  0.2711\n",
      "     19        \u001b[36m0.5905\u001b[0m       0.6600        0.7714  0.3415\n",
      "     20        \u001b[36m0.5901\u001b[0m       0.6780        0.7483  0.3124\n",
      "     21        \u001b[36m0.5888\u001b[0m       \u001b[32m0.6910\u001b[0m        0.7539  0.2546\n",
      "     22        \u001b[36m0.5884\u001b[0m       0.6790        0.7497  0.2569\n",
      "     23        \u001b[36m0.5860\u001b[0m       0.6800        0.7455  0.2977\n",
      "     24        \u001b[36m0.5836\u001b[0m       \u001b[32m0.7070\u001b[0m        \u001b[35m0.7270\u001b[0m  0.4064\n",
      "     25        0.5842       \u001b[32m0.7080\u001b[0m        \u001b[35m0.7218\u001b[0m  0.3403\n",
      "     26        \u001b[36m0.5825\u001b[0m       0.6850        0.7533  0.3602\n",
      "     27        0.5828       0.7040        0.7248  0.3453\n",
      "     28        \u001b[36m0.5785\u001b[0m       0.6870        0.7387  0.2700\n",
      "     29        \u001b[36m0.5770\u001b[0m       0.7000        0.7428  0.2675\n",
      "     30        \u001b[36m0.5752\u001b[0m       0.6760        0.7553  0.2909\n",
      "     31        \u001b[36m0.5749\u001b[0m       0.6920        0.7283  0.2731\n",
      "     32        \u001b[36m0.5717\u001b[0m       0.6890        0.7466  0.3751\n",
      "     33        \u001b[36m0.5688\u001b[0m       0.7010        0.7265  0.3168\n",
      "     34        0.5808       \u001b[32m0.7110\u001b[0m        \u001b[35m0.7119\u001b[0m  0.2725\n",
      "     35        \u001b[36m0.5678\u001b[0m       0.6970        0.7363  0.2558\n",
      "     36        \u001b[36m0.5657\u001b[0m       0.7030        0.7403  0.2555\n",
      "     37        \u001b[36m0.5631\u001b[0m       0.6950        0.7327  0.2621\n",
      "     38        0.5692       0.7040        0.7143  0.2619\n",
      "     39        \u001b[36m0.5610\u001b[0m       0.7020        0.7189  0.2589\n",
      "     40        0.5634       0.6900        0.7355  0.4509\n",
      "     41        0.5618       0.6990        \u001b[35m0.7099\u001b[0m  0.2741\n",
      "     42        0.5611       \u001b[32m0.7190\u001b[0m        \u001b[35m0.6863\u001b[0m  0.2608\n",
      "     43        0.5622       0.6970        0.7105  0.2777\n",
      "     44        \u001b[36m0.5584\u001b[0m       0.7060        0.7009  0.2663\n",
      "     45        \u001b[36m0.5562\u001b[0m       0.6900        0.7115  0.2635\n",
      "     46        \u001b[36m0.5534\u001b[0m       0.6860        0.7089  0.2725\n",
      "     47        0.5539       0.6880        0.7133  0.3836\n",
      "     48        0.5546       0.6940        0.7037  0.2663\n",
      "     49        \u001b[36m0.5534\u001b[0m       0.6890        0.7080  0.2757\n",
      "     50        \u001b[36m0.5511\u001b[0m       0.6970        0.7052  0.2755\n",
      "     51        0.5523       0.6960        0.7086  0.2608\n",
      "     52        0.5537       \u001b[32m0.7220\u001b[0m        \u001b[35m0.6774\u001b[0m  0.2692\n",
      "     53        \u001b[36m0.5500\u001b[0m       0.6990        0.7007  0.2621\n",
      "     54        \u001b[36m0.5498\u001b[0m       0.7020        0.6894  0.5567\n",
      "     55        0.5550       0.7040        0.7045  0.5919\n",
      "     56        0.5520       0.7030        0.7040  0.3201\n",
      "     57        \u001b[36m0.5494\u001b[0m       0.7020        0.6995  0.3095\n",
      "     58        0.5497       0.6960        0.7192  0.2634\n",
      "     59        0.5501       0.7100        0.6918  0.2656\n",
      "     60        0.5544       0.6920        0.7056  0.2704\n",
      "     61        0.5547       0.7190        0.6839  0.2615\n",
      "     62        0.5545       0.7200        0.6927  0.3031\n",
      "     63        \u001b[36m0.5453\u001b[0m       0.7040        0.7065  0.2799\n",
      "     64        0.5488       \u001b[32m0.7270\u001b[0m        0.6839  0.3015\n",
      "     65        0.5541       0.7060        0.6886  0.2660\n",
      "     66        \u001b[36m0.5427\u001b[0m       0.7150        0.6966  0.3064\n",
      "     67        0.5511       0.6800        0.7058  0.2713\n",
      "     68        0.5467       0.6980        0.7030  0.3957\n",
      "     69        0.5468       0.7170        \u001b[35m0.6744\u001b[0m  0.2872\n",
      "     70        \u001b[36m0.5418\u001b[0m       0.7180        0.7022  0.2796\n",
      "     71        \u001b[36m0.5391\u001b[0m       0.7130        0.6957  0.3483\n",
      "     72        0.5400       0.7120        0.6893  0.3081\n",
      "     73        0.5459       0.7210        0.6890  0.2654\n",
      "     74        0.5406       0.7060        0.6987  0.2697\n",
      "     75        0.5392       \u001b[32m0.7320\u001b[0m        0.6912  0.2681\n",
      "     76        \u001b[36m0.5386\u001b[0m       0.7200        0.6876  0.2587\n",
      "     77        0.5395       0.7290        0.6778  0.2845\n",
      "     78        \u001b[36m0.5344\u001b[0m       0.7210        0.6937  0.3546\n",
      "     79        0.5375       0.7220        0.6891  0.2884\n",
      "     80        0.5404       0.7170        0.6847  0.2847\n",
      "     81        0.5371       0.7200        0.6901  0.2774\n",
      "     82        \u001b[36m0.5335\u001b[0m       0.7120        0.6832  0.2729\n",
      "     83        0.5386       0.7250        0.6765  0.2680\n",
      "     84        0.5340       \u001b[32m0.7350\u001b[0m        \u001b[35m0.6711\u001b[0m  0.2675\n",
      "     85        \u001b[36m0.5334\u001b[0m       0.7240        0.6867  0.4553\n",
      "     86        0.5375       0.7290        0.6763  0.5092\n",
      "     87        \u001b[36m0.5291\u001b[0m       0.7240        0.6912  0.2707\n",
      "     88        0.5332       0.7240        0.6907  0.2766\n",
      "     89        \u001b[36m0.5237\u001b[0m       0.7200        0.6892  0.2535\n",
      "     90        0.5324       0.7120        0.6891  0.2534\n",
      "     91        0.5327       0.7210        0.6924  0.2594\n",
      "     92        0.5304       0.7250        0.6985  0.2788\n",
      "     93        0.5253       0.7160        0.7084  0.2801\n",
      "     94        0.5320       0.7240        0.6965  0.2766\n",
      "     95        0.5258       0.7260        0.6890  0.2860\n",
      "     96        0.5313       0.7280        0.6851  0.3445\n",
      "     97        0.5281       0.7290        0.6994  0.3300\n",
      "     98        0.5280       0.7170        0.7065  0.2560\n",
      "     99        0.5249       0.7240        0.6904  0.2741\n",
      "    100        0.5239       0.7170        0.6798  0.2980\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.0511\u001b[0m       \u001b[32m0.4890\u001b[0m        \u001b[35m1.0351\u001b[0m  0.2852\n",
      "      2        \u001b[36m1.0346\u001b[0m       0.4890        1.0357  0.3055\n",
      "      3        1.0347       0.4890        1.0359  0.2909\n",
      "      4        1.0347       0.4890        1.0360  0.2801\n",
      "      5        1.0348       0.4890        1.0360  0.2919\n",
      "      6        1.0348       0.4890        1.0361  0.2889\n",
      "      7        1.0348       0.4890        1.0361  0.3062\n",
      "      8        1.0348       0.4890        1.0361  0.4127\n",
      "      9        1.0348       0.4890        1.0361  0.2795\n",
      "     10        1.0348       0.4890        1.0361  0.3781\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8035\u001b[0m       \u001b[32m0.6850\u001b[0m        \u001b[35m0.7462\u001b[0m  0.4226\n",
      "      2        \u001b[36m0.7008\u001b[0m       0.6280        0.7925  0.3767\n",
      "      3        0.7036       0.6690        0.8685  0.3732\n",
      "      4        \u001b[36m0.6962\u001b[0m       0.6660        0.8917  0.2953\n",
      "      5        \u001b[36m0.6897\u001b[0m       \u001b[32m0.7200\u001b[0m        \u001b[35m0.7180\u001b[0m  0.2847\n",
      "      6        \u001b[36m0.6736\u001b[0m       \u001b[32m0.7220\u001b[0m        0.7404  0.2875\n",
      "      7        \u001b[36m0.6723\u001b[0m       0.6960        0.7465  0.2856\n",
      "      8        \u001b[36m0.6681\u001b[0m       \u001b[32m0.7300\u001b[0m        \u001b[35m0.7048\u001b[0m  0.2792\n",
      "      9        0.6776       0.7030        0.7664  0.3245\n",
      "     10        0.6723       \u001b[32m0.7330\u001b[0m        \u001b[35m0.6842\u001b[0m  0.5354\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.6201\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.2983\n",
      "      2       \u001b[36m10.6176\u001b[0m       0.3340       10.6176  0.2801\n",
      "      3       10.6176       0.3340       10.6176  0.2584\n",
      "      4       10.6176       0.3340       10.6176  0.2711\n",
      "      5       10.6176       0.3340       10.6176  0.2780\n",
      "      6       10.6176       0.3340       10.6176  0.3899\n",
      "      7       10.6176       0.3340       10.6176  0.2730\n",
      "      8       10.6176       0.3340       10.6176  0.2683\n",
      "      9       10.6176       0.3340       10.6176  0.3151\n",
      "     10       10.6176       0.3340       10.6176  0.3100\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m8.0635\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m8.1306\u001b[0m  0.2418\n",
      "      2        8.1426       0.4900        8.1306  0.2745\n",
      "      3        8.1426       0.4900        8.1306  0.2594\n",
      "      4        8.1426       0.4900        8.1306  0.2690\n",
      "      5        8.1426       0.4900        8.1306  0.2700\n",
      "      6        8.1426       0.4900        8.1306  0.3617\n",
      "      7        8.1426       0.4900        8.1306  0.5191\n",
      "      8        8.1426       0.4900        8.1306  0.5013\n",
      "      9        8.1426       0.4900        8.1306  0.3197\n",
      "     10        8.1426       0.4900        8.1306  0.2728\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8282\u001b[0m       \u001b[32m0.6910\u001b[0m        \u001b[35m0.7130\u001b[0m  0.2681\n",
      "      2        \u001b[36m0.7509\u001b[0m       \u001b[32m0.7020\u001b[0m        \u001b[35m0.7020\u001b[0m  0.2844\n",
      "      3        \u001b[36m0.7288\u001b[0m       0.6950        \u001b[35m0.6949\u001b[0m  0.3209\n",
      "      4        \u001b[36m0.7022\u001b[0m       0.6980        0.7200  0.3151\n",
      "      5        0.7153       0.6980        0.7160  0.2714\n",
      "      6        0.7087       0.7010        0.7210  0.2610\n",
      "      7        0.7118       0.7000        \u001b[35m0.6831\u001b[0m  0.2900\n",
      "      8        0.7325       0.7000        \u001b[35m0.6801\u001b[0m  0.2790\n",
      "      9        0.7252       0.7010        0.6929  0.2620\n",
      "     10        0.7230       0.6970        0.6955  0.2665\n",
      "     11        0.7206       \u001b[32m0.7070\u001b[0m        0.6897  0.2695\n",
      "     12        0.7139       0.7050        0.6821  0.2640\n",
      "     13        0.7099       0.6860        0.7116  0.2729\n",
      "     14        0.7209       0.7070        0.6818  0.2659\n",
      "     15        0.7211       0.7050        0.6917  0.2716\n",
      "     16        0.7217       \u001b[32m0.7090\u001b[0m        0.6849  0.2636\n",
      "     17        0.7311       0.7050        0.6908  0.2819\n",
      "     18        0.7211       \u001b[32m0.7110\u001b[0m        \u001b[35m0.6797\u001b[0m  0.2761\n",
      "     19        0.7146       0.7090        \u001b[35m0.6673\u001b[0m  0.2850\n",
      "     20        0.7161       \u001b[32m0.7140\u001b[0m        0.6815  0.2911\n",
      "     21        0.7194       0.7070        0.6871  0.2880\n",
      "     22        0.7242       0.7030        0.7027  0.2787\n",
      "     23        0.7203       0.7080        0.6930  0.5415\n",
      "     24        0.7106       0.7080        0.6854  0.2695\n",
      "     25        0.7067       0.7100        0.6882  0.2743\n",
      "     26        0.7149       0.7100        0.6844  0.2856\n",
      "     27        0.7140       0.7090        0.6823  0.2911\n",
      "     28        0.7148       0.7080        0.6935  0.2875\n",
      "     29        0.7095       0.7090        0.6920  0.3300\n",
      "     30        0.7151       0.7080        0.7039  0.2823\n",
      "     31        0.7040       0.7020        0.7001  0.2820\n",
      "     32        0.7224       0.7040        0.7126  0.2920\n",
      "     33        0.7107       0.7110        0.6957  0.3337\n",
      "     34        0.7179       \u001b[32m0.7150\u001b[0m        0.6775  0.2815\n",
      "     35        0.7174       0.7100        0.7150  0.2813\n",
      "     36        0.7143       0.7140        0.6952  0.3698\n",
      "     37        0.7083       0.7090        0.7255  0.3885\n",
      "     38        \u001b[36m0.6980\u001b[0m       0.7130        0.6984  0.3227\n",
      "     39        0.7085       0.7130        0.6832  0.3242\n",
      "     40        0.7168       0.7110        0.6865  0.2735\n",
      "     41        0.7150       0.7060        0.6737  0.2643\n",
      "     42        0.7050       0.7090        0.6890  0.2706\n",
      "     43        0.7047       0.7100        0.7010  0.2910\n",
      "     44        0.7035       0.7070        0.6922  0.3970\n",
      "     45        0.7068       0.6980        0.7413  0.3209\n",
      "     46        0.7175       0.7110        0.6938  0.3154\n",
      "     47        0.7190       0.7090        0.6912  0.2956\n",
      "     48        0.7247       \u001b[32m0.7160\u001b[0m        0.6853  0.3500\n",
      "     49        0.7274       0.7110        0.6983  0.3149\n",
      "     50        0.7071       0.7150        0.7060  0.3968\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8530\u001b[0m       \u001b[32m0.5570\u001b[0m        \u001b[35m0.9530\u001b[0m  0.2705\n",
      "      2        \u001b[36m0.7744\u001b[0m       \u001b[32m0.6010\u001b[0m        \u001b[35m0.8134\u001b[0m  0.2940\n",
      "      3        \u001b[36m0.7482\u001b[0m       0.5350        \u001b[35m0.8120\u001b[0m  0.2857\n",
      "      4        \u001b[36m0.7437\u001b[0m       0.5600        \u001b[35m0.7939\u001b[0m  0.3277\n",
      "      5        \u001b[36m0.7432\u001b[0m       0.5280        0.8258  0.2958\n",
      "      6        \u001b[36m0.7425\u001b[0m       \u001b[32m0.6100\u001b[0m        0.8117  0.2810\n",
      "      7        \u001b[36m0.7379\u001b[0m       0.5460        0.8145  0.3955\n",
      "      8        \u001b[36m0.7330\u001b[0m       0.6030        0.8145  0.2990\n",
      "      9        0.7344       \u001b[32m0.6110\u001b[0m        0.8164  0.3310\n",
      "     10        0.7411       0.5830        0.8299  0.3002\n",
      "     11        0.7346       0.6090        0.8096  0.2893\n",
      "     12        0.7394       0.5440        0.8225  0.3180\n",
      "     13        \u001b[36m0.7302\u001b[0m       0.5390        0.8322  0.2814\n",
      "     14        0.7306       0.5430        0.8268  0.2728\n",
      "     15        0.7359       \u001b[32m0.6270\u001b[0m        0.8012  0.2749\n",
      "     16        0.7311       0.6150        0.8099  0.3686\n",
      "     17        0.7324       0.5570        0.8038  0.2698\n",
      "     18        0.7329       0.5440        0.8391  0.2974\n",
      "     19        0.7347       0.5300        0.8570  0.3146\n",
      "     20        0.7324       0.5350        0.8486  0.3278\n",
      "     21        0.7343       0.5590        0.8060  0.3121\n",
      "     22        0.7354       0.5800        0.8507  0.3795\n",
      "     23        0.7357       0.5820        0.8543  0.2993\n",
      "     24        0.7372       0.5310        0.8357  0.3295\n",
      "     25        0.7373       0.5080        0.8661  0.2729\n",
      "     26        0.7377       0.5610        0.8245  0.3196\n",
      "     27        0.7318       0.5430        0.8281  0.3150\n",
      "     28        0.7379       0.5070        0.8729  0.3913\n",
      "     29        0.7418       0.4910        0.8911  0.2906\n",
      "     30        0.7388       0.5570        0.8108  0.2810\n",
      "     31        0.7390       0.5020        0.8810  0.2825\n",
      "     32        0.7416       0.5020        0.8855  0.3052\n",
      "     33        0.7422       0.5010        0.8815  0.3235\n",
      "     34        0.7416       0.4980        0.8884  0.4487\n",
      "     35        0.7364       0.5260        0.8446  0.2927\n",
      "     36        0.7307       0.5320        0.8572  0.2877\n",
      "     37        0.7375       0.5720        0.8627  0.3072\n",
      "     38        0.7341       0.5270        0.8615  0.3045\n",
      "     39        0.7327       0.5410        0.8471  0.2935\n",
      "     40        0.7343       0.5740        0.8601  0.2960\n",
      "     41        0.7391       0.5110        0.8676  0.2797\n",
      "     42        0.7313       0.5410        0.8444  0.3175\n",
      "     43        0.7325       0.5200        0.8532  0.2841\n",
      "     44        0.7363       0.5640        0.8653  0.3126\n",
      "     45        0.7360       0.5350        0.8418  0.4170\n",
      "     46        0.7316       0.5050        0.8712  0.4778\n",
      "     47        0.7381       0.5110        0.8590  0.2840\n",
      "     48        0.7346       0.5250        0.8438  0.2695\n",
      "     49        0.7356       0.5230        0.8461  0.2770\n",
      "     50        0.7321       0.5170        0.8554  0.2828\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.6188\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.2702\n",
      "      2       \u001b[36m10.6176\u001b[0m       0.3340       10.6176  0.3060\n",
      "      3       10.6176       0.3340       10.6176  0.2698\n",
      "      4       10.6176       0.3340       10.6176  0.2655\n",
      "      5       10.6176       0.3340       10.6176  0.2736\n",
      "      6       10.6176       0.3340       10.6176  0.2734\n",
      "      7       10.6176       0.3340       10.6176  0.3357\n",
      "      8       10.6176       0.3340       10.6176  0.3119\n",
      "      9       10.6176       0.3340       10.6176  0.3010\n",
      "     10       10.6176       0.3340       10.6176  0.2820\n",
      "     11       10.6176       0.3340       10.6176  0.2546\n",
      "     12       10.6176       0.3340       10.6176  0.2593\n",
      "     13       10.6176       0.3340       10.6176  0.2866\n",
      "     14       10.6176       0.3340       10.6176  0.3017\n",
      "     15       10.6176       0.3340       10.6176  0.5006\n",
      "     16       10.6176       0.3340       10.6176  0.3910\n",
      "     17       10.6176       0.3340       10.6176  0.2779\n",
      "     18       10.6176       0.3340       10.6176  0.2938\n",
      "     19       10.6176       0.3340       10.6176  0.2803\n",
      "     20       10.6176       0.3340       10.6176  0.3431\n",
      "     21       10.6176       0.3340       10.6176  0.3000\n",
      "     22       10.6176       0.3340       10.6176  0.2670\n",
      "     23       10.6176       0.3340       10.6176  0.2638\n",
      "     24       10.6176       0.3340       10.6176  0.2662\n",
      "     25       10.6176       0.3340       10.6176  0.3024\n",
      "     26       10.6176       0.3340       10.6176  0.3165\n",
      "     27       10.6176       0.3340       10.6176  0.3181\n",
      "     28       10.6176       0.3340       10.6176  0.3220\n",
      "     29       10.6176       0.3340       10.6176  0.3104\n",
      "     30       10.6176       0.3340       10.6176  0.3312\n",
      "     31       10.6176       0.3340       10.6176  0.2925\n",
      "     32       10.6176       0.3340       10.6176  0.2887\n",
      "     33       10.6176       0.3340       10.6176  0.3495\n",
      "     34       10.6176       0.3340       10.6176  0.3428\n",
      "     35       10.6176       0.3340       10.6176  0.2731\n",
      "     36       10.6176       0.3340       10.6176  0.2734\n",
      "     37       10.6176       0.3340       10.6176  0.2719\n",
      "     38       10.6176       0.3340       10.6176  0.2711\n",
      "     39       10.6176       0.3340       10.6176  0.2786\n",
      "     40       10.6176       0.3340       10.6176  0.2877\n",
      "     41       10.6176       0.3340       10.6176  0.2943\n",
      "     42       10.6176       0.3340       10.6176  0.3479\n",
      "     43       10.6176       0.3340       10.6176  0.2763\n",
      "     44       10.6176       0.3340       10.6176  0.2786\n",
      "     45       10.6176       0.3340       10.6176  0.2694\n",
      "     46       10.6176       0.3340       10.6176  0.2945\n",
      "     47       10.6176       0.3340       10.6176  0.2628\n",
      "     48       10.6176       0.3340       10.6176  0.3639\n",
      "     49       10.6176       0.3340       10.6176  0.3905\n",
      "     50       10.6176       0.3340       10.6176  0.2683\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5662\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.2527\n",
      "      2       10.6176       0.3340       10.6176  0.2652\n",
      "      3       10.6176       0.3340       10.6176  0.2621\n",
      "      4       10.6176       0.3340       10.6176  0.2648\n",
      "      5       10.6176       0.3340       10.6176  0.3661\n",
      "      6       10.6176       0.3340       10.6176  0.2694\n",
      "      7       10.6176       0.3340       10.6176  0.2580\n",
      "      8       10.6176       0.3340       10.6176  0.2575\n",
      "      9       10.6176       0.3340       10.6176  0.2689\n",
      "     10       10.6176       0.3340       10.6176  0.2686\n",
      "     11       10.6176       0.3340       10.6176  0.2574\n",
      "     12       10.6176       0.3340       10.6176  0.6102\n",
      "     13       10.6176       0.3340       10.6176  0.4494\n",
      "     14       10.6176       0.3340       10.6176  0.3765\n",
      "     15       10.6176       0.3340       10.6176  0.3035\n",
      "     16       10.6176       0.3340       10.6176  0.3079\n",
      "     17       10.6176       0.3340       10.6176  0.3278\n",
      "     18       10.6176       0.3340       10.6176  0.3240\n",
      "     19       10.6176       0.3340       10.6176  0.2998\n",
      "     20       10.6176       0.3340       10.6176  0.3130\n",
      "     21       10.6176       0.3340       10.6176  0.3135\n",
      "     22       10.6176       0.3340       10.6176  0.2953\n",
      "     23       10.6176       0.3340       10.6176  0.2613\n",
      "     24       10.6176       0.3340       10.6176  0.2673\n",
      "     25       10.6176       0.3340       10.6176  0.2672\n",
      "     26       10.6176       0.3340       10.6176  0.2713\n",
      "     27       10.6176       0.3340       10.6176  0.2630\n",
      "     28       10.6176       0.3340       10.6176  0.3803\n",
      "     29       10.6176       0.3340       10.6176  0.2886\n",
      "     30       10.6176       0.3340       10.6176  0.2636\n",
      "     31       10.6176       0.3340       10.6176  0.3183\n",
      "     32       10.6176       0.3340       10.6176  0.3051\n",
      "     33       10.6176       0.3340       10.6176  0.3161\n",
      "     34       10.6176       0.3340       10.6176  0.2976\n",
      "     35       10.6176       0.3340       10.6176  0.2844\n",
      "     36       10.6176       0.3340       10.6176  0.2635\n",
      "     37       10.6176       0.3340       10.6176  0.2577\n",
      "     38       10.6176       0.3340       10.6176  0.3762\n",
      "     39       10.6176       0.3340       10.6176  0.2732\n",
      "     40       10.6176       0.3340       10.6176  0.2779\n",
      "     41       10.6176       0.3340       10.6176  0.3249\n",
      "     42       10.6176       0.3340       10.6176  0.2820\n",
      "     43       10.6176       0.3340       10.6176  0.3119\n",
      "     44       10.6176       0.3340       10.6176  0.3120\n",
      "     45       10.6176       0.3340       10.6176  0.3235\n",
      "     46       10.6176       0.3340       10.6176  0.3394\n",
      "     47       10.6176       0.3340       10.6176  0.2907\n",
      "     48       10.6176       0.3340       10.6176  0.2879\n",
      "     49       10.6176       0.3340       10.6176  0.2950\n",
      "     50       10.6176       0.3340       10.6176  0.3302\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7855\u001b[0m       \u001b[32m0.6980\u001b[0m        \u001b[35m0.6958\u001b[0m  0.3011\n",
      "      2        \u001b[36m0.7389\u001b[0m       0.6920        0.7082  0.2821\n",
      "      3        \u001b[36m0.7328\u001b[0m       0.6920        0.7347  0.2770\n",
      "      4        0.7394       0.6900        0.7415  0.3182\n",
      "      5        0.7357       0.6900        0.7462  0.2824\n",
      "      6        \u001b[36m0.7275\u001b[0m       0.6900        0.7474  0.3922\n",
      "      7        0.7351       0.6830        0.7595  0.2894\n",
      "      8        \u001b[36m0.7204\u001b[0m       0.6830        0.7313  0.2779\n",
      "      9        0.7462       0.6910        0.7404  0.2745\n",
      "     10        0.7498       \u001b[32m0.6990\u001b[0m        0.7386  0.3195\n",
      "     11        0.7312       0.6480        0.7555  0.2889\n",
      "     12        0.7354       0.6790        0.7454  0.3010\n",
      "     13        0.7403       0.6840        0.7522  0.4416\n",
      "     14        0.7212       \u001b[32m0.7000\u001b[0m        0.7351  0.3055\n",
      "     15        0.7226       \u001b[32m0.7080\u001b[0m        0.7173  0.2823\n",
      "     16        0.7379       0.6920        0.7390  0.2925\n",
      "     17        0.7337       0.6720        0.7655  0.2804\n",
      "     18        0.7535       \u001b[32m0.7120\u001b[0m        0.7177  0.2954\n",
      "     19        0.7293       0.7020        0.7481  0.2848\n",
      "     20        0.7295       0.6440        0.7451  0.3464\n",
      "     21        0.7473       0.7090        0.7123  0.2982\n",
      "     22        0.7265       0.6960        0.7376  0.4035\n",
      "     23        0.7262       0.6940        0.7505  0.3485\n",
      "     24        0.7267       0.6960        0.7512  0.3402\n",
      "     25        0.7283       0.6730        0.7819  0.3230\n",
      "     26        0.7374       0.7080        0.7476  0.3461\n",
      "     27        0.7331       0.7120        0.7319  0.3212\n",
      "     28        \u001b[36m0.7203\u001b[0m       0.6930        0.7336  0.3752\n",
      "     29        0.7512       0.7080        0.7327  0.2992\n",
      "     30        0.7378       0.7110        0.7297  0.3186\n",
      "     31        0.7300       0.7070        0.7374  0.2936\n",
      "     32        0.7864       0.6250        0.7941  0.3146\n",
      "     33        0.7514       0.7050        0.7420  0.3156\n",
      "     34        0.7291       0.7030        0.7425  0.3362\n",
      "     35        0.7399       0.7070        0.7431  0.3496\n",
      "     36        0.7313       0.7090        0.7298  0.2926\n",
      "     37        0.7284       0.6490        0.7549  0.2856\n",
      "     38        0.7287       0.7020        0.7339  0.2836\n",
      "     39        \u001b[36m0.7178\u001b[0m       0.7060        0.7326  0.3016\n",
      "     40        0.7191       0.7020        0.7389  0.2976\n",
      "     41        0.7327       0.7080        0.7291  0.2906\n",
      "     42        0.7342       0.7110        0.7319  0.2866\n",
      "     43        0.7390       0.7070        0.7463  0.4172\n",
      "     44        0.7299       0.7070        0.7464  0.2985\n",
      "     45        0.7314       0.6510        0.7384  0.3400\n",
      "     46        0.7347       0.7040        0.7582  0.2780\n",
      "     47        0.7260       0.7070        0.7334  0.2780\n",
      "     48        0.7241       0.7050        0.7357  0.2860\n",
      "     49        0.7234       0.7040        0.7532  0.2740\n",
      "     50        0.7253       0.6510        0.7286  0.2900\n",
      "     51        0.7290       0.7120        0.7310  0.2860\n",
      "     52        0.7336       0.7050        0.7305  0.3720\n",
      "     53        0.7228       0.7090        0.7178  0.2970\n",
      "     54        0.7285       0.7060        0.7443  0.2960\n",
      "     55        0.7288       0.7090        0.7308  0.2850\n",
      "     56        0.7380       0.7070        0.7529  0.2840\n",
      "     57        0.7400       \u001b[32m0.7130\u001b[0m        0.7186  0.2950\n",
      "     58        0.7252       0.6910        0.7471  0.3950\n",
      "     59        0.7433       0.7110        0.7069  0.4401\n",
      "     60        0.7292       0.7050        0.7382  0.2790\n",
      "     61        0.7297       0.7020        0.7225  0.2710\n",
      "     62        0.7334       0.7130        0.7086  0.2850\n",
      "     63        0.7228       \u001b[32m0.7140\u001b[0m        0.7055  0.2830\n",
      "     64        0.7271       0.7100        0.7111  0.2860\n",
      "     65        0.7274       0.7110        0.6991  0.2870\n",
      "     66        0.7274       0.7070        \u001b[35m0.6922\u001b[0m  0.4690\n",
      "     67        0.7263       0.7070        \u001b[35m0.6898\u001b[0m  0.2750\n",
      "     68        0.7202       0.7060        0.6995  0.2700\n",
      "     69        0.7251       0.7050        0.6967  0.2820\n",
      "     70        0.7229       0.7050        \u001b[35m0.6882\u001b[0m  0.2880\n",
      "     71        0.7226       0.7080        \u001b[35m0.6877\u001b[0m  0.2950\n",
      "     72        0.7273       0.7050        \u001b[35m0.6836\u001b[0m  0.2750\n",
      "     73        \u001b[36m0.7176\u001b[0m       0.7010        0.6922  0.5370\n",
      "     74        0.7270       0.7100        0.6861  0.2660\n",
      "     75        0.7270       0.7040        0.6852  0.2990\n",
      "     76        0.7195       0.7070        0.6925  0.2720\n",
      "     77        0.7253       0.7040        0.6900  0.2680\n",
      "     78        0.7244       0.7030        0.7062  0.2790\n",
      "     79        0.7323       0.7070        0.6877  0.2970\n",
      "     80        0.7234       0.7060        0.6993  0.3060\n",
      "     81        0.7207       0.7040        0.6852  0.2940\n",
      "     82        0.7253       0.7010        0.7190  0.3050\n",
      "     83        0.7288       0.7080        0.6957  0.2860\n",
      "     84        0.7179       0.6990        0.6966  0.3090\n",
      "     85        0.7225       0.7020        0.6904  0.2960\n",
      "     86        \u001b[36m0.7146\u001b[0m       0.7060        0.6851  0.2900\n",
      "     87        0.7222       0.7000        0.7094  0.2890\n",
      "     88        0.7169       0.7080        0.7053  0.3690\n",
      "     89        \u001b[36m0.7106\u001b[0m       0.7090        0.6931  0.4100\n",
      "     90        0.7184       0.7070        0.6989  0.2940\n",
      "     91        0.7140       0.7070        0.7152  0.2810\n",
      "     92        \u001b[36m0.7066\u001b[0m       0.7110        0.6845  0.2920\n",
      "     93        0.7184       0.7110        0.6842  0.2920\n",
      "     94        0.7179       0.7090        0.7111  0.2740\n",
      "     95        \u001b[36m0.7044\u001b[0m       0.7100        0.6914  0.3950\n",
      "     96        0.7114       0.7100        0.7004  0.5521\n",
      "     97        0.7096       0.7120        0.6933  0.4020\n",
      "     98        \u001b[36m0.7025\u001b[0m       0.7090        0.6861  0.2750\n",
      "     99        0.7051       0.7100        0.6924  0.2750\n",
      "    100        0.7049       0.7140        0.6837  0.2790\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8028\u001b[0m       \u001b[32m0.5110\u001b[0m        \u001b[35m0.9298\u001b[0m  0.2740\n",
      "      2        \u001b[36m0.7489\u001b[0m       0.4900        \u001b[35m0.8388\u001b[0m  0.2890\n",
      "      3        \u001b[36m0.7170\u001b[0m       \u001b[32m0.6230\u001b[0m        \u001b[35m0.7821\u001b[0m  0.3850\n",
      "      4        \u001b[36m0.7030\u001b[0m       0.5200        0.7857  0.3660\n",
      "      5        \u001b[36m0.6991\u001b[0m       \u001b[32m0.6540\u001b[0m        \u001b[35m0.7558\u001b[0m  0.2970\n",
      "      6        \u001b[36m0.6914\u001b[0m       0.5050        0.7964  0.3410\n",
      "      7        \u001b[36m0.6902\u001b[0m       \u001b[32m0.6590\u001b[0m        \u001b[35m0.7182\u001b[0m  0.3670\n",
      "      8        \u001b[36m0.6847\u001b[0m       0.6560        0.7198  0.4186\n",
      "      9        \u001b[36m0.6765\u001b[0m       0.6560        0.7262  0.3921\n",
      "     10        \u001b[36m0.6751\u001b[0m       0.6380        0.7736  0.4445\n",
      "     11        0.6779       0.6550        0.7337  0.4507\n",
      "     12        0.6830       0.6570        0.7402  0.3960\n",
      "     13        0.6881       0.6530        0.7228  0.2813\n",
      "     14        0.6787       0.6570        0.7339  0.2877\n",
      "     15        \u001b[36m0.6741\u001b[0m       0.6570        0.7426  0.2909\n",
      "     16        \u001b[36m0.6740\u001b[0m       0.6560        0.7395  0.2848\n",
      "     17        0.6763       0.6530        0.7670  0.2965\n",
      "     18        \u001b[36m0.6725\u001b[0m       0.6560        0.7495  0.2717\n",
      "     19        \u001b[36m0.6722\u001b[0m       0.6540        0.7429  0.3211\n",
      "     20        0.6743       0.6530        0.7609  0.3308\n",
      "     21        \u001b[36m0.6716\u001b[0m       0.6540        0.7500  0.3154\n",
      "     22        \u001b[36m0.6712\u001b[0m       0.6550        0.7405  0.3173\n",
      "     23        0.6811       0.6560        0.7627  0.3311\n",
      "     24        0.6758       0.6540        0.7573  0.3303\n",
      "     25        0.6715       0.6550        0.7353  0.3300\n",
      "     26        0.6775       0.6540        0.7505  0.3380\n",
      "     27        0.6803       0.6580        0.7749  0.3004\n",
      "     28        0.6814       0.6540        0.7415  0.3009\n",
      "     29        \u001b[36m0.6700\u001b[0m       0.6570        0.7498  0.3312\n",
      "     30        0.6708       0.6540        0.7552  0.3768\n",
      "     31        0.6721       0.6440        0.7848  0.3293\n",
      "     32        0.6855       0.6570        0.7549  0.2986\n",
      "     33        \u001b[36m0.6699\u001b[0m       0.6510        0.7583  0.3693\n",
      "     34        0.6967       0.6520        0.7450  0.2934\n",
      "     35        0.6725       0.6490        0.7502  0.3600\n",
      "     36        0.6722       0.6550        0.7416  0.2710\n",
      "     37        0.6707       0.6540        0.7452  0.2843\n",
      "     38        0.7005       0.6530        0.7645  0.2703\n",
      "     39        0.6742       0.6530        0.7960  0.2708\n",
      "     40        0.6782       0.6570        0.7856  0.2781\n",
      "     41        0.6795       0.6550        0.7836  0.2893\n",
      "     42        0.6776       0.6530        0.7707  0.3048\n",
      "     43        0.6741       0.6540        0.7671  0.2913\n",
      "     44        0.6744       0.6490        0.7772  0.2996\n",
      "     45        0.6754       0.6530        0.7485  0.3000\n",
      "     46        0.6724       0.6520        0.7756  0.3125\n",
      "     47        0.6723       0.6400        0.7594  0.3178\n",
      "     48        0.6727       0.6580        0.7525  0.2971\n",
      "     49        0.8080       0.6350        0.8945  0.3310\n",
      "     50        0.6949       0.6480        0.7296  0.3376\n",
      "     51        0.6754       0.6570        0.7559  0.2985\n",
      "     52        0.6769       0.6550        0.7529  0.3207\n",
      "     53        0.6769       0.6530        0.7469  0.2919\n",
      "     54        0.6737       0.6550        0.7733  0.2893\n",
      "     55        0.6740       0.6540        0.7843  0.3045\n",
      "     56        0.6752       0.6540        0.7858  0.3024\n",
      "     57        0.6737       0.6550        0.7756  0.2989\n",
      "     58        0.6732       0.6540        0.8184  0.3155\n",
      "     59        0.6758       0.6540        0.7788  0.2991\n",
      "     60        0.6715       0.6550        0.7435  0.2895\n",
      "     61        0.7045       0.6480        0.8053  0.2861\n",
      "     62        0.6847       0.6510        0.7541  0.3383\n",
      "     63        0.6720       0.6510        0.7546  0.3136\n",
      "     64        0.6739       0.6550        0.7405  0.3053\n",
      "     65        0.6700       0.6420        0.7682  0.2965\n",
      "     66        0.6796       0.6560        0.7823  0.2952\n",
      "     67        0.6793       0.6550        0.7755  0.3100\n",
      "     68        0.6760       0.6570        0.7725  0.3092\n",
      "     69        0.6715       0.6560        0.7645  0.3063\n",
      "     70        0.6780       0.6560        0.7742  0.2980\n",
      "     71        0.6770       0.6310        0.7898  0.3145\n",
      "     72        0.6876       0.6500        0.7515  0.3132\n",
      "     73        0.6711       0.6550        0.7582  0.2911\n",
      "     74        0.6713       0.6540        0.7608  0.2930\n",
      "     75        0.6716       0.6540        0.7646  0.3074\n",
      "     76        0.6709       0.6550        0.7556  0.3072\n",
      "     77        0.6726       0.6560        0.7507  0.3061\n",
      "     78        0.6819       0.6410        0.7717  0.4455\n",
      "     79        0.6789       0.6570        0.7658  0.3519\n",
      "     80        0.6744       0.6510        0.7525  0.3216\n",
      "     81        0.6713       0.6570        0.7563  0.3566\n",
      "     82        0.6717       0.6500        0.7547  0.3366\n",
      "     83        0.6703       0.6520        0.7675  0.3246\n",
      "     84        0.6725       0.6540        0.7760  0.3193\n",
      "     85        0.6762       0.6390        0.7993  0.3184\n",
      "     86        0.6773       0.6530        0.7818  0.3284\n",
      "     87        0.6742       0.6490        0.7836  0.3061\n",
      "     88        0.6987       0.6520        0.7460  0.3431\n",
      "     89        0.8494       0.6500        0.8636  0.3045\n",
      "     90        0.8464       \u001b[32m0.6710\u001b[0m        0.8241  0.3212\n",
      "     91        0.6917       0.6540        0.7614  0.3116\n",
      "     92        0.6830       0.6510        0.7634  0.3066\n",
      "     93        0.6797       0.6440        0.7956  0.3149\n",
      "     94        0.6795       0.6570        0.7713  0.3176\n",
      "     95        0.6883       0.6550        0.7652  0.3770\n",
      "     96        0.6722       0.6570        0.8093  0.3055\n",
      "     97        0.6826       0.6570        0.7774  0.3447\n",
      "     98        0.6805       0.6550        0.8208  0.3018\n",
      "     99        0.6936       0.6560        0.7723  0.3296\n",
      "    100        0.6843       0.6570        \u001b[35m0.7037\u001b[0m  0.3230\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.6176\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.3140\n",
      "      2       10.6176       0.3340       10.6176  0.3075\n",
      "      3       10.6176       0.3340       10.6176  0.3103\n",
      "      4       10.6176       0.3340       10.6176  0.3105\n",
      "      5       10.6176       0.3340       10.6176  0.3469\n",
      "      6       10.6176       0.3340       10.6176  0.3336\n",
      "      7       10.6176       0.3340       10.6176  0.3083\n",
      "      8       10.6176       0.3340       10.6176  0.3027\n",
      "      9       10.6176       0.3340       10.6176  0.3094\n",
      "     10       10.6176       0.3340       10.6176  0.3415\n",
      "     11       10.6176       0.3340       10.6176  0.3184\n",
      "     12       10.6176       0.3340       10.6176  0.3123\n",
      "     13       10.6176       0.3340       10.6176  0.2858\n",
      "     14       10.6176       0.3340       10.6176  0.2775\n",
      "     15       10.6176       0.3340       10.6176  0.2861\n",
      "     16       10.6176       0.3340       10.6176  0.2936\n",
      "     17       10.6176       0.3340       10.6176  0.2854\n",
      "     18       10.6176       0.3340       10.6176  0.3137\n",
      "     19       10.6176       0.3340       10.6176  0.2812\n",
      "     20       10.6176       0.3340       10.6176  0.3284\n",
      "     21       10.6176       0.3340       10.6176  0.3319\n",
      "     22       10.6176       0.3340       10.6176  0.2976\n",
      "     23       10.6176       0.3340       10.6176  0.2978\n",
      "     24       10.6176       0.3340       10.6176  0.3147\n",
      "     25       10.6176       0.3340       10.6176  0.2909\n",
      "     26       10.6176       0.3340       10.6176  0.3832\n",
      "     27       10.6176       0.3340       10.6176  0.3136\n",
      "     28       10.6176       0.3340       10.6176  0.3056\n",
      "     29       10.6176       0.3340       10.6176  0.2836\n",
      "     30       10.6176       0.3340       10.6176  0.2946\n",
      "     31       10.6176       0.3340       10.6176  0.2746\n",
      "     32       10.6176       0.3340       10.6176  0.3311\n",
      "     33       10.6176       0.3340       10.6176  0.3513\n",
      "     34       10.6176       0.3340       10.6176  0.3552\n",
      "     35       10.6176       0.3340       10.6176  0.3470\n",
      "     36       10.6176       0.3340       10.6176  0.2929\n",
      "     37       10.6176       0.3340       10.6176  0.2959\n",
      "     38       10.6176       0.3340       10.6176  0.3248\n",
      "     39       10.6176       0.3340       10.6176  0.2999\n",
      "     40       10.6176       0.3340       10.6176  0.3324\n",
      "     41       10.6176       0.3340       10.6176  0.3113\n",
      "     42       10.6176       0.3340       10.6176  0.3128\n",
      "     43       10.6176       0.3340       10.6176  0.3656\n",
      "     44       10.6176       0.3340       10.6176  0.2697\n",
      "     45       10.6176       0.3340       10.6176  0.2472\n",
      "     46       10.6176       0.3340       10.6176  0.2606\n",
      "     47       10.6176       0.3340       10.6176  0.2528\n",
      "     48       10.6176       0.3340       10.6176  0.2650\n",
      "     49       10.6176       0.3340       10.6176  0.2573\n",
      "     50       10.6176       0.3340       10.6176  0.2529\n",
      "     51       10.6176       0.3340       10.6176  0.2701\n",
      "     52       10.6176       0.3340       10.6176  0.2708\n",
      "     53       10.6176       0.3340       10.6176  0.2682\n",
      "     54       10.6176       0.3340       10.6176  0.3105\n",
      "     55       10.6176       0.3340       10.6176  0.2726\n",
      "     56       10.6176       0.3340       10.6176  0.3223\n",
      "     57       10.6176       0.3340       10.6176  0.3147\n",
      "     58       10.6176       0.3340       10.6176  0.3332\n",
      "     59       10.6176       0.3340       10.6176  0.3662\n",
      "     60       10.6176       0.3340       10.6176  0.3461\n",
      "     61       10.6176       0.3340       10.6176  0.4048\n",
      "     62       10.6176       0.3340       10.6176  0.2830\n",
      "     63       10.6176       0.3340       10.6176  0.2971\n",
      "     64       10.6176       0.3340       10.6176  0.2841\n",
      "     65       10.6176       0.3340       10.6176  0.2656\n",
      "     66       10.6176       0.3340       10.6176  0.2771\n",
      "     67       10.6176       0.3340       10.6176  0.2673\n",
      "     68       10.6176       0.3340       10.6176  0.2864\n",
      "     69       10.6176       0.3340       10.6176  0.3061\n",
      "     70       10.6176       0.3340       10.6176  0.3677\n",
      "     71       10.6176       0.3340       10.6176  0.3190\n",
      "     72       10.6176       0.3340       10.6176  0.3122\n",
      "     73       10.6176       0.3340       10.6176  0.2810\n",
      "     74       10.6176       0.3340       10.6176  0.3127\n",
      "     75       10.6176       0.3340       10.6176  0.2777\n",
      "     76       10.6176       0.3340       10.6176  0.3314\n",
      "     77       10.6176       0.3340       10.6176  0.3527\n",
      "     78       10.6176       0.3340       10.6176  0.3041\n",
      "     79       10.6176       0.3340       10.6176  0.2976\n",
      "     80       10.6176       0.3340       10.6176  0.3213\n",
      "     81       10.6176       0.3340       10.6176  0.3268\n",
      "     82       10.6176       0.3340       10.6176  0.3303\n",
      "     83       10.6176       0.3340       10.6176  0.2887\n",
      "     84       10.6176       0.3340       10.6176  0.3233\n",
      "     85       10.6176       0.3340       10.6176  0.2797\n",
      "     86       10.6176       0.3340       10.6176  0.2965\n",
      "     87       10.6176       0.3340       10.6176  0.3363\n",
      "     88       10.6176       0.3340       10.6176  0.3240\n",
      "     89       10.6176       0.3340       10.6176  0.3708\n",
      "     90       10.6176       0.3340       10.6176  0.3115\n",
      "     91       10.6176       0.3340       10.6176  0.2833\n",
      "     92       10.6176       0.3340       10.6176  0.2892\n",
      "     93       10.6176       0.3340       10.6176  0.2695\n",
      "     94       10.6176       0.3340       10.6176  0.2977\n",
      "     95       10.6176       0.3340       10.6176  0.2753\n",
      "     96       10.6176       0.3340       10.6176  0.2972\n",
      "     97       10.6176       0.3340       10.6176  0.3048\n",
      "     98       10.6176       0.3340       10.6176  0.2942\n",
      "     99       10.6176       0.3340       10.6176  0.3154\n",
      "    100       10.6176       0.3340       10.6176  0.3099\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5671\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.3095\n",
      "      2       10.6176       0.3340       10.6176  0.2822\n",
      "      3       10.6176       0.3340       10.6176  0.2641\n",
      "      4       10.6176       0.3340       10.6176  0.2865\n",
      "      5       10.6176       0.3340       10.6176  0.2982\n",
      "      6       10.6176       0.3340       10.6176  0.3054\n",
      "      7       10.6176       0.3340       10.6176  0.3019\n",
      "      8       10.6176       0.3340       10.6176  0.2816\n",
      "      9       10.6176       0.3340       10.6176  0.2784\n",
      "     10       10.6176       0.3340       10.6176  0.2947\n",
      "     11       10.6176       0.3340       10.6176  0.3111\n",
      "     12       10.6176       0.3340       10.6176  0.2882\n",
      "     13       10.6176       0.3340       10.6176  0.3974\n",
      "     14       10.6176       0.3340       10.6176  0.3087\n",
      "     15       10.6176       0.3340       10.6176  0.2852\n",
      "     16       10.6176       0.3340       10.6176  0.2786\n",
      "     17       10.6176       0.3340       10.6176  0.2777\n",
      "     18       10.6176       0.3340       10.6176  0.2698\n",
      "     19       10.6176       0.3340       10.6176  0.2758\n",
      "     20       10.6176       0.3340       10.6176  0.2777\n",
      "     21       10.6176       0.3340       10.6176  0.3080\n",
      "     22       10.6176       0.3340       10.6176  0.2810\n",
      "     23       10.6176       0.3340       10.6176  0.2746\n",
      "     24       10.6176       0.3340       10.6176  0.2944\n",
      "     25       10.6176       0.3340       10.6176  0.2874\n",
      "     26       10.6176       0.3340       10.6176  0.2836\n",
      "     27       10.6176       0.3340       10.6176  0.2944\n",
      "     28       10.6176       0.3340       10.6176  0.3348\n",
      "     29       10.6176       0.3340       10.6176  0.3470\n",
      "     30       10.6176       0.3340       10.6176  0.3473\n",
      "     31       10.6176       0.3340       10.6176  0.3432\n",
      "     32       10.6176       0.3340       10.6176  0.3415\n",
      "     33       10.6176       0.3340       10.6176  0.3602\n",
      "     34       10.6176       0.3340       10.6176  0.3327\n",
      "     35       10.6176       0.3340       10.6176  0.3007\n",
      "     36       10.6176       0.3340       10.6176  0.3379\n",
      "     37       10.6176       0.3340       10.6176  0.2586\n",
      "     38       10.6176       0.3340       10.6176  0.2604\n",
      "     39       10.6176       0.3340       10.6176  0.2472\n",
      "     40       10.6176       0.3340       10.6176  0.2621\n",
      "     41       10.6176       0.3340       10.6176  0.2526\n",
      "     42       10.6176       0.3340       10.6176  0.2578\n",
      "     43       10.6176       0.3340       10.6176  0.2693\n",
      "     44       10.6176       0.3340       10.6176  0.2858\n",
      "     45       10.6176       0.3340       10.6176  0.2795\n",
      "     46       10.6176       0.3340       10.6176  0.3581\n",
      "     47       10.6176       0.3340       10.6176  0.3074\n",
      "     48       10.6176       0.3340       10.6176  0.2960\n",
      "     49       10.6176       0.3340       10.6176  0.2938\n",
      "     50       10.6176       0.3340       10.6176  0.3384\n",
      "     51       10.6176       0.3340       10.6176  0.3241\n",
      "     52       10.6176       0.3340       10.6176  0.3204\n",
      "     53       10.6176       0.3340       10.6176  0.3461\n",
      "     54       10.6176       0.3340       10.6176  0.2988\n",
      "     55       10.6176       0.3340       10.6176  0.3277\n",
      "     56       10.6176       0.3340       10.6176  0.3549\n",
      "     57       10.6176       0.3340       10.6176  0.3583\n",
      "     58       10.6176       0.3340       10.6176  0.3392\n",
      "     59       10.6176       0.3340       10.6176  0.3073\n",
      "     60       10.6176       0.3340       10.6176  0.2995\n",
      "     61       10.6176       0.3340       10.6176  0.3120\n",
      "     62       10.6176       0.3340       10.6176  0.3173\n",
      "     63       10.6176       0.3340       10.6176  0.3157\n",
      "     64       10.6176       0.3340       10.6176  0.3085\n",
      "     65       10.6176       0.3340       10.6176  0.3374\n",
      "     66       10.6176       0.3340       10.6176  0.3068\n",
      "     67       10.6176       0.3340       10.6176  0.3198\n",
      "     68       10.6176       0.3340       10.6176  0.3582\n",
      "     69       10.6176       0.3340       10.6176  0.3068\n",
      "     70       10.6176       0.3340       10.6176  0.2725\n",
      "     71       10.6176       0.3340       10.6176  0.2931\n",
      "     72       10.6176       0.3340       10.6176  0.2855\n",
      "     73       10.6176       0.3340       10.6176  0.2816\n",
      "     74       10.6176       0.3340       10.6176  0.2814\n",
      "     75       10.6176       0.3340       10.6176  0.3663\n",
      "     76       10.6176       0.3340       10.6176  0.3561\n",
      "     77       10.6176       0.3340       10.6176  0.2560\n",
      "     78       10.6176       0.3340       10.6176  0.2759\n",
      "     79       10.6176       0.3340       10.6176  0.2853\n",
      "     80       10.6176       0.3340       10.6176  0.2743\n",
      "     81       10.6176       0.3340       10.6176  0.2682\n",
      "     82       10.6176       0.3340       10.6176  0.2657\n",
      "     83       10.6176       0.3340       10.6176  0.3396\n",
      "     84       10.6176       0.3340       10.6176  0.3418\n",
      "     85       10.6176       0.3340       10.6176  0.3345\n",
      "     86       10.6176       0.3340       10.6176  0.2820\n",
      "     87       10.6176       0.3340       10.6176  0.2670\n",
      "     88       10.6176       0.3340       10.6176  0.2647\n",
      "     89       10.6176       0.3340       10.6176  0.2615\n",
      "     90       10.6176       0.3340       10.6176  0.2810\n",
      "     91       10.6176       0.3340       10.6176  0.2648\n",
      "     92       10.6176       0.3340       10.6176  0.2732\n",
      "     93       10.6176       0.3340       10.6176  0.2849\n",
      "     94       10.6176       0.3340       10.6176  0.3027\n",
      "     95       10.6176       0.3340       10.6176  0.2956\n",
      "     96       10.6176       0.3340       10.6176  0.2967\n",
      "     97       10.6176       0.3340       10.6176  0.2853\n",
      "     98       10.6176       0.3340       10.6176  0.3141\n",
      "     99       10.6176       0.3340       10.6176  0.3477\n",
      "    100       10.6176       0.3340       10.6176  0.2951\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8741\u001b[0m       \u001b[32m0.6540\u001b[0m        \u001b[35m0.7593\u001b[0m  0.2067\n",
      "      2        \u001b[36m0.7211\u001b[0m       \u001b[32m0.6720\u001b[0m        \u001b[35m0.7053\u001b[0m  0.1981\n",
      "      3        \u001b[36m0.6782\u001b[0m       \u001b[32m0.6780\u001b[0m        \u001b[35m0.6845\u001b[0m  0.2279\n",
      "      4        \u001b[36m0.6556\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.6623\u001b[0m  0.2151\n",
      "      5        \u001b[36m0.6418\u001b[0m       \u001b[32m0.6980\u001b[0m        \u001b[35m0.6529\u001b[0m  0.2169\n",
      "      6        \u001b[36m0.6312\u001b[0m       0.6930        \u001b[35m0.6505\u001b[0m  0.1861\n",
      "      7        \u001b[36m0.6251\u001b[0m       0.6920        \u001b[35m0.6480\u001b[0m  0.1818\n",
      "      8        \u001b[36m0.6197\u001b[0m       0.6790        0.6591  0.1892\n",
      "      9        \u001b[36m0.6166\u001b[0m       0.6720        0.6601  0.1958\n",
      "     10        \u001b[36m0.6146\u001b[0m       0.6820        0.6532  0.1925\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7877\u001b[0m       \u001b[32m0.5450\u001b[0m        \u001b[35m0.8325\u001b[0m  0.1976\n",
      "      2        \u001b[36m0.7064\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.6796\u001b[0m  0.1888\n",
      "      3        \u001b[36m0.6580\u001b[0m       \u001b[32m0.7340\u001b[0m        \u001b[35m0.6568\u001b[0m  0.1907\n",
      "      4        \u001b[36m0.6430\u001b[0m       \u001b[32m0.7470\u001b[0m        \u001b[35m0.6383\u001b[0m  0.1853\n",
      "      5        \u001b[36m0.6290\u001b[0m       \u001b[32m0.7480\u001b[0m        \u001b[35m0.6313\u001b[0m  0.2145\n",
      "      6        \u001b[36m0.6215\u001b[0m       0.7380        0.6401  0.1878\n",
      "      7        \u001b[36m0.6188\u001b[0m       0.7450        \u001b[35m0.6259\u001b[0m  0.1948\n",
      "      8        \u001b[36m0.6125\u001b[0m       0.7440        \u001b[35m0.6241\u001b[0m  0.1857\n",
      "      9        \u001b[36m0.6096\u001b[0m       0.7400        0.6394  0.1838\n",
      "     10        0.6097       0.7470        0.6324  0.1925\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9428\u001b[0m       \u001b[32m0.6800\u001b[0m        \u001b[35m0.7319\u001b[0m  0.1878\n",
      "      2        \u001b[36m0.7124\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6881\u001b[0m  0.1819\n",
      "      3        \u001b[36m0.6728\u001b[0m       0.7100        \u001b[35m0.6631\u001b[0m  0.1802\n",
      "      4        \u001b[36m0.6494\u001b[0m       \u001b[32m0.7210\u001b[0m        \u001b[35m0.6575\u001b[0m  0.1887\n",
      "      5        \u001b[36m0.6365\u001b[0m       0.7190        \u001b[35m0.6505\u001b[0m  0.1793\n",
      "      6        \u001b[36m0.6283\u001b[0m       0.7170        \u001b[35m0.6455\u001b[0m  0.1802\n",
      "      7        \u001b[36m0.6252\u001b[0m       0.7180        \u001b[35m0.6430\u001b[0m  0.1809\n",
      "      8        \u001b[36m0.6213\u001b[0m       \u001b[32m0.7220\u001b[0m        \u001b[35m0.6417\u001b[0m  0.1838\n",
      "      9        \u001b[36m0.6165\u001b[0m       0.7200        \u001b[35m0.6376\u001b[0m  0.1800\n",
      "     10        \u001b[36m0.6119\u001b[0m       \u001b[32m0.7230\u001b[0m        0.6386  0.1769\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8359\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.1827\u001b[0m  0.2057\n",
      "      2        \u001b[36m0.7121\u001b[0m       \u001b[32m0.5220\u001b[0m        \u001b[35m0.9253\u001b[0m  0.1799\n",
      "      3        \u001b[36m0.6688\u001b[0m       \u001b[32m0.5440\u001b[0m        \u001b[35m0.8719\u001b[0m  0.1821\n",
      "      4        \u001b[36m0.6460\u001b[0m       \u001b[32m0.6160\u001b[0m        \u001b[35m0.7962\u001b[0m  0.1806\n",
      "      5        \u001b[36m0.6326\u001b[0m       \u001b[32m0.6500\u001b[0m        \u001b[35m0.7766\u001b[0m  0.1874\n",
      "      6        \u001b[36m0.6263\u001b[0m       0.6470        \u001b[35m0.7702\u001b[0m  0.1959\n",
      "      7        \u001b[36m0.6216\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.7439\u001b[0m  0.1783\n",
      "      8        \u001b[36m0.6176\u001b[0m       \u001b[32m0.6720\u001b[0m        \u001b[35m0.7411\u001b[0m  0.1904\n",
      "      9        \u001b[36m0.6157\u001b[0m       0.6640        0.7416  0.1910\n",
      "     10        \u001b[36m0.6130\u001b[0m       \u001b[32m0.6930\u001b[0m        \u001b[35m0.7225\u001b[0m  0.1804\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8270\u001b[0m       \u001b[32m0.6490\u001b[0m        \u001b[35m0.7409\u001b[0m  0.2169\n",
      "      2        \u001b[36m0.6985\u001b[0m       \u001b[32m0.6890\u001b[0m        \u001b[35m0.6962\u001b[0m  0.2034\n",
      "      3        \u001b[36m0.6616\u001b[0m       0.6830        \u001b[35m0.6948\u001b[0m  0.1971\n",
      "      4        \u001b[36m0.6477\u001b[0m       0.6820        0.6957  0.1931\n",
      "      5        \u001b[36m0.6380\u001b[0m       0.6850        \u001b[35m0.6826\u001b[0m  0.1983\n",
      "      6        \u001b[36m0.6289\u001b[0m       \u001b[32m0.7000\u001b[0m        \u001b[35m0.6721\u001b[0m  0.1960\n",
      "      7        \u001b[36m0.6239\u001b[0m       0.6970        0.6774  0.2123\n",
      "      8        \u001b[36m0.6198\u001b[0m       0.6940        0.6797  0.1904\n",
      "      9        \u001b[36m0.6144\u001b[0m       \u001b[32m0.7080\u001b[0m        0.6787  0.1983\n",
      "     10        \u001b[36m0.6109\u001b[0m       0.7020        0.6808  0.1925\n",
      "     11        \u001b[36m0.6079\u001b[0m       0.7020        0.6866  0.1985\n",
      "     12        \u001b[36m0.6044\u001b[0m       \u001b[32m0.7120\u001b[0m        0.6750  0.2128\n",
      "     13        \u001b[36m0.5998\u001b[0m       \u001b[32m0.7130\u001b[0m        \u001b[35m0.6698\u001b[0m  0.2032\n",
      "     14        \u001b[36m0.5964\u001b[0m       0.7130        0.6754  0.1866\n",
      "     15        \u001b[36m0.5948\u001b[0m       \u001b[32m0.7160\u001b[0m        0.6728  0.1978\n",
      "     16        \u001b[36m0.5934\u001b[0m       0.7110        \u001b[35m0.6693\u001b[0m  0.1920\n",
      "     17        \u001b[36m0.5898\u001b[0m       0.7030        \u001b[35m0.6619\u001b[0m  0.1999\n",
      "     18        \u001b[36m0.5876\u001b[0m       \u001b[32m0.7260\u001b[0m        \u001b[35m0.6572\u001b[0m  0.1984\n",
      "     19        \u001b[36m0.5851\u001b[0m       0.7060        0.6695  0.1971\n",
      "     20        \u001b[36m0.5807\u001b[0m       0.7180        0.6574  0.2067\n",
      "     21        \u001b[36m0.5784\u001b[0m       0.7140        \u001b[35m0.6528\u001b[0m  0.2180\n",
      "     22        \u001b[36m0.5774\u001b[0m       0.7150        0.6607  0.2160\n",
      "     23        \u001b[36m0.5728\u001b[0m       0.7150        0.6599  0.2195\n",
      "     24        \u001b[36m0.5709\u001b[0m       0.7100        0.6685  0.2086\n",
      "     25        \u001b[36m0.5688\u001b[0m       0.7120        0.6641  0.1865\n",
      "     26        \u001b[36m0.5651\u001b[0m       0.7180        0.6672  0.1810\n",
      "     27        0.5675       0.7250        \u001b[35m0.6517\u001b[0m  0.2097\n",
      "     28        \u001b[36m0.5616\u001b[0m       \u001b[32m0.7270\u001b[0m        0.6693  0.2024\n",
      "     29        0.5677       0.7270        0.6587  0.1919\n",
      "     30        \u001b[36m0.5600\u001b[0m       0.7250        \u001b[35m0.6486\u001b[0m  0.2217\n",
      "     31        \u001b[36m0.5567\u001b[0m       0.7260        0.6540  0.1897\n",
      "     32        \u001b[36m0.5555\u001b[0m       0.7250        0.6515  0.1960\n",
      "     33        \u001b[36m0.5522\u001b[0m       \u001b[32m0.7300\u001b[0m        0.6539  0.2063\n",
      "     34        0.5572       \u001b[32m0.7330\u001b[0m        0.6583  0.1902\n",
      "     35        0.5570       0.7240        0.6500  0.1871\n",
      "     36        0.5524       0.7310        \u001b[35m0.6455\u001b[0m  0.1947\n",
      "     37        0.5541       0.7270        0.6581  0.1908\n",
      "     38        0.5574       0.7200        0.6585  0.2169\n",
      "     39        0.5537       0.7140        0.6715  0.2048\n",
      "     40        \u001b[36m0.5514\u001b[0m       0.7140        0.6613  0.1966\n",
      "     41        \u001b[36m0.5455\u001b[0m       0.7110        0.6730  0.1965\n",
      "     42        0.5469       0.7160        0.6576  0.1991\n",
      "     43        \u001b[36m0.5438\u001b[0m       0.7190        0.6625  0.1978\n",
      "     44        \u001b[36m0.5414\u001b[0m       0.7190        0.6629  0.2108\n",
      "     45        \u001b[36m0.5407\u001b[0m       0.7220        0.6721  0.1935\n",
      "     46        0.5417       0.7240        0.6777  0.1864\n",
      "     47        0.5440       0.7180        0.6750  0.1951\n",
      "     48        \u001b[36m0.5396\u001b[0m       0.7150        0.6616  0.1964\n",
      "     49        0.5403       0.7130        0.6755  0.2153\n",
      "     50        \u001b[36m0.5370\u001b[0m       0.7080        0.6722  0.1861\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8186\u001b[0m       \u001b[32m0.5150\u001b[0m        \u001b[35m0.8884\u001b[0m  0.1981\n",
      "      2        \u001b[36m0.7153\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6937\u001b[0m  0.1953\n",
      "      3        \u001b[36m0.6654\u001b[0m       \u001b[32m0.7190\u001b[0m        \u001b[35m0.6711\u001b[0m  0.1912\n",
      "      4        \u001b[36m0.6484\u001b[0m       \u001b[32m0.7440\u001b[0m        \u001b[35m0.6366\u001b[0m  0.1956\n",
      "      5        \u001b[36m0.6316\u001b[0m       \u001b[32m0.7490\u001b[0m        \u001b[35m0.6312\u001b[0m  0.1817\n",
      "      6        \u001b[36m0.6251\u001b[0m       0.7490        \u001b[35m0.6280\u001b[0m  0.2033\n",
      "      7        \u001b[36m0.6222\u001b[0m       0.7490        \u001b[35m0.6223\u001b[0m  0.3344\n",
      "      8        \u001b[36m0.6178\u001b[0m       \u001b[32m0.7520\u001b[0m        \u001b[35m0.6151\u001b[0m  0.1874\n",
      "      9        \u001b[36m0.6128\u001b[0m       0.7460        0.6164  0.1952\n",
      "     10        \u001b[36m0.6107\u001b[0m       0.7420        0.6163  0.1545\n",
      "     11        \u001b[36m0.6070\u001b[0m       \u001b[32m0.7540\u001b[0m        \u001b[35m0.6114\u001b[0m  0.1572\n",
      "     12        \u001b[36m0.6058\u001b[0m       0.7540        \u001b[35m0.6071\u001b[0m  0.1644\n",
      "     13        \u001b[36m0.6010\u001b[0m       0.7480        0.6092  0.1625\n",
      "     14        \u001b[36m0.5989\u001b[0m       0.7490        0.6073  0.1684\n",
      "     15        \u001b[36m0.5973\u001b[0m       \u001b[32m0.7590\u001b[0m        0.6079  0.1579\n",
      "     16        \u001b[36m0.5962\u001b[0m       0.7500        0.6088  0.1564\n",
      "     17        \u001b[36m0.5910\u001b[0m       0.7470        0.6096  0.1671\n",
      "     18        0.5917       0.7490        0.6101  0.1668\n",
      "     19        \u001b[36m0.5899\u001b[0m       0.7500        0.6133  0.1693\n",
      "     20        \u001b[36m0.5870\u001b[0m       0.7370        0.6241  0.2128\n",
      "     21        0.5882       0.7420        0.6169  0.1898\n",
      "     22        \u001b[36m0.5862\u001b[0m       0.7390        0.6206  0.1825\n",
      "     23        \u001b[36m0.5842\u001b[0m       0.7500        0.6168  0.1860\n",
      "     24        \u001b[36m0.5796\u001b[0m       0.7520        0.6140  0.1992\n",
      "     25        \u001b[36m0.5757\u001b[0m       0.7490        0.6162  0.1893\n",
      "     26        0.5765       0.7490        0.6124  0.1813\n",
      "     27        \u001b[36m0.5751\u001b[0m       0.7520        0.6139  0.1959\n",
      "     28        \u001b[36m0.5722\u001b[0m       0.7490        0.6086  0.1934\n",
      "     29        \u001b[36m0.5688\u001b[0m       0.7520        \u001b[35m0.6068\u001b[0m  0.1913\n",
      "     30        \u001b[36m0.5676\u001b[0m       0.7500        0.6105  0.2018\n",
      "     31        \u001b[36m0.5639\u001b[0m       0.7440        0.6147  0.2335\n",
      "     32        0.5648       0.7420        0.6127  0.1970\n",
      "     33        \u001b[36m0.5636\u001b[0m       0.7370        0.6182  0.1979\n",
      "     34        \u001b[36m0.5633\u001b[0m       0.7490        0.6075  0.1996\n",
      "     35        \u001b[36m0.5597\u001b[0m       0.7490        0.6188  0.1852\n",
      "     36        0.5620       0.7550        0.6186  0.2122\n",
      "     37        0.5612       0.7500        \u001b[35m0.6065\u001b[0m  0.1982\n",
      "     38        \u001b[36m0.5563\u001b[0m       0.7570        0.6121  0.1922\n",
      "     39        0.5566       0.7580        0.6102  0.1944\n",
      "     40        0.5571       0.7520        0.6069  0.1978\n",
      "     41        \u001b[36m0.5530\u001b[0m       0.7540        \u001b[35m0.6014\u001b[0m  0.1889\n",
      "     42        \u001b[36m0.5485\u001b[0m       0.7500        0.6030  0.1902\n",
      "     43        \u001b[36m0.5476\u001b[0m       0.7590        0.6024  0.1905\n",
      "     44        0.5488       0.7510        0.6070  0.1765\n",
      "     45        \u001b[36m0.5460\u001b[0m       0.7550        0.6017  0.1900\n",
      "     46        \u001b[36m0.5384\u001b[0m       0.7520        0.6168  0.1909\n",
      "     47        0.5413       0.7490        0.6209  0.1909\n",
      "     48        0.5412       0.7470        0.6210  0.2008\n",
      "     49        0.5425       0.7560        0.6221  0.1947\n",
      "     50        0.5465       0.7460        0.6440  0.1874\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8954\u001b[0m       \u001b[32m0.6940\u001b[0m        \u001b[35m0.7124\u001b[0m  0.1964\n",
      "      2        \u001b[36m0.7017\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6783\u001b[0m  0.2014\n",
      "      3        \u001b[36m0.6695\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m0.6599\u001b[0m  0.2089\n",
      "      4        \u001b[36m0.6537\u001b[0m       0.7080        \u001b[35m0.6523\u001b[0m  0.1864\n",
      "      5        \u001b[36m0.6413\u001b[0m       0.7130        \u001b[35m0.6493\u001b[0m  0.1899\n",
      "      6        \u001b[36m0.6336\u001b[0m       \u001b[32m0.7210\u001b[0m        0.6495  0.1903\n",
      "      7        \u001b[36m0.6274\u001b[0m       0.7170        \u001b[35m0.6455\u001b[0m  0.1827\n",
      "      8        \u001b[36m0.6239\u001b[0m       0.7160        \u001b[35m0.6438\u001b[0m  0.1969\n",
      "      9        \u001b[36m0.6192\u001b[0m       0.7130        0.6451  0.1791\n",
      "     10        \u001b[36m0.6156\u001b[0m       0.7150        \u001b[35m0.6411\u001b[0m  0.2063\n",
      "     11        \u001b[36m0.6115\u001b[0m       0.7180        \u001b[35m0.6377\u001b[0m  0.1719\n",
      "     12        \u001b[36m0.6073\u001b[0m       0.7180        0.6381  0.1811\n",
      "     13        \u001b[36m0.6026\u001b[0m       0.7110        0.6414  0.1679\n",
      "     14        \u001b[36m0.6015\u001b[0m       0.7190        \u001b[35m0.6342\u001b[0m  0.2517\n",
      "     15        \u001b[36m0.5977\u001b[0m       0.7210        0.6468  0.2020\n",
      "     16        \u001b[36m0.5952\u001b[0m       0.7150        0.6366  0.1996\n",
      "     17        \u001b[36m0.5924\u001b[0m       0.7090        0.6517  0.1951\n",
      "     18        \u001b[36m0.5904\u001b[0m       0.7190        0.6425  0.2238\n",
      "     19        \u001b[36m0.5883\u001b[0m       0.7130        0.6398  0.2162\n",
      "     20        \u001b[36m0.5864\u001b[0m       0.7170        0.6468  0.1570\n",
      "     21        \u001b[36m0.5848\u001b[0m       0.7120        0.6605  0.1927\n",
      "     22        \u001b[36m0.5826\u001b[0m       0.7160        0.6541  0.1617\n",
      "     23        \u001b[36m0.5814\u001b[0m       0.7050        0.6590  0.1869\n",
      "     24        \u001b[36m0.5786\u001b[0m       0.7110        0.6719  0.1926\n",
      "     25        \u001b[36m0.5770\u001b[0m       0.7170        0.6647  0.1820\n",
      "     26        0.5774       0.7000        0.6544  0.1991\n",
      "     27        \u001b[36m0.5767\u001b[0m       0.6850        0.6779  0.1965\n",
      "     28        \u001b[36m0.5735\u001b[0m       0.7040        0.6524  0.1687\n",
      "     29        \u001b[36m0.5716\u001b[0m       0.6950        0.6587  0.2119\n",
      "     30        \u001b[36m0.5703\u001b[0m       0.6980        0.6713  0.2130\n",
      "     31        \u001b[36m0.5679\u001b[0m       0.7050        0.6692  0.1933\n",
      "     32        \u001b[36m0.5674\u001b[0m       0.7120        0.6680  0.1978\n",
      "     33        \u001b[36m0.5670\u001b[0m       0.7070        0.6787  0.2011\n",
      "     34        \u001b[36m0.5642\u001b[0m       0.7090        0.6634  0.1751\n",
      "     35        \u001b[36m0.5635\u001b[0m       0.7040        0.6689  0.1874\n",
      "     36        \u001b[36m0.5620\u001b[0m       0.6990        0.6831  0.1830\n",
      "     37        \u001b[36m0.5618\u001b[0m       0.7060        0.6656  0.1788\n",
      "     38        \u001b[36m0.5582\u001b[0m       0.7130        0.6677  0.1850\n",
      "     39        \u001b[36m0.5577\u001b[0m       0.7200        0.6797  0.1748\n",
      "     40        \u001b[36m0.5552\u001b[0m       0.7170        0.6761  0.1839\n",
      "     41        \u001b[36m0.5531\u001b[0m       0.7130        0.6695  0.2002\n",
      "     42        \u001b[36m0.5514\u001b[0m       0.7210        0.6867  0.1773\n",
      "     43        \u001b[36m0.5501\u001b[0m       0.7130        0.6743  0.1816\n",
      "     44        \u001b[36m0.5474\u001b[0m       0.7120        0.6855  0.1972\n",
      "     45        0.5495       0.7170        0.6905  0.1994\n",
      "     46        0.5489       0.7140        0.6808  0.1872\n",
      "     47        \u001b[36m0.5463\u001b[0m       0.7170        0.6864  0.1808\n",
      "     48        \u001b[36m0.5444\u001b[0m       0.7140        0.6798  0.1955\n",
      "     49        \u001b[36m0.5423\u001b[0m       0.7170        0.6842  0.1821\n",
      "     50        \u001b[36m0.5417\u001b[0m       0.7130        0.6780  0.1789\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8460\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.2216\u001b[0m  0.2586\n",
      "      2        \u001b[36m0.6972\u001b[0m       \u001b[32m0.4940\u001b[0m        \u001b[35m0.9489\u001b[0m  0.2420\n",
      "      3        \u001b[36m0.6570\u001b[0m       \u001b[32m0.5410\u001b[0m        \u001b[35m0.8697\u001b[0m  0.1880\n",
      "      4        \u001b[36m0.6379\u001b[0m       \u001b[32m0.5710\u001b[0m        \u001b[35m0.8429\u001b[0m  0.1778\n",
      "      5        \u001b[36m0.6288\u001b[0m       \u001b[32m0.5910\u001b[0m        \u001b[35m0.8194\u001b[0m  0.1589\n",
      "      6        \u001b[36m0.6223\u001b[0m       \u001b[32m0.6120\u001b[0m        \u001b[35m0.8083\u001b[0m  0.1653\n",
      "      7        \u001b[36m0.6170\u001b[0m       0.6110        \u001b[35m0.8004\u001b[0m  0.1544\n",
      "      8        \u001b[36m0.6129\u001b[0m       \u001b[32m0.6160\u001b[0m        \u001b[35m0.7952\u001b[0m  0.1568\n",
      "      9        \u001b[36m0.6099\u001b[0m       \u001b[32m0.6170\u001b[0m        \u001b[35m0.7857\u001b[0m  0.1543\n",
      "     10        \u001b[36m0.6067\u001b[0m       \u001b[32m0.6250\u001b[0m        \u001b[35m0.7825\u001b[0m  0.1608\n",
      "     11        \u001b[36m0.6036\u001b[0m       \u001b[32m0.6420\u001b[0m        \u001b[35m0.7613\u001b[0m  0.1529\n",
      "     12        \u001b[36m0.6013\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m0.7561\u001b[0m  0.1589\n",
      "     13        \u001b[36m0.5998\u001b[0m       \u001b[32m0.6480\u001b[0m        \u001b[35m0.7448\u001b[0m  0.2701\n",
      "     14        \u001b[36m0.5976\u001b[0m       \u001b[32m0.6610\u001b[0m        \u001b[35m0.7405\u001b[0m  0.1743\n",
      "     15        \u001b[36m0.5955\u001b[0m       0.6470        0.7587  0.1895\n",
      "     16        \u001b[36m0.5944\u001b[0m       0.6500        0.7423  0.1744\n",
      "     17        \u001b[36m0.5915\u001b[0m       0.6520        0.7422  0.1662\n",
      "     18        \u001b[36m0.5893\u001b[0m       \u001b[32m0.6640\u001b[0m        \u001b[35m0.7376\u001b[0m  0.1735\n",
      "     19        \u001b[36m0.5881\u001b[0m       0.6580        0.7404  0.1775\n",
      "     20        \u001b[36m0.5876\u001b[0m       0.6590        \u001b[35m0.7360\u001b[0m  0.1904\n",
      "     21        \u001b[36m0.5845\u001b[0m       0.6520        0.7371  0.1688\n",
      "     22        \u001b[36m0.5839\u001b[0m       0.6520        0.7361  0.1623\n",
      "     23        \u001b[36m0.5821\u001b[0m       0.6630        0.7401  0.1944\n",
      "     24        \u001b[36m0.5792\u001b[0m       0.6620        \u001b[35m0.7332\u001b[0m  0.2706\n",
      "     25        \u001b[36m0.5780\u001b[0m       0.6570        \u001b[35m0.7315\u001b[0m  0.1807\n",
      "     26        \u001b[36m0.5761\u001b[0m       0.6600        \u001b[35m0.7280\u001b[0m  0.1849\n",
      "     27        0.5762       0.6540        0.7299  0.1655\n",
      "     28        \u001b[36m0.5757\u001b[0m       \u001b[32m0.6670\u001b[0m        \u001b[35m0.7263\u001b[0m  0.1570\n",
      "     29        \u001b[36m0.5737\u001b[0m       0.6650        \u001b[35m0.7213\u001b[0m  0.1627\n",
      "     30        \u001b[36m0.5735\u001b[0m       \u001b[32m0.6750\u001b[0m        0.7224  0.1805\n",
      "     31        \u001b[36m0.5732\u001b[0m       0.6680        0.7246  0.1597\n",
      "     32        \u001b[36m0.5712\u001b[0m       0.6590        \u001b[35m0.7177\u001b[0m  0.1648\n",
      "     33        0.5713       0.6660        \u001b[35m0.7118\u001b[0m  0.1555\n",
      "     34        \u001b[36m0.5710\u001b[0m       0.6710        0.7144  0.1669\n",
      "     35        \u001b[36m0.5695\u001b[0m       0.6500        0.7139  0.2745\n",
      "     36        0.5701       0.6610        0.7122  0.1600\n",
      "     37        0.5697       0.6640        0.7123  0.1720\n",
      "     38        \u001b[36m0.5676\u001b[0m       0.6570        0.7121  0.1570\n",
      "     39        0.5680       0.6600        \u001b[35m0.7033\u001b[0m  0.1695\n",
      "     40        \u001b[36m0.5652\u001b[0m       0.6750        0.7090  0.1555\n",
      "     41        \u001b[36m0.5641\u001b[0m       0.6620        0.7111  0.1775\n",
      "     42        \u001b[36m0.5631\u001b[0m       0.6590        0.7164  0.1730\n",
      "     43        0.5642       0.6630        0.7144  0.1624\n",
      "     44        0.5636       \u001b[32m0.6800\u001b[0m        \u001b[35m0.7007\u001b[0m  0.1630\n",
      "     45        \u001b[36m0.5622\u001b[0m       \u001b[32m0.6860\u001b[0m        0.7040  0.1614\n",
      "     46        \u001b[36m0.5614\u001b[0m       0.6830        0.7047  0.2685\n",
      "     47        \u001b[36m0.5590\u001b[0m       0.6790        0.7053  0.2021\n",
      "     48        0.5594       0.6670        0.7094  0.1559\n",
      "     49        \u001b[36m0.5569\u001b[0m       0.6710        0.7081  0.1806\n",
      "     50        0.5578       0.6640        0.7153  0.1922\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8343\u001b[0m       \u001b[32m0.6610\u001b[0m        \u001b[35m0.7336\u001b[0m  0.1924\n",
      "      2        \u001b[36m0.7006\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.6747\u001b[0m  0.1816\n",
      "      3        \u001b[36m0.6656\u001b[0m       \u001b[32m0.6980\u001b[0m        \u001b[35m0.6605\u001b[0m  0.1788\n",
      "      4        \u001b[36m0.6428\u001b[0m       \u001b[32m0.7030\u001b[0m        \u001b[35m0.6497\u001b[0m  0.1916\n",
      "      5        \u001b[36m0.6311\u001b[0m       0.6990        0.6510  0.2980\n",
      "      6        \u001b[36m0.6246\u001b[0m       0.6940        \u001b[35m0.6448\u001b[0m  0.3298\n",
      "      7        \u001b[36m0.6183\u001b[0m       0.6950        0.6469  0.1803\n",
      "      8        \u001b[36m0.6148\u001b[0m       0.6910        0.6454  0.1751\n",
      "      9        \u001b[36m0.6138\u001b[0m       0.6950        0.6518  0.1716\n",
      "     10        \u001b[36m0.6106\u001b[0m       \u001b[32m0.7040\u001b[0m        0.6552  0.1526\n",
      "     11        \u001b[36m0.6105\u001b[0m       0.6990        0.6683  0.1737\n",
      "     12        \u001b[36m0.6080\u001b[0m       0.6950        0.6710  0.1671\n",
      "     13        \u001b[36m0.6034\u001b[0m       \u001b[32m0.7110\u001b[0m        0.6612  0.1694\n",
      "     14        \u001b[36m0.5983\u001b[0m       \u001b[32m0.7210\u001b[0m        0.6533  0.1691\n",
      "     15        \u001b[36m0.5945\u001b[0m       0.7120        0.6549  0.1748\n",
      "     16        \u001b[36m0.5908\u001b[0m       0.7060        0.6693  0.1686\n",
      "     17        0.5920       0.7140        0.6590  0.2694\n",
      "     18        \u001b[36m0.5876\u001b[0m       \u001b[32m0.7290\u001b[0m        0.6584  0.1639\n",
      "     19        \u001b[36m0.5855\u001b[0m       0.7250        0.6613  0.1670\n",
      "     20        \u001b[36m0.5833\u001b[0m       0.7140        0.6544  0.1617\n",
      "     21        \u001b[36m0.5816\u001b[0m       0.7130        0.6681  0.1733\n",
      "     22        \u001b[36m0.5772\u001b[0m       \u001b[32m0.7330\u001b[0m        0.6527  0.1812\n",
      "     23        0.5783       0.7210        0.6578  0.1883\n",
      "     24        \u001b[36m0.5742\u001b[0m       0.7330        0.6549  0.1963\n",
      "     25        \u001b[36m0.5737\u001b[0m       0.7260        0.6561  0.1631\n",
      "     26        \u001b[36m0.5715\u001b[0m       0.7320        0.6612  0.1600\n",
      "     27        \u001b[36m0.5687\u001b[0m       0.7240        0.6613  0.1624\n",
      "     28        0.5715       0.7260        0.6614  0.2717\n",
      "     29        0.5703       0.7250        0.6525  0.1682\n",
      "     30        \u001b[36m0.5675\u001b[0m       0.7230        0.6650  0.1594\n",
      "     31        \u001b[36m0.5649\u001b[0m       0.7330        0.6626  0.1697\n",
      "     32        \u001b[36m0.5648\u001b[0m       0.7330        0.6595  0.1654\n",
      "     33        \u001b[36m0.5619\u001b[0m       0.7270        0.6567  0.1645\n",
      "     34        0.5626       \u001b[32m0.7380\u001b[0m        0.6593  0.1683\n",
      "     35        \u001b[36m0.5614\u001b[0m       0.7290        0.6555  0.1701\n",
      "     36        \u001b[36m0.5593\u001b[0m       0.7270        0.6660  0.1716\n",
      "     37        \u001b[36m0.5565\u001b[0m       0.7260        0.6658  0.1613\n",
      "     38        0.5587       0.7310        0.6582  0.1614\n",
      "     39        \u001b[36m0.5556\u001b[0m       0.7290        0.6469  0.2780\n",
      "     40        0.5557       0.7290        0.6603  0.1613\n",
      "     41        \u001b[36m0.5526\u001b[0m       0.7240        0.6598  0.1669\n",
      "     42        \u001b[36m0.5509\u001b[0m       0.7250        0.6645  0.1554\n",
      "     43        \u001b[36m0.5485\u001b[0m       0.7160        0.6706  0.1636\n",
      "     44        0.5485       0.7300        0.6599  0.1653\n",
      "     45        0.5493       0.7220        0.6618  0.1686\n",
      "     46        0.5486       0.7200        0.6684  0.1586\n",
      "     47        0.5510       0.7160        0.6773  0.1659\n",
      "     48        \u001b[36m0.5483\u001b[0m       0.7160        0.6811  0.1687\n",
      "     49        \u001b[36m0.5480\u001b[0m       0.7090        0.6808  0.1707\n",
      "     50        \u001b[36m0.5424\u001b[0m       0.7090        0.6748  0.2384\n",
      "     51        0.5443       0.7220        0.6866  0.1861\n",
      "     52        \u001b[36m0.5399\u001b[0m       0.7070        0.6762  0.1637\n",
      "     53        \u001b[36m0.5362\u001b[0m       0.7160        0.6952  0.1563\n",
      "     54        \u001b[36m0.5345\u001b[0m       0.7210        0.6989  0.1731\n",
      "     55        0.5345       0.7210        0.6841  0.1645\n",
      "     56        \u001b[36m0.5335\u001b[0m       0.7250        0.6985  0.1679\n",
      "     57        \u001b[36m0.5325\u001b[0m       0.7190        0.6859  0.1589\n",
      "     58        \u001b[36m0.5266\u001b[0m       0.7130        0.6926  0.1673\n",
      "     59        0.5278       0.7150        0.6879  0.1677\n",
      "     60        0.5267       0.7150        0.6818  0.1627\n",
      "     61        \u001b[36m0.5262\u001b[0m       0.7200        0.6808  0.1821\n",
      "     62        \u001b[36m0.5221\u001b[0m       0.7120        0.6747  0.3341\n",
      "     63        0.5223       0.7140        0.6991  0.1835\n",
      "     64        0.5264       0.7170        0.6913  0.1651\n",
      "     65        0.5235       0.7190        0.6920  0.1592\n",
      "     66        \u001b[36m0.5216\u001b[0m       0.7260        0.6941  0.1713\n",
      "     67        \u001b[36m0.5200\u001b[0m       0.7270        0.7132  0.1759\n",
      "     68        \u001b[36m0.5181\u001b[0m       0.7220        0.7141  0.1991\n",
      "     69        \u001b[36m0.5168\u001b[0m       0.7290        0.7068  0.1846\n",
      "     70        \u001b[36m0.5142\u001b[0m       0.7150        0.7192  0.1796\n",
      "     71        0.5150       0.7190        0.7247  0.2143\n",
      "     72        \u001b[36m0.5136\u001b[0m       0.7200        0.7159  0.2469\n",
      "     73        \u001b[36m0.5131\u001b[0m       0.7040        0.7140  0.2231\n",
      "     74        \u001b[36m0.5084\u001b[0m       0.6980        0.7447  0.1848\n",
      "     75        0.5096       0.7030        0.7279  0.1618\n",
      "     76        \u001b[36m0.5066\u001b[0m       0.7110        0.7328  0.1685\n",
      "     77        0.5104       0.7180        0.7193  0.1627\n",
      "     78        0.5096       0.7150        0.7434  0.1613\n",
      "     79        \u001b[36m0.5054\u001b[0m       0.7080        0.7415  0.2889\n",
      "     80        0.5058       0.7140        0.7606  0.1747\n",
      "     81        \u001b[36m0.5054\u001b[0m       0.7110        0.7502  0.1682\n",
      "     82        0.5080       0.7190        0.7684  0.1601\n",
      "     83        0.5093       0.7090        0.7698  0.1729\n",
      "     84        \u001b[36m0.4999\u001b[0m       0.6960        0.7848  0.1672\n",
      "     85        0.5032       0.7120        0.7824  0.1724\n",
      "     86        \u001b[36m0.4973\u001b[0m       0.6980        0.7879  0.1837\n",
      "     87        0.5039       0.6990        0.7720  0.1771\n",
      "     88        0.5054       0.7070        0.7620  0.1818\n",
      "     89        0.5008       0.7040        0.7681  0.1791\n",
      "     90        \u001b[36m0.4928\u001b[0m       0.6910        0.7935  0.2001\n",
      "     91        0.5007       0.7000        0.7848  0.1941\n",
      "     92        0.4998       0.7060        0.7790  0.1909\n",
      "     93        0.4941       0.7140        0.7957  0.1631\n",
      "     94        0.4955       0.7130        0.7865  0.1612\n",
      "     95        0.4957       0.7090        0.7649  0.1675\n",
      "     96        0.4933       0.7170        0.7730  0.1573\n",
      "     97        0.4930       0.7090        0.7733  0.1605\n",
      "     98        \u001b[36m0.4924\u001b[0m       0.7060        0.7891  0.1631\n",
      "     99        \u001b[36m0.4923\u001b[0m       0.6950        0.7706  0.1600\n",
      "    100        \u001b[36m0.4862\u001b[0m       0.7020        0.7735  0.1655\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8086\u001b[0m       \u001b[32m0.5830\u001b[0m        \u001b[35m0.7883\u001b[0m  0.1670\n",
      "      2        \u001b[36m0.7122\u001b[0m       \u001b[32m0.7010\u001b[0m        \u001b[35m0.6941\u001b[0m  0.1655\n",
      "      3        \u001b[36m0.6686\u001b[0m       \u001b[32m0.7220\u001b[0m        \u001b[35m0.6822\u001b[0m  0.1792\n",
      "      4        \u001b[36m0.6471\u001b[0m       \u001b[32m0.7270\u001b[0m        \u001b[35m0.6640\u001b[0m  0.1680\n",
      "      5        \u001b[36m0.6355\u001b[0m       \u001b[32m0.7490\u001b[0m        \u001b[35m0.6337\u001b[0m  0.2649\n",
      "      6        \u001b[36m0.6255\u001b[0m       0.7490        \u001b[35m0.6274\u001b[0m  0.1822\n",
      "      7        \u001b[36m0.6176\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.6235\u001b[0m  0.1803\n",
      "      8        \u001b[36m0.6131\u001b[0m       0.7490        0.6240  0.1719\n",
      "      9        \u001b[36m0.6084\u001b[0m       \u001b[32m0.7540\u001b[0m        \u001b[35m0.6185\u001b[0m  0.1739\n",
      "     10        \u001b[36m0.6025\u001b[0m       \u001b[32m0.7560\u001b[0m        \u001b[35m0.6139\u001b[0m  0.1690\n",
      "     11        \u001b[36m0.5990\u001b[0m       0.7560        \u001b[35m0.6127\u001b[0m  0.1657\n",
      "     12        \u001b[36m0.5966\u001b[0m       0.7530        \u001b[35m0.6085\u001b[0m  0.1796\n",
      "     13        \u001b[36m0.5926\u001b[0m       \u001b[32m0.7600\u001b[0m        \u001b[35m0.6066\u001b[0m  0.1594\n",
      "     14        \u001b[36m0.5896\u001b[0m       0.7590        \u001b[35m0.6056\u001b[0m  0.1735\n",
      "     15        \u001b[36m0.5888\u001b[0m       \u001b[32m0.7610\u001b[0m        \u001b[35m0.6021\u001b[0m  0.1579\n",
      "     16        \u001b[36m0.5874\u001b[0m       \u001b[32m0.7620\u001b[0m        0.6092  0.3077\n",
      "     17        \u001b[36m0.5851\u001b[0m       \u001b[32m0.7660\u001b[0m        0.6061  0.1776\n",
      "     18        \u001b[36m0.5839\u001b[0m       \u001b[32m0.7680\u001b[0m        \u001b[35m0.5952\u001b[0m  0.1832\n",
      "     19        \u001b[36m0.5794\u001b[0m       0.7630        0.6002  0.1778\n",
      "     20        \u001b[36m0.5763\u001b[0m       0.7630        0.5994  0.1805\n",
      "     21        \u001b[36m0.5755\u001b[0m       0.7580        0.6045  0.1587\n",
      "     22        \u001b[36m0.5749\u001b[0m       0.7600        0.6065  0.1613\n",
      "     23        \u001b[36m0.5707\u001b[0m       0.7530        0.6094  0.1644\n",
      "     24        \u001b[36m0.5700\u001b[0m       0.7530        0.6068  0.1835\n",
      "     25        \u001b[36m0.5673\u001b[0m       0.7520        0.6052  0.1901\n",
      "     26        \u001b[36m0.5630\u001b[0m       0.7560        0.6109  0.1960\n",
      "     27        0.5680       0.7540        0.6108  0.1653\n",
      "     28        \u001b[36m0.5617\u001b[0m       0.7540        0.6107  0.1841\n",
      "     29        \u001b[36m0.5614\u001b[0m       0.7460        0.6270  0.1976\n",
      "     30        0.5656       0.7620        0.6142  0.2063\n",
      "     31        \u001b[36m0.5600\u001b[0m       0.7520        0.6141  0.1827\n",
      "     32        \u001b[36m0.5558\u001b[0m       0.7570        0.6238  0.1677\n",
      "     33        \u001b[36m0.5517\u001b[0m       0.7580        0.6259  0.1625\n",
      "     34        \u001b[36m0.5491\u001b[0m       0.7590        0.6207  0.1624\n",
      "     35        \u001b[36m0.5475\u001b[0m       0.7520        0.6305  0.1586\n",
      "     36        \u001b[36m0.5453\u001b[0m       0.7440        0.6323  0.1694\n",
      "     37        \u001b[36m0.5449\u001b[0m       0.7500        0.6247  0.1580\n",
      "     38        \u001b[36m0.5402\u001b[0m       0.7550        0.6347  0.1622\n",
      "     39        \u001b[36m0.5377\u001b[0m       \u001b[32m0.7700\u001b[0m        0.6218  0.1669\n",
      "     40        \u001b[36m0.5345\u001b[0m       0.7530        0.6329  0.1643\n",
      "     41        0.5366       0.7540        0.6337  0.1615\n",
      "     42        0.5350       0.7370        0.6411  0.1647\n",
      "     43        0.5408       0.7440        0.6426  0.2929\n",
      "     44        0.5364       0.7480        0.6339  0.1647\n",
      "     45        \u001b[36m0.5318\u001b[0m       0.7610        0.6236  0.1663\n",
      "     46        \u001b[36m0.5304\u001b[0m       0.7510        0.6278  0.1618\n",
      "     47        \u001b[36m0.5278\u001b[0m       0.7640        0.6154  0.1628\n",
      "     48        0.5286       0.7240        0.6547  0.1688\n",
      "     49        0.5291       0.7410        0.6440  0.1653\n",
      "     50        0.5291       0.7250        0.6679  0.1654\n",
      "     51        \u001b[36m0.5261\u001b[0m       0.7210        0.6561  0.1597\n",
      "     52        \u001b[36m0.5255\u001b[0m       0.7240        0.6578  0.1679\n",
      "     53        0.5261       0.7220        0.6588  0.1785\n",
      "     54        \u001b[36m0.5239\u001b[0m       0.7260        0.6434  0.1680\n",
      "     55        0.5271       0.7260        0.6510  0.1667\n",
      "     56        0.5260       0.7340        0.6524  0.1646\n",
      "     57        \u001b[36m0.5178\u001b[0m       0.7230        0.6570  0.1690\n",
      "     58        0.5224       0.7200        0.6566  0.1815\n",
      "     59        0.5193       0.7240        0.6557  0.2743\n",
      "     60        0.5227       0.7390        0.6326  0.1620\n",
      "     61        0.5194       0.7400        0.6294  0.1655\n",
      "     62        \u001b[36m0.5167\u001b[0m       0.7400        0.6369  0.1575\n",
      "     63        0.5185       0.7310        0.6543  0.1584\n",
      "     64        \u001b[36m0.5103\u001b[0m       0.7370        0.6582  0.1629\n",
      "     65        \u001b[36m0.5070\u001b[0m       0.7450        0.6366  0.1599\n",
      "     66        \u001b[36m0.5069\u001b[0m       0.7340        0.6488  0.1628\n",
      "     67        \u001b[36m0.5033\u001b[0m       0.7370        0.6521  0.1631\n",
      "     68        \u001b[36m0.4993\u001b[0m       0.7370        0.6580  0.1833\n",
      "     69        0.5062       0.7380        0.6529  0.1632\n",
      "     70        0.5114       0.7370        0.6589  0.1570\n",
      "     71        \u001b[36m0.4990\u001b[0m       0.7370        0.6552  0.1665\n",
      "     72        0.5062       0.7400        0.6655  0.1725\n",
      "     73        0.5045       0.7390        0.6737  0.1817\n",
      "     74        0.5015       0.7430        0.6539  0.1629\n",
      "     75        0.5005       0.7310        0.6612  0.1654\n",
      "     76        0.5017       0.7530        0.6581  0.2945\n",
      "     77        \u001b[36m0.4951\u001b[0m       0.7400        0.6617  0.1734\n",
      "     78        0.4954       0.7330        0.6732  0.1686\n",
      "     79        \u001b[36m0.4902\u001b[0m       0.7380        0.6904  0.1864\n",
      "     80        \u001b[36m0.4879\u001b[0m       0.7290        0.7012  0.1834\n",
      "     81        0.4900       0.7270        0.7051  0.1814\n",
      "     82        \u001b[36m0.4857\u001b[0m       0.7240        0.7309  0.1759\n",
      "     83        \u001b[36m0.4845\u001b[0m       0.7160        0.7349  0.1744\n",
      "     84        0.4944       0.7160        0.7317  0.1783\n",
      "     85        0.5010       0.7230        0.7261  0.2221\n",
      "     86        0.5056       0.7370        0.6932  0.2037\n",
      "     87        0.4871       0.7350        0.7235  0.1654\n",
      "     88        \u001b[36m0.4796\u001b[0m       0.7250        0.7468  0.1693\n",
      "     89        0.4802       0.7370        0.7249  0.1739\n",
      "     90        \u001b[36m0.4702\u001b[0m       0.7430        0.7137  0.1716\n",
      "     91        0.4748       0.7480        0.6877  0.1605\n",
      "     92        \u001b[36m0.4693\u001b[0m       0.7350        0.7365  0.1675\n",
      "     93        0.4723       0.7370        0.7346  0.1632\n",
      "     94        0.4749       0.7320        0.7194  0.1651\n",
      "     95        0.4766       0.7350        0.7534  0.1740\n",
      "     96        0.4695       0.7300        0.7343  0.1757\n",
      "     97        0.4699       0.7180        0.7351  0.1597\n",
      "     98        \u001b[36m0.4659\u001b[0m       0.7320        0.7310  0.1592\n",
      "     99        \u001b[36m0.4583\u001b[0m       0.7180        0.7524  0.1677\n",
      "    100        \u001b[36m0.4577\u001b[0m       0.7240        0.7517  0.1628\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9300\u001b[0m       \u001b[32m0.6770\u001b[0m        \u001b[35m0.7245\u001b[0m  0.1630\n",
      "      2        \u001b[36m0.7020\u001b[0m       \u001b[32m0.7030\u001b[0m        \u001b[35m0.6774\u001b[0m  0.1539\n",
      "      3        \u001b[36m0.6636\u001b[0m       \u001b[32m0.7090\u001b[0m        \u001b[35m0.6513\u001b[0m  0.1560\n",
      "      4        \u001b[36m0.6436\u001b[0m       \u001b[32m0.7230\u001b[0m        \u001b[35m0.6449\u001b[0m  0.1849\n",
      "      5        \u001b[36m0.6310\u001b[0m       0.7230        0.6479  0.1631\n",
      "      6        \u001b[36m0.6258\u001b[0m       0.7200        0.6467  0.1731\n",
      "      7        \u001b[36m0.6212\u001b[0m       0.7150        \u001b[35m0.6406\u001b[0m  0.1590\n",
      "      8        \u001b[36m0.6177\u001b[0m       0.7220        0.6415  0.1592\n",
      "      9        \u001b[36m0.6136\u001b[0m       0.7220        0.6448  0.2697\n",
      "     10        \u001b[36m0.6108\u001b[0m       \u001b[32m0.7270\u001b[0m        0.6464  0.1599\n",
      "     11        \u001b[36m0.6078\u001b[0m       0.7220        0.6433  0.1559\n",
      "     12        \u001b[36m0.6047\u001b[0m       0.7240        \u001b[35m0.6401\u001b[0m  0.1858\n",
      "     13        \u001b[36m0.6018\u001b[0m       0.7190        \u001b[35m0.6369\u001b[0m  0.1863\n",
      "     14        \u001b[36m0.5995\u001b[0m       0.7190        0.6388  0.1705\n",
      "     15        \u001b[36m0.5961\u001b[0m       0.7220        0.6397  0.1727\n",
      "     16        \u001b[36m0.5938\u001b[0m       \u001b[32m0.7280\u001b[0m        0.6415  0.1614\n",
      "     17        \u001b[36m0.5920\u001b[0m       0.7270        0.6414  0.1570\n",
      "     18        \u001b[36m0.5904\u001b[0m       0.7260        0.6431  0.1890\n",
      "     19        \u001b[36m0.5888\u001b[0m       0.7250        0.6415  0.1623\n",
      "     20        \u001b[36m0.5873\u001b[0m       0.7230        0.6408  0.1547\n",
      "     21        \u001b[36m0.5846\u001b[0m       0.7280        0.6447  0.1629\n",
      "     22        0.5854       \u001b[32m0.7300\u001b[0m        0.6458  0.1791\n",
      "     23        \u001b[36m0.5817\u001b[0m       0.7180        0.6514  0.1609\n",
      "     24        0.5828       0.7120        0.6551  0.1555\n",
      "     25        \u001b[36m0.5810\u001b[0m       0.7180        0.6545  0.1867\n",
      "     26        \u001b[36m0.5783\u001b[0m       0.7190        0.6480  0.1458\n",
      "     27        \u001b[36m0.5760\u001b[0m       0.7160        0.6583  0.1830\n",
      "     28        \u001b[36m0.5746\u001b[0m       0.7250        0.6476  0.1731\n",
      "     29        \u001b[36m0.5734\u001b[0m       0.7250        0.6518  0.1836\n",
      "     30        \u001b[36m0.5709\u001b[0m       0.7260        0.6588  0.1746\n",
      "     31        0.5711       0.7300        0.6583  0.1587\n",
      "     32        \u001b[36m0.5688\u001b[0m       \u001b[32m0.7310\u001b[0m        0.6654  0.1560\n",
      "     33        \u001b[36m0.5654\u001b[0m       0.7310        0.6719  0.1581\n",
      "     34        0.5660       0.7310        0.6760  0.1569\n",
      "     35        \u001b[36m0.5621\u001b[0m       \u001b[32m0.7320\u001b[0m        0.6973  0.1886\n",
      "     36        0.5623       0.7310        0.6903  0.1649\n",
      "     37        \u001b[36m0.5595\u001b[0m       0.7310        0.6967  0.1873\n",
      "     38        \u001b[36m0.5594\u001b[0m       0.7240        0.7038  0.1783\n",
      "     39        \u001b[36m0.5564\u001b[0m       0.7290        0.6900  0.1526\n",
      "     40        \u001b[36m0.5549\u001b[0m       0.7320        0.6831  0.1534\n",
      "     41        \u001b[36m0.5542\u001b[0m       0.7250        0.6885  0.1510\n",
      "     42        \u001b[36m0.5529\u001b[0m       0.7190        0.6919  0.1528\n",
      "     43        0.5545       0.7200        0.6892  0.1556\n",
      "     44        \u001b[36m0.5517\u001b[0m       0.7260        0.7015  0.1648\n",
      "     45        \u001b[36m0.5496\u001b[0m       0.7210        0.6862  0.1817\n",
      "     46        \u001b[36m0.5490\u001b[0m       0.7240        0.6863  0.1606\n",
      "     47        \u001b[36m0.5451\u001b[0m       0.7170        0.6924  0.1639\n",
      "     48        0.5460       0.7220        0.6919  0.1561\n",
      "     49        \u001b[36m0.5437\u001b[0m       0.7210        0.7037  0.1529\n",
      "     50        \u001b[36m0.5388\u001b[0m       0.7190        0.7266  0.1519\n",
      "     51        0.5411       0.7190        0.6996  0.1627\n",
      "     52        0.5415       0.7160        0.7031  0.1555\n",
      "     53        \u001b[36m0.5383\u001b[0m       0.7120        0.6997  0.1524\n",
      "     54        \u001b[36m0.5363\u001b[0m       0.7080        0.6976  0.1737\n",
      "     55        0.5385       0.7100        0.6994  0.1966\n",
      "     56        0.5377       0.7090        0.7106  0.1677\n",
      "     57        \u001b[36m0.5346\u001b[0m       0.7070        0.7078  0.1498\n",
      "     58        0.5352       0.7110        0.6995  0.1924\n",
      "     59        \u001b[36m0.5279\u001b[0m       0.7110        0.7209  0.1513\n",
      "     60        0.5319       0.7140        0.7114  0.1565\n",
      "     61        0.5294       0.7050        0.7012  0.1593\n",
      "     62        0.5301       0.7170        0.7076  0.1650\n",
      "     63        \u001b[36m0.5271\u001b[0m       0.7120        0.7183  0.1552\n",
      "     64        0.5338       0.7100        0.7163  0.1432\n",
      "     65        0.5280       0.7140        0.7253  0.1544\n",
      "     66        0.5311       0.7090        0.6993  0.1548\n",
      "     67        \u001b[36m0.5239\u001b[0m       0.7080        0.7096  0.2579\n",
      "     68        0.5285       0.7120        0.7381  0.1658\n",
      "     69        \u001b[36m0.5227\u001b[0m       0.7090        0.7669  0.1611\n",
      "     70        0.5256       0.7070        0.7600  0.1652\n",
      "     71        \u001b[36m0.5217\u001b[0m       0.7110        0.7275  0.1602\n",
      "     72        0.5221       0.7130        0.7124  0.1726\n",
      "     73        0.5219       0.7000        0.7566  0.1682\n",
      "     74        \u001b[36m0.5212\u001b[0m       0.7060        0.7410  0.1628\n",
      "     75        0.5225       0.7110        0.7284  0.1594\n",
      "     76        \u001b[36m0.5202\u001b[0m       0.7030        0.7404  0.1562\n",
      "     77        \u001b[36m0.5154\u001b[0m       0.7050        0.7350  0.1560\n",
      "     78        0.5182       0.7080        0.7582  0.1503\n",
      "     79        \u001b[36m0.5152\u001b[0m       0.7050        0.7346  0.2627\n",
      "     80        0.5186       0.6970        0.7362  0.1660\n",
      "     81        0.5156       0.7090        0.7489  0.1598\n",
      "     82        \u001b[36m0.5130\u001b[0m       0.7060        0.7444  0.1606\n",
      "     83        \u001b[36m0.5103\u001b[0m       0.7000        0.7517  0.1555\n",
      "     84        0.5149       0.7090        0.7639  0.1521\n",
      "     85        0.5147       0.7030        0.7568  0.1535\n",
      "     86        0.5123       0.7030        0.7570  0.1645\n",
      "     87        0.5135       0.7130        0.7498  0.1709\n",
      "     88        0.5125       0.7120        0.7672  0.1819\n",
      "     89        0.5119       0.7020        0.7691  0.1745\n",
      "     90        \u001b[36m0.5090\u001b[0m       0.7030        0.7502  0.1516\n",
      "     91        0.5148       0.7150        0.7363  0.1576\n",
      "     92        0.5094       0.7080        0.7732  0.1621\n",
      "     93        \u001b[36m0.5076\u001b[0m       0.7180        0.7482  0.1612\n",
      "     94        \u001b[36m0.5067\u001b[0m       0.7090        0.7687  0.1726\n",
      "     95        \u001b[36m0.5051\u001b[0m       0.7030        0.7788  0.1671\n",
      "     96        \u001b[36m0.5029\u001b[0m       0.7060        0.7855  0.1915\n",
      "     97        0.5064       0.7150        0.7462  0.1668\n",
      "     98        0.5058       0.7010        0.7685  0.1848\n",
      "     99        \u001b[36m0.5022\u001b[0m       0.7120        0.7722  0.1764\n",
      "    100        0.5060       0.7030        0.7848  0.1619\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8574\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.2470\u001b[0m  0.1669\n",
      "      2        \u001b[36m0.7172\u001b[0m       \u001b[32m0.5180\u001b[0m        \u001b[35m0.8826\u001b[0m  0.1612\n",
      "      3        \u001b[36m0.6763\u001b[0m       \u001b[32m0.5430\u001b[0m        \u001b[35m0.8417\u001b[0m  0.1590\n",
      "      4        \u001b[36m0.6524\u001b[0m       \u001b[32m0.5770\u001b[0m        \u001b[35m0.8271\u001b[0m  0.1619\n",
      "      5        \u001b[36m0.6380\u001b[0m       \u001b[32m0.5980\u001b[0m        \u001b[35m0.8083\u001b[0m  0.1592\n",
      "      6        \u001b[36m0.6284\u001b[0m       \u001b[32m0.6160\u001b[0m        \u001b[35m0.7923\u001b[0m  0.1540\n",
      "      7        \u001b[36m0.6229\u001b[0m       0.6150        0.7996  0.1563\n",
      "      8        \u001b[36m0.6170\u001b[0m       \u001b[32m0.6260\u001b[0m        \u001b[35m0.7863\u001b[0m  0.1449\n",
      "      9        \u001b[36m0.6134\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m0.7595\u001b[0m  0.2559\n",
      "     10        \u001b[36m0.6074\u001b[0m       0.6370        0.7682  0.1537\n",
      "     11        \u001b[36m0.6060\u001b[0m       \u001b[32m0.6570\u001b[0m        \u001b[35m0.7576\u001b[0m  0.1586\n",
      "     12        \u001b[36m0.6032\u001b[0m       0.6520        \u001b[35m0.7568\u001b[0m  0.1630\n",
      "     13        \u001b[36m0.5993\u001b[0m       0.6430        0.7661  0.1584\n",
      "     14        \u001b[36m0.5990\u001b[0m       \u001b[32m0.6620\u001b[0m        \u001b[35m0.7517\u001b[0m  0.1563\n",
      "     15        \u001b[36m0.5966\u001b[0m       0.6570        0.7517  0.1654\n",
      "     16        \u001b[36m0.5945\u001b[0m       0.6540        \u001b[35m0.7484\u001b[0m  0.1703\n",
      "     17        \u001b[36m0.5923\u001b[0m       0.6620        \u001b[35m0.7413\u001b[0m  0.1610\n",
      "     18        \u001b[36m0.5903\u001b[0m       \u001b[32m0.6680\u001b[0m        0.7414  0.1726\n",
      "     19        \u001b[36m0.5890\u001b[0m       0.6650        \u001b[35m0.7396\u001b[0m  0.1774\n",
      "     20        \u001b[36m0.5878\u001b[0m       \u001b[32m0.6730\u001b[0m        \u001b[35m0.7324\u001b[0m  0.1675\n",
      "     21        \u001b[36m0.5861\u001b[0m       0.6690        0.7357  0.1605\n",
      "     22        \u001b[36m0.5833\u001b[0m       0.6660        0.7423  0.1687\n",
      "     23        \u001b[36m0.5821\u001b[0m       \u001b[32m0.6810\u001b[0m        0.7327  0.1585\n",
      "     24        \u001b[36m0.5812\u001b[0m       0.6760        0.7332  0.1674\n",
      "     25        \u001b[36m0.5793\u001b[0m       0.6780        \u001b[35m0.7262\u001b[0m  0.2136\n",
      "     26        \u001b[36m0.5764\u001b[0m       0.6680        0.7300  0.1972\n",
      "     27        \u001b[36m0.5763\u001b[0m       0.6700        0.7317  0.1823\n",
      "     28        \u001b[36m0.5733\u001b[0m       0.6700        0.7274  0.1511\n",
      "     29        \u001b[36m0.5713\u001b[0m       0.6710        \u001b[35m0.7215\u001b[0m  0.1551\n",
      "     30        \u001b[36m0.5705\u001b[0m       0.6730        \u001b[35m0.7095\u001b[0m  0.1500\n",
      "     31        \u001b[36m0.5692\u001b[0m       0.6760        \u001b[35m0.6959\u001b[0m  0.1646\n",
      "     32        \u001b[36m0.5654\u001b[0m       \u001b[32m0.6840\u001b[0m        0.7034  0.1543\n",
      "     33        0.5658       0.6730        0.7105  0.1522\n",
      "     34        \u001b[36m0.5633\u001b[0m       0.6740        0.7033  0.1490\n",
      "     35        0.5640       \u001b[32m0.6850\u001b[0m        \u001b[35m0.6892\u001b[0m  0.1537\n",
      "     36        \u001b[36m0.5611\u001b[0m       0.6700        0.6988  0.1446\n",
      "     37        \u001b[36m0.5587\u001b[0m       0.6730        0.7031  0.1528\n",
      "     38        \u001b[36m0.5579\u001b[0m       0.6640        0.7037  0.1537\n",
      "     39        0.5588       \u001b[32m0.6860\u001b[0m        0.6913  0.1560\n",
      "     40        \u001b[36m0.5576\u001b[0m       0.6800        0.6934  0.1553\n",
      "     41        \u001b[36m0.5542\u001b[0m       0.6830        0.6961  0.2602\n",
      "     42        \u001b[36m0.5539\u001b[0m       \u001b[32m0.6940\u001b[0m        \u001b[35m0.6827\u001b[0m  0.1533\n",
      "     43        \u001b[36m0.5529\u001b[0m       0.6870        0.6967  0.1547\n",
      "     44        \u001b[36m0.5512\u001b[0m       0.6910        0.6991  0.1506\n",
      "     45        0.5513       0.6920        0.7058  0.1536\n",
      "     46        \u001b[36m0.5495\u001b[0m       \u001b[32m0.7010\u001b[0m        0.6947  0.1525\n",
      "     47        \u001b[36m0.5450\u001b[0m       0.6900        0.7051  0.1677\n",
      "     48        \u001b[36m0.5434\u001b[0m       \u001b[32m0.7060\u001b[0m        0.7001  0.1789\n",
      "     49        0.5462       \u001b[32m0.7120\u001b[0m        0.6906  0.1708\n",
      "     50        0.5443       0.7040        0.6948  0.1558\n",
      "     51        \u001b[36m0.5416\u001b[0m       \u001b[32m0.7190\u001b[0m        0.6941  0.1874\n",
      "     52        \u001b[36m0.5396\u001b[0m       0.7130        0.7005  0.1873\n",
      "     53        0.5410       \u001b[32m0.7340\u001b[0m        0.6862  0.1752\n",
      "     54        0.5446       0.7250        0.6963  0.1772\n",
      "     55        \u001b[36m0.5371\u001b[0m       0.6980        0.7023  0.1543\n",
      "     56        0.5381       0.7090        0.6994  0.2765\n",
      "     57        \u001b[36m0.5351\u001b[0m       0.7010        0.7112  0.1589\n",
      "     58        \u001b[36m0.5340\u001b[0m       0.7140        0.7081  0.1611\n",
      "     59        0.5350       0.7120        0.6971  0.1646\n",
      "     60        \u001b[36m0.5332\u001b[0m       0.7270        0.6995  0.1633\n",
      "     61        0.5342       0.7240        0.6860  0.1627\n",
      "     62        \u001b[36m0.5307\u001b[0m       0.7130        0.7172  0.1586\n",
      "     63        0.5325       0.7040        0.7217  0.1574\n",
      "     64        \u001b[36m0.5262\u001b[0m       0.7060        0.7172  0.1517\n",
      "     65        0.5327       0.7100        0.7151  0.1549\n",
      "     66        0.5292       0.6940        0.7368  0.1560\n",
      "     67        0.5271       0.6910        0.7315  0.1512\n",
      "     68        \u001b[36m0.5249\u001b[0m       0.7030        0.7196  0.1758\n",
      "     69        \u001b[36m0.5204\u001b[0m       0.7290        0.6873  0.2672\n",
      "     70        0.5259       0.7200        0.7191  0.1664\n",
      "     71        0.5242       0.7250        0.7329  0.1890\n",
      "     72        0.5219       0.7050        0.7496  0.1740\n",
      "     73        0.5214       0.6980        0.7469  0.1599\n",
      "     74        \u001b[36m0.5183\u001b[0m       0.7270        0.7288  0.1934\n",
      "     75        0.5202       0.7100        0.7559  0.1843\n",
      "     76        0.5216       0.7070        0.7406  0.1680\n",
      "     77        \u001b[36m0.5159\u001b[0m       0.7020        0.7604  0.1728\n",
      "     78        \u001b[36m0.5158\u001b[0m       0.7210        0.7218  0.1679\n",
      "     79        \u001b[36m0.5152\u001b[0m       0.7260        0.7113  0.1627\n",
      "     80        \u001b[36m0.5119\u001b[0m       0.6950        0.7801  0.1550\n",
      "     81        0.5150       0.6780        0.7834  0.1573\n",
      "     82        \u001b[36m0.5080\u001b[0m       0.6990        0.7836  0.1590\n",
      "     83        0.5136       0.7100        0.7539  0.1571\n",
      "     84        0.5131       0.6770        0.7992  0.1542\n",
      "     85        0.5143       0.7130        0.7527  0.1559\n",
      "     86        0.5095       0.7120        0.7437  0.1628\n",
      "     87        0.5108       0.6990        0.7579  0.1541\n",
      "     88        \u001b[36m0.5059\u001b[0m       0.7190        0.7652  0.1958\n",
      "     89        0.5067       0.6830        0.7932  0.2417\n",
      "     90        0.5078       0.6960        0.7542  0.1875\n",
      "     91        0.5133       0.6980        0.7623  0.1552\n",
      "     92        \u001b[36m0.5005\u001b[0m       0.6950        0.7750  0.1879\n",
      "     93        0.5059       0.6910        0.7898  0.2009\n",
      "     94        0.5035       0.6840        0.7572  0.1593\n",
      "     95        0.5024       0.6450        0.8541  0.1633\n",
      "     96        0.5047       0.6900        0.7761  0.1660\n",
      "     97        0.5074       0.6960        0.7552  0.1642\n",
      "     98        0.5047       0.6890        0.8115  0.1552\n",
      "     99        0.5044       0.7140        0.7727  0.1764\n",
      "    100        0.5047       0.6880        0.7982  0.1611\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8451\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6882\u001b[0m  0.1691\n",
      "      2        \u001b[36m0.7129\u001b[0m       0.6710        0.7414  0.1762\n",
      "      3        0.7131       0.6740        0.7137  0.2134\n",
      "      4        \u001b[36m0.6950\u001b[0m       0.6700        0.7305  0.1936\n",
      "      5        0.6994       0.6780        0.7304  0.1974\n",
      "      6        0.7148       0.6610        0.7480  0.2022\n",
      "      7        \u001b[36m0.6936\u001b[0m       0.6730        0.7162  0.1973\n",
      "      8        \u001b[36m0.6787\u001b[0m       0.6470        0.7475  0.1998\n",
      "      9        0.6935       0.6680        0.7034  0.1771\n",
      "     10        0.6849       0.6670        0.7458  0.1659\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8761\u001b[0m       \u001b[32m0.5810\u001b[0m        \u001b[35m0.7588\u001b[0m  0.1654\n",
      "      2        \u001b[36m0.7234\u001b[0m       \u001b[32m0.6170\u001b[0m        \u001b[35m0.7545\u001b[0m  0.1619\n",
      "      3        \u001b[36m0.7039\u001b[0m       0.5540        0.8119  0.1662\n",
      "      4        0.7090       \u001b[32m0.6220\u001b[0m        0.7551  0.1653\n",
      "      5        0.7280       0.5690        0.8556  0.1738\n",
      "      6        0.7170       0.5960        0.8031  0.1635\n",
      "      7        0.7172       0.6130        0.7677  0.1662\n",
      "      8        \u001b[36m0.6864\u001b[0m       0.5680        0.8406  0.1655\n",
      "      9        0.6865       0.5730        0.8972  0.1632\n",
      "     10        0.6917       0.5700        0.8432  0.1643\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5731\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1631\n",
      "      2       10.6176       0.3340       10.6176  0.1658\n",
      "      3       10.6176       0.3340       10.6176  0.1641\n",
      "      4       10.6176       0.3340       10.6176  0.1541\n",
      "      5       10.6176       0.3340       10.6176  0.1639\n",
      "      6       10.6176       0.3340       10.6176  0.2612\n",
      "      7       10.6176       0.3340       10.6176  0.1594\n",
      "      8       10.6176       0.3340       10.6176  0.1562\n",
      "      9       10.6176       0.3340       10.6176  0.1692\n",
      "     10       10.6176       0.3340       10.6176  0.1629\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5159\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1647\n",
      "      2       10.6176       0.3340       10.6176  0.1520\n",
      "      3       10.6176       0.3340       10.6176  0.1568\n",
      "      4       10.6176       0.3340       10.6176  0.1519\n",
      "      5       10.6176       0.3340       10.6176  0.1567\n",
      "      6       10.6176       0.3340       10.6176  0.1546\n",
      "      7       10.6176       0.3340       10.6176  0.2662\n",
      "      8       10.6176       0.3340       10.6176  0.1546\n",
      "      9       10.6176       0.3340       10.6176  0.1529\n",
      "     10       10.6176       0.3340       10.6176  0.1534\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8803\u001b[0m       \u001b[32m0.6680\u001b[0m        \u001b[35m0.7467\u001b[0m  0.1773\n",
      "      2        \u001b[36m0.7544\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.7192\u001b[0m  0.1657\n",
      "      3        \u001b[36m0.7190\u001b[0m       0.6680        0.7414  0.1623\n",
      "      4        \u001b[36m0.7066\u001b[0m       \u001b[32m0.6790\u001b[0m        \u001b[35m0.7089\u001b[0m  0.1629\n",
      "      5        \u001b[36m0.6920\u001b[0m       0.6790        \u001b[35m0.7013\u001b[0m  0.1606\n",
      "      6        \u001b[36m0.6871\u001b[0m       0.6750        0.7036  0.1590\n",
      "      7        0.6880       \u001b[32m0.6850\u001b[0m        \u001b[35m0.6932\u001b[0m  0.1646\n",
      "      8        0.6893       0.6850        0.7004  0.2727\n",
      "      9        \u001b[36m0.6868\u001b[0m       \u001b[32m0.6970\u001b[0m        \u001b[35m0.6826\u001b[0m  0.1618\n",
      "     10        0.6883       0.6900        0.6939  0.1619\n",
      "     11        \u001b[36m0.6842\u001b[0m       0.6890        0.7126  0.1596\n",
      "     12        0.6886       \u001b[32m0.7020\u001b[0m        \u001b[35m0.6770\u001b[0m  0.1602\n",
      "     13        0.6853       0.6840        0.7194  0.1636\n",
      "     14        \u001b[36m0.6732\u001b[0m       0.6790        0.7225  0.1585\n",
      "     15        0.6845       0.6980        0.6918  0.1623\n",
      "     16        \u001b[36m0.6719\u001b[0m       0.6720        0.7217  0.1615\n",
      "     17        0.6936       0.6890        0.7095  0.1639\n",
      "     18        0.6908       0.6870        0.7163  0.1726\n",
      "     19        0.6924       0.6910        0.7020  0.2440\n",
      "     20        \u001b[36m0.6674\u001b[0m       0.7000        0.6847  0.1900\n",
      "     21        \u001b[36m0.6646\u001b[0m       0.6930        0.7031  0.1671\n",
      "     22        0.6731       0.6980        0.7005  0.1625\n",
      "     23        0.6733       0.6580        0.7529  0.1741\n",
      "     24        0.7021       0.6950        0.6962  0.1623\n",
      "     25        0.6689       0.6960        0.6979  0.1615\n",
      "     26        0.6725       0.7010        0.6962  0.1636\n",
      "     27        0.6659       0.6980        0.6886  0.1677\n",
      "     28        0.6675       \u001b[32m0.7040\u001b[0m        0.6855  0.1558\n",
      "     29        \u001b[36m0.6610\u001b[0m       0.6920        0.7121  0.1583\n",
      "     30        0.6679       0.7040        0.6848  0.1647\n",
      "     31        \u001b[36m0.6585\u001b[0m       0.7000        0.6962  0.2922\n",
      "     32        0.6671       0.6990        0.6787  0.1652\n",
      "     33        0.6667       0.6980        0.6875  0.1585\n",
      "     34        0.6594       0.6830        0.7041  0.1695\n",
      "     35        0.6728       0.6940        0.6996  0.1648\n",
      "     36        0.6641       0.6980        0.6846  0.1671\n",
      "     37        0.6604       0.6860        0.7092  0.1672\n",
      "     38        0.6670       0.7010        \u001b[35m0.6768\u001b[0m  0.1613\n",
      "     39        0.6600       0.6880        0.6899  0.1561\n",
      "     40        0.6771       0.6810        0.7226  0.1592\n",
      "     41        0.6895       0.7040        0.6890  0.1635\n",
      "     42        0.6670       0.7010        0.6934  0.1666\n",
      "     43        0.6633       0.6890        0.6971  0.2466\n",
      "     44        0.6693       0.6860        0.7278  0.1807\n",
      "     45        0.6719       0.6990        0.6958  0.1587\n",
      "     46        0.6688       0.6920        0.6918  0.1593\n",
      "     47        \u001b[36m0.6582\u001b[0m       0.6980        0.6850  0.1604\n",
      "     48        \u001b[36m0.6566\u001b[0m       0.6980        0.6868  0.1682\n",
      "     49        0.6670       0.6900        0.7179  0.1591\n",
      "     50        0.6728       0.6940        0.7085  0.1553\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8456\u001b[0m       \u001b[32m0.6140\u001b[0m        \u001b[35m0.8051\u001b[0m  0.1756\n",
      "      2        \u001b[36m0.7138\u001b[0m       \u001b[32m0.6410\u001b[0m        0.8219  0.1674\n",
      "      3        \u001b[36m0.7101\u001b[0m       \u001b[32m0.6870\u001b[0m        \u001b[35m0.7339\u001b[0m  0.1647\n",
      "      4        \u001b[36m0.6923\u001b[0m       0.6570        0.7391  0.2723\n",
      "      5        \u001b[36m0.6779\u001b[0m       \u001b[32m0.6920\u001b[0m        \u001b[35m0.7231\u001b[0m  0.1626\n",
      "      6        \u001b[36m0.6668\u001b[0m       0.6350        0.7704  0.1706\n",
      "      7        0.6886       \u001b[32m0.7210\u001b[0m        \u001b[35m0.6947\u001b[0m  0.1653\n",
      "      8        0.6913       \u001b[32m0.7460\u001b[0m        \u001b[35m0.6467\u001b[0m  0.1659\n",
      "      9        \u001b[36m0.6586\u001b[0m       0.7240        0.6863  0.1693\n",
      "     10        0.6612       0.6830        0.7096  0.1700\n",
      "     11        0.6692       0.7320        0.6768  0.1605\n",
      "     12        0.6728       0.6830        0.6980  0.1615\n",
      "     13        0.6685       0.7400        0.6663  0.1664\n",
      "     14        \u001b[36m0.6502\u001b[0m       0.7390        0.6607  0.1599\n",
      "     15        0.6532       0.7380        0.6742  0.2205\n",
      "     16        0.6611       0.7440        0.6544  0.2050\n",
      "     17        0.6547       0.7360        0.6650  0.1626\n",
      "     18        0.6584       0.7360        0.6666  0.1856\n",
      "     19        0.6533       0.7390        0.6583  0.1767\n",
      "     20        0.6526       0.7360        0.6543  0.1609\n",
      "     21        \u001b[36m0.6483\u001b[0m       0.7440        \u001b[35m0.6395\u001b[0m  0.1742\n",
      "     22        0.6485       0.7460        \u001b[35m0.6393\u001b[0m  0.1550\n",
      "     23        0.6497       0.7400        0.6558  0.1541\n",
      "     24        0.6510       0.7400        0.6607  0.1636\n",
      "     25        0.6490       0.7410        0.6534  0.1646\n",
      "     26        0.6552       0.6930        0.7353  0.2032\n",
      "     27        0.7077       \u001b[32m0.7470\u001b[0m        0.6460  0.2507\n",
      "     28        0.6530       0.7450        0.6422  0.1675\n",
      "     29        0.6495       0.7120        0.6938  0.1755\n",
      "     30        0.6541       0.7420        0.6515  0.1567\n",
      "     31        0.6521       0.7400        0.6534  0.1708\n",
      "     32        0.6526       0.7370        0.6524  0.1609\n",
      "     33        0.6570       0.7430        0.6550  0.1651\n",
      "     34        0.6508       0.7390        0.6601  0.1616\n",
      "     35        0.6520       0.7360        0.6608  0.1790\n",
      "     36        0.6679       0.7400        0.6629  0.1640\n",
      "     37        0.6620       0.7370        0.6874  0.1651\n",
      "     38        0.6696       0.7410        0.6517  0.2829\n",
      "     39        0.6522       0.7200        0.6936  0.1805\n",
      "     40        0.6640       0.7420        0.6525  0.1834\n",
      "     41        0.6501       0.7440        0.6429  0.1595\n",
      "     42        \u001b[36m0.6446\u001b[0m       \u001b[32m0.7480\u001b[0m        0.6442  0.1651\n",
      "     43        \u001b[36m0.6434\u001b[0m       0.7460        0.6463  0.1735\n",
      "     44        0.6442       0.7450        0.6554  0.2025\n",
      "     45        0.6512       0.7420        0.6465  0.1802\n",
      "     46        0.6576       0.7410        0.6593  0.1717\n",
      "     47        0.6569       0.7440        0.6629  0.1923\n",
      "     48        0.6479       0.7450        0.6453  0.1837\n",
      "     49        \u001b[36m0.6428\u001b[0m       0.7420        0.6471  0.1645\n",
      "     50        0.6462       0.7420        0.6473  0.1628\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5755\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1706\n",
      "      2       10.6176       0.3340       10.6176  0.1596\n",
      "      3       10.6176       0.3340       10.6176  0.1550\n",
      "      4       10.6176       0.3340       10.6176  0.1866\n",
      "      5       10.6176       0.3340       10.6176  0.1664\n",
      "      6       10.6176       0.3340       10.6176  0.1463\n",
      "      7       10.6176       0.3340       10.6176  0.1615\n",
      "      8       10.6176       0.3340       10.6176  0.1715\n",
      "      9       10.6176       0.3340       10.6176  0.1770\n",
      "     10       10.6176       0.3340       10.6176  0.1665\n",
      "     11       10.6176       0.3340       10.6176  0.1543\n",
      "     12       10.6176       0.3340       10.6176  0.2667\n",
      "     13       10.6176       0.3340       10.6176  0.1569\n",
      "     14       10.6176       0.3340       10.6176  0.1547\n",
      "     15       10.6176       0.3340       10.6176  0.1534\n",
      "     16       10.6176       0.3340       10.6176  0.1684\n",
      "     17       10.6176       0.3340       10.6176  0.1761\n",
      "     18       10.6176       0.3340       10.6176  0.1580\n",
      "     19       10.6176       0.3340       10.6176  0.1560\n",
      "     20       10.6176       0.3340       10.6176  0.1536\n",
      "     21       10.6176       0.3340       10.6176  0.1526\n",
      "     22       10.6176       0.3340       10.6176  0.1638\n",
      "     23       10.6176       0.3340       10.6176  0.1740\n",
      "     24       10.6176       0.3340       10.6176  0.1561\n",
      "     25       10.6176       0.3340       10.6176  0.1560\n",
      "     26       10.6176       0.3340       10.6176  0.1571\n",
      "     27       10.6176       0.3340       10.6176  0.1586\n",
      "     28       10.6176       0.3340       10.6176  0.1579\n",
      "     29       10.6176       0.3340       10.6176  0.1904\n",
      "     30       10.6176       0.3340       10.6176  0.1650\n",
      "     31       10.6176       0.3340       10.6176  0.1560\n",
      "     32       10.6176       0.3340       10.6176  0.1773\n",
      "     33       10.6176       0.3340       10.6176  0.1875\n",
      "     34       10.6176       0.3340       10.6176  0.1718\n",
      "     35       10.6176       0.3340       10.6176  0.2683\n",
      "     36       10.6176       0.3340       10.6176  0.1921\n",
      "     37       10.6176       0.3340       10.6176  0.1680\n",
      "     38       10.6176       0.3340       10.6176  0.1505\n",
      "     39       10.6176       0.3340       10.6176  0.1648\n",
      "     40       10.6176       0.3340       10.6176  0.1488\n",
      "     41       10.6176       0.3340       10.6176  0.1437\n",
      "     42       10.6176       0.3340       10.6176  0.1467\n",
      "     43       10.6176       0.3340       10.6176  0.1859\n",
      "     44       10.6176       0.3340       10.6176  0.1974\n",
      "     45       10.6176       0.3340       10.6176  0.1361\n",
      "     46       10.6176       0.3340       10.6176  0.1476\n",
      "     47       10.6176       0.3340       10.6176  0.1383\n",
      "     48       10.6176       0.3340       10.6176  0.1494\n",
      "     49       10.6176       0.3340       10.6176  0.1413\n",
      "     50       10.6176       0.3340       10.6176  0.1496\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5160\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1471\n",
      "      2       10.6176       0.3340       10.6176  0.1483\n",
      "      3       10.6176       0.3340       10.6176  0.1408\n",
      "      4       10.6176       0.3340       10.6176  0.1485\n",
      "      5       10.6176       0.3340       10.6176  0.1699\n",
      "      6       10.6176       0.3340       10.6176  0.2052\n",
      "      7       10.6176       0.3340       10.6176  0.1573\n",
      "      8       10.6176       0.3340       10.6176  0.1563\n",
      "      9       10.6176       0.3340       10.6176  0.1594\n",
      "     10       10.6176       0.3340       10.6176  0.1653\n",
      "     11       10.6176       0.3340       10.6176  0.1546\n",
      "     12       10.6176       0.3340       10.6176  0.1539\n",
      "     13       10.6176       0.3340       10.6176  0.1590\n",
      "     14       10.6176       0.3340       10.6176  0.1563\n",
      "     15       10.6176       0.3340       10.6176  0.2143\n",
      "     16       10.6176       0.3340       10.6176  0.1919\n",
      "     17       10.6176       0.3340       10.6176  0.1527\n",
      "     18       10.6176       0.3340       10.6176  0.1566\n",
      "     19       10.6176       0.3340       10.6176  0.1542\n",
      "     20       10.6176       0.3340       10.6176  0.1703\n",
      "     21       10.6176       0.3340       10.6176  0.1502\n",
      "     22       10.6176       0.3340       10.6176  0.1565\n",
      "     23       10.6176       0.3340       10.6176  0.1500\n",
      "     24       10.6176       0.3340       10.6176  0.1529\n",
      "     25       10.6176       0.3340       10.6176  0.1530\n",
      "     26       10.6176       0.3340       10.6176  0.1558\n",
      "     27       10.6176       0.3340       10.6176  0.2431\n",
      "     28       10.6176       0.3340       10.6176  0.2845\n",
      "     29       10.6176       0.3340       10.6176  0.1491\n",
      "     30       10.6176       0.3340       10.6176  0.1571\n",
      "     31       10.6176       0.3340       10.6176  0.1539\n",
      "     32       10.6176       0.3340       10.6176  0.1515\n",
      "     33       10.6176       0.3340       10.6176  0.1584\n",
      "     34       10.6176       0.3340       10.6176  0.1475\n",
      "     35       10.6176       0.3340       10.6176  0.1541\n",
      "     36       10.6176       0.3340       10.6176  0.1548\n",
      "     37       10.6176       0.3340       10.6176  0.1478\n",
      "     38       10.6176       0.3340       10.6176  0.1479\n",
      "     39       10.6176       0.3340       10.6176  0.1562\n",
      "     40       10.6176       0.3340       10.6176  0.2400\n",
      "     41       10.6176       0.3340       10.6176  0.1755\n",
      "     42       10.6176       0.3340       10.6176  0.1468\n",
      "     43       10.6176       0.3340       10.6176  0.1491\n",
      "     44       10.6176       0.3340       10.6176  0.1532\n",
      "     45       10.6176       0.3340       10.6176  0.1527\n",
      "     46       10.6176       0.3340       10.6176  0.1539\n",
      "     47       10.6176       0.3340       10.6176  0.1552\n",
      "     48       10.6176       0.3340       10.6176  0.1502\n",
      "     49       10.6176       0.3340       10.6176  0.1469\n",
      "     50       10.6176       0.3340       10.6176  0.1535\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.9299\u001b[0m       \u001b[32m0.6110\u001b[0m        \u001b[35m0.8273\u001b[0m  0.1721\n",
      "      2        \u001b[36m0.8294\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.7751\u001b[0m  0.3371\n",
      "      3        \u001b[36m0.7599\u001b[0m       \u001b[32m0.6720\u001b[0m        \u001b[35m0.7521\u001b[0m  0.1796\n",
      "      4        0.7638       \u001b[32m0.6750\u001b[0m        \u001b[35m0.7426\u001b[0m  0.1580\n",
      "      5        \u001b[36m0.7509\u001b[0m       \u001b[32m0.6820\u001b[0m        \u001b[35m0.7355\u001b[0m  0.1604\n",
      "      6        \u001b[36m0.7450\u001b[0m       0.6390        0.7375  0.1609\n",
      "      7        \u001b[36m0.7412\u001b[0m       0.6380        0.7368  0.1788\n",
      "      8        \u001b[36m0.7405\u001b[0m       0.6390        0.7378  0.1661\n",
      "      9        0.7445       0.6410        0.7394  0.1638\n",
      "     10        0.7485       0.6370        0.7387  0.1555\n",
      "     11        0.7443       0.6430        0.7406  0.1670\n",
      "     12        \u001b[36m0.7402\u001b[0m       0.6450        0.7370  0.1583\n",
      "     13        0.7446       0.6460        0.7427  0.1563\n",
      "     14        0.7434       0.6460        0.7439  0.2729\n",
      "     15        0.7422       0.6430        0.7502  0.1641\n",
      "     16        0.7478       0.6410        0.7538  0.1672\n",
      "     17        0.7510       0.6420        0.7442  0.1665\n",
      "     18        0.7500       0.6320        0.7630  0.1563\n",
      "     19        0.7501       0.6350        0.7412  0.1533\n",
      "     20        0.7440       0.6310        0.7575  0.1794\n",
      "     21        0.7545       0.6330        0.7616  0.1627\n",
      "     22        0.7482       0.6430        0.7459  0.1610\n",
      "     23        0.7489       0.6480        0.7532  0.1698\n",
      "     24        0.7621       0.6480        0.7703  0.1549\n",
      "     25        0.7623       0.6490        0.7490  0.2864\n",
      "     26        \u001b[36m0.7379\u001b[0m       0.6360        0.7412  0.2698\n",
      "     27        0.7471       0.6410        0.7569  0.1650\n",
      "     28        0.7402       0.6490        0.7460  0.1662\n",
      "     29        \u001b[36m0.7360\u001b[0m       0.6500        0.7396  0.1602\n",
      "     30        \u001b[36m0.7353\u001b[0m       0.6490        0.7422  0.1785\n",
      "     31        0.7490       0.6470        0.7792  0.1569\n",
      "     32        0.7466       0.6470        0.7739  0.1552\n",
      "     33        0.7415       0.6490        0.7459  0.1605\n",
      "     34        \u001b[36m0.7349\u001b[0m       0.6480        0.7414  0.1705\n",
      "     35        0.7368       0.6380        0.7460  0.1544\n",
      "     36        0.7394       0.6470        0.7425  0.1560\n",
      "     37        0.7453       0.6460        0.7681  0.2496\n",
      "     38        0.7482       0.6500        0.7765  0.1702\n",
      "     39        0.7382       0.6490        0.7442  0.1579\n",
      "     40        0.7422       0.6440        0.7424  0.1661\n",
      "     41        0.7422       0.6320        0.7673  0.1622\n",
      "     42        0.7439       0.6450        0.7438  0.1650\n",
      "     43        0.7394       0.6400        0.7573  0.1624\n",
      "     44        0.7364       0.6450        0.7447  0.1577\n",
      "     45        0.7481       0.6480        0.7656  0.1613\n",
      "     46        0.7421       0.6450        0.7730  0.1607\n",
      "     47        0.7422       0.6440        0.7403  0.1636\n",
      "     48        \u001b[36m0.7331\u001b[0m       0.6470        0.7462  0.1551\n",
      "     49        0.7408       0.6460        0.7679  0.3470\n",
      "     50        0.7484       0.6470        0.7758  0.1708\n",
      "     51        0.7497       0.6460        0.7585  0.1734\n",
      "     52        0.7398       0.6450        0.7428  0.1630\n",
      "     53        0.7335       0.6470        \u001b[35m0.7330\u001b[0m  0.1669\n",
      "     54        0.7363       0.6490        0.7463  0.1735\n",
      "     55        0.7373       0.6480        0.7452  0.1719\n",
      "     56        0.7407       0.6450        0.7443  0.1788\n",
      "     57        0.7453       0.6370        0.7654  0.1773\n",
      "     58        0.7439       0.6360        0.7657  0.1969\n",
      "     59        0.7465       0.6400        0.7598  0.2236\n",
      "     60        0.7531       0.6400        0.7647  0.2076\n",
      "     61        0.7438       0.6450        0.7456  0.1990\n",
      "     62        0.7386       0.6490        0.7391  0.1752\n",
      "     63        0.7432       0.6480        0.7701  0.1844\n",
      "     64        0.7474       0.6440        0.7368  0.1726\n",
      "     65        0.7425       0.6440        0.7474  0.1782\n",
      "     66        0.7486       0.6400        0.7534  0.2144\n",
      "     67        0.7458       0.6470        0.7406  0.2278\n",
      "     68        0.7422       0.6470        0.7451  0.1558\n",
      "     69        0.7400       0.6470        0.7534  0.1548\n",
      "     70        0.7419       0.6500        0.7491  0.1612\n",
      "     71        0.7393       0.6480        0.7447  0.1608\n",
      "     72        0.7429       0.6520        0.7468  0.1486\n",
      "     73        0.7374       0.6490        0.7388  0.1898\n",
      "     74        0.7365       0.6480        0.7510  0.1719\n",
      "     75        0.7383       0.6480        0.7511  0.1505\n",
      "     76        0.7358       0.6430        0.7524  0.1544\n",
      "     77        0.7434       0.6470        0.7547  0.1527\n",
      "     78        0.7389       0.6420        0.7500  0.1647\n",
      "     79        0.7504       0.6380        0.7750  0.1490\n",
      "     80        0.7468       0.6470        0.7512  0.1505\n",
      "     81        0.7411       0.6440        0.7517  0.1506\n",
      "     82        0.7470       0.6430        0.7660  0.2665\n",
      "     83        0.7448       0.6490        0.7539  0.2975\n",
      "     84        0.7385       0.6490        0.7378  0.1921\n",
      "     85        0.7407       0.6500        0.7476  0.2114\n",
      "     86        0.7416       0.6480        0.7542  0.2217\n",
      "     87        0.7450       0.6480        0.7652  0.2476\n",
      "     88        0.7414       0.6480        0.7574  0.2246\n",
      "     89        0.7464       0.6460        0.7587  0.2229\n",
      "     90        0.7381       0.6470        0.7425  0.1636\n",
      "     91        0.7399       0.6400        0.7461  0.1565\n",
      "     92        0.7407       0.6470        0.7496  0.1549\n",
      "     93        0.7392       0.6480        0.7476  0.1500\n",
      "     94        0.7452       0.6430        0.7736  0.1581\n",
      "     95        0.7461       0.6460        0.7536  0.1571\n",
      "     96        0.7445       0.6390        0.7434  0.1605\n",
      "     97        0.7479       \u001b[32m0.6900\u001b[0m        \u001b[35m0.7287\u001b[0m  0.1502\n",
      "     98        0.7407       0.6490        0.7569  0.1456\n",
      "     99        0.7448       0.6430        0.7507  0.1699\n",
      "    100        0.7391       0.6500        0.7450  0.2802\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.8278\u001b[0m       \u001b[32m0.6270\u001b[0m        \u001b[35m0.7299\u001b[0m  0.3021\n",
      "      2        \u001b[36m0.6909\u001b[0m       \u001b[32m0.6560\u001b[0m        0.7861  0.2611\n",
      "      3        \u001b[36m0.6854\u001b[0m       \u001b[32m0.6650\u001b[0m        0.7624  0.2841\n",
      "      4        \u001b[36m0.6844\u001b[0m       \u001b[32m0.6670\u001b[0m        0.7724  0.2784\n",
      "      5        \u001b[36m0.6733\u001b[0m       \u001b[32m0.6740\u001b[0m        0.7660  0.2979\n",
      "      6        0.6836       \u001b[32m0.7150\u001b[0m        \u001b[35m0.7149\u001b[0m  0.2680\n",
      "      7        0.6909       0.6110        0.7515  0.2067\n",
      "      8        0.6910       0.6830        0.7489  0.1734\n",
      "      9        0.7115       \u001b[32m0.7300\u001b[0m        \u001b[35m0.7136\u001b[0m  0.1671\n",
      "     10        0.6917       0.5780        0.7947  0.1559\n",
      "     11        0.7234       0.6890        0.7435  0.1566\n",
      "     12        0.7169       0.7250        \u001b[35m0.6757\u001b[0m  0.1570\n",
      "     13        0.7038       0.7190        0.6982  0.1798\n",
      "     14        0.6824       \u001b[32m0.7400\u001b[0m        \u001b[35m0.6598\u001b[0m  0.1858\n",
      "     15        \u001b[36m0.6710\u001b[0m       \u001b[32m0.7420\u001b[0m        \u001b[35m0.6595\u001b[0m  0.2416\n",
      "     16        \u001b[36m0.6592\u001b[0m       0.7380        0.6597  0.1708\n",
      "     17        0.6643       \u001b[32m0.7440\u001b[0m        0.6735  0.1621\n",
      "     18        \u001b[36m0.6569\u001b[0m       0.7440        0.6693  0.1561\n",
      "     19        \u001b[36m0.6530\u001b[0m       0.7400        0.6643  0.1591\n",
      "     20        0.6613       0.7440        0.6612  0.1739\n",
      "     21        0.6554       0.7350        \u001b[35m0.6451\u001b[0m  0.1823\n",
      "     22        0.6560       0.7380        \u001b[35m0.6420\u001b[0m  0.1605\n",
      "     23        \u001b[36m0.6528\u001b[0m       0.7380        0.6487  0.1533\n",
      "     24        0.6557       0.7100        0.6738  0.1606\n",
      "     25        0.6687       0.7120        0.6941  0.1580\n",
      "     26        0.6702       0.7340        0.6944  0.2610\n",
      "     27        0.6569       0.7390        0.6605  0.3329\n",
      "     28        \u001b[36m0.6474\u001b[0m       \u001b[32m0.7470\u001b[0m        0.6482  0.2073\n",
      "     29        \u001b[36m0.6464\u001b[0m       0.7380        \u001b[35m0.6377\u001b[0m  0.1798\n",
      "     30        0.6523       0.7310        0.6758  0.1736\n",
      "     31        0.6850       0.7360        0.6514  0.1865\n",
      "     32        0.6478       0.7460        0.6501  0.1720\n",
      "     33        0.6578       0.7340        0.6771  0.1571\n",
      "     34        0.6865       \u001b[32m0.7490\u001b[0m        0.6634  0.1873\n",
      "     35        0.6488       0.7480        0.6598  0.1769\n",
      "     36        0.6472       0.7390        0.6469  0.1436\n",
      "     37        \u001b[36m0.6455\u001b[0m       0.7480        0.6569  0.1720\n",
      "     38        0.6522       0.7390        0.6559  0.2090\n",
      "     39        \u001b[36m0.6422\u001b[0m       0.7480        0.6719  0.3064\n",
      "     40        0.6523       0.7370        0.6508  0.2957\n",
      "     41        0.6442       \u001b[32m0.7520\u001b[0m        0.6574  0.2995\n",
      "     42        0.6460       0.7380        0.6548  0.3512\n",
      "     43        0.6477       0.7490        0.6397  0.2927\n",
      "     44        0.6434       0.7380        0.6392  0.2846\n",
      "     45        0.6423       0.7490        0.6402  0.3534\n",
      "     46        0.6498       0.7380        0.6391  0.1714\n",
      "     47        0.6484       0.7450        0.6465  0.1733\n",
      "     48        0.6569       0.7170        0.6808  0.1817\n",
      "     49        0.6698       0.7490        0.6688  0.1633\n",
      "     50        0.6515       0.7400        0.6570  0.1621\n",
      "     51        0.6510       0.7310        0.6644  0.1538\n",
      "     52        0.6760       0.7460        0.6687  0.1578\n",
      "     53        0.6621       0.7440        0.6585  0.1593\n",
      "     54        0.6469       0.7400        \u001b[35m0.6333\u001b[0m  0.1587\n",
      "     55        \u001b[36m0.6402\u001b[0m       0.7460        0.6371  0.1470\n",
      "     56        0.6408       0.7490        0.6435  0.2034\n",
      "     57        0.6408       0.7390        0.6374  0.1635\n",
      "     58        \u001b[36m0.6399\u001b[0m       0.7470        0.6389  0.1537\n",
      "     59        0.6425       0.7510        0.6483  0.1674\n",
      "     60        0.6499       0.6900        0.6890  0.1718\n",
      "     61        0.6646       0.6840        0.7016  0.1723\n",
      "     62        0.6525       0.7380        0.6593  0.1846\n",
      "     63        0.6473       0.7000        0.6883  0.2293\n",
      "     64        0.6550       0.6930        0.7233  0.1932\n",
      "     65        0.7441       0.7450        0.6694  0.1634\n",
      "     66        0.6525       \u001b[32m0.7530\u001b[0m        0.6434  0.1634\n",
      "     67        0.6432       0.7530        0.6465  0.1660\n",
      "     68        \u001b[36m0.6394\u001b[0m       0.7440        0.6425  0.1662\n",
      "     69        \u001b[36m0.6377\u001b[0m       0.7460        0.6433  0.1605\n",
      "     70        0.6386       0.7530        0.6440  0.1801\n",
      "     71        0.6400       0.7520        0.6441  0.3028\n",
      "     72        0.6430       0.7380        \u001b[35m0.6332\u001b[0m  0.2788\n",
      "     73        0.6417       0.6950        0.6810  0.2950\n",
      "     74        0.6505       0.7450        0.6655  0.3077\n",
      "     75        0.6531       0.7180        0.7006  0.1573\n",
      "     76        0.6857       0.7500        0.6666  0.1541\n",
      "     77        0.6574       0.7500        0.6575  0.1526\n",
      "     78        0.6451       0.7390        0.6374  0.1578\n",
      "     79        0.6406       0.7490        0.6498  0.1533\n",
      "     80        0.6431       0.6840        0.6918  0.1505\n",
      "     81        0.6480       0.7360        0.6595  0.1586\n",
      "     82        0.6472       0.7360        0.6666  0.1495\n",
      "     83        0.6630       0.7480        0.6591  0.1795\n",
      "     84        0.6498       0.7150        0.6783  0.1638\n",
      "     85        0.6482       0.7410        \u001b[35m0.6242\u001b[0m  0.1721\n",
      "     86        0.6434       0.7490        0.6424  0.3719\n",
      "     87        0.6411       0.7490        0.6406  0.2290\n",
      "     88        0.6440       0.7360        0.6607  0.1870\n",
      "     89        0.6442       0.7500        0.6421  0.1630\n",
      "     90        0.6452       0.7380        0.6476  0.1861\n",
      "     91        0.6461       0.7490        0.6716  0.1730\n",
      "     92        0.6464       0.7390        0.6534  0.1967\n",
      "     93        0.6481       \u001b[32m0.7560\u001b[0m        0.6429  0.1868\n",
      "     94        0.6450       0.7320        0.6485  0.1718\n",
      "     95        0.6470       0.7500        0.6531  0.1937\n",
      "     96        0.6514       0.7370        0.6549  0.1855\n",
      "     97        0.6456       0.7500        0.6491  0.1778\n",
      "     98        0.6462       0.7340        0.6580  0.1710\n",
      "     99        0.6451       0.7430        0.6608  0.1734\n",
      "    100        0.6475       0.7500        0.6684  0.1533\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5761\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1579\n",
      "      2       10.6176       0.3340       10.6176  0.1428\n",
      "      3       10.6176       0.3340       10.6176  0.1441\n",
      "      4       10.6176       0.3340       10.6176  0.1544\n",
      "      5       10.6176       0.3340       10.6176  0.1530\n",
      "      6       10.6176       0.3340       10.6176  0.1502\n",
      "      7       10.6176       0.3340       10.6176  0.1381\n",
      "      8       10.6176       0.3340       10.6176  0.1461\n",
      "      9       10.6176       0.3340       10.6176  0.1474\n",
      "     10       10.6176       0.3340       10.6176  0.1516\n",
      "     11       10.6176       0.3340       10.6176  0.1593\n",
      "     12       10.6176       0.3340       10.6176  0.1658\n",
      "     13       10.6176       0.3340       10.6176  0.1612\n",
      "     14       10.6176       0.3340       10.6176  0.1569\n",
      "     15       10.6176       0.3340       10.6176  0.1549\n",
      "     16       10.6176       0.3340       10.6176  0.1542\n",
      "     17       10.6176       0.3340       10.6176  0.1502\n",
      "     18       10.6176       0.3340       10.6176  0.1542\n",
      "     19       10.6176       0.3340       10.6176  0.1401\n",
      "     20       10.6176       0.3340       10.6176  0.1551\n",
      "     21       10.6176       0.3340       10.6176  0.2680\n",
      "     22       10.6176       0.3340       10.6176  0.2494\n",
      "     23       10.6176       0.3340       10.6176  0.1515\n",
      "     24       10.6176       0.3340       10.6176  0.1473\n",
      "     25       10.6176       0.3340       10.6176  0.1482\n",
      "     26       10.6176       0.3340       10.6176  0.1472\n",
      "     27       10.6176       0.3340       10.6176  0.1567\n",
      "     28       10.6176       0.3340       10.6176  0.1490\n",
      "     29       10.6176       0.3340       10.6176  0.1507\n",
      "     30       10.6176       0.3340       10.6176  0.1444\n",
      "     31       10.6176       0.3340       10.6176  0.1537\n",
      "     32       10.6176       0.3340       10.6176  0.1511\n",
      "     33       10.6176       0.3340       10.6176  0.1572\n",
      "     34       10.6176       0.3340       10.6176  0.2727\n",
      "     35       10.6176       0.3340       10.6176  0.3804\n",
      "     36       10.6176       0.3340       10.6176  0.1511\n",
      "     37       10.6176       0.3340       10.6176  0.1451\n",
      "     38       10.6176       0.3340       10.6176  0.1483\n",
      "     39       10.6176       0.3340       10.6176  0.1457\n",
      "     40       10.6176       0.3340       10.6176  0.1435\n",
      "     41       10.6176       0.3340       10.6176  0.1496\n",
      "     42       10.6176       0.3340       10.6176  0.1490\n",
      "     43       10.6176       0.3340       10.6176  0.1524\n",
      "     44       10.6176       0.3340       10.6176  0.1520\n",
      "     45       10.6176       0.3340       10.6176  0.1469\n",
      "     46       10.6176       0.3340       10.6176  0.1490\n",
      "     47       10.6176       0.3340       10.6176  0.1626\n",
      "     48       10.6176       0.3340       10.6176  0.2684\n",
      "     49       10.6176       0.3340       10.6176  0.2946\n",
      "     50       10.6176       0.3340       10.6176  0.3005\n",
      "     51       10.6176       0.3340       10.6176  0.2648\n",
      "     52       10.6176       0.3340       10.6176  0.2772\n",
      "     53       10.6176       0.3340       10.6176  0.3134\n",
      "     54       10.6176       0.3340       10.6176  0.1806\n",
      "     55       10.6176       0.3340       10.6176  0.1551\n",
      "     56       10.6176       0.3340       10.6176  0.1745\n",
      "     57       10.6176       0.3340       10.6176  0.1603\n",
      "     58       10.6176       0.3340       10.6176  0.1691\n",
      "     59       10.6176       0.3340       10.6176  0.1661\n",
      "     60       10.6176       0.3340       10.6176  0.1536\n",
      "     61       10.6176       0.3340       10.6176  0.1577\n",
      "     62       10.6176       0.3340       10.6176  0.1907\n",
      "     63       10.6176       0.3340       10.6176  0.1565\n",
      "     64       10.6176       0.3340       10.6176  0.1617\n",
      "     65       10.6176       0.3340       10.6176  0.2747\n",
      "     66       10.6176       0.3340       10.6176  0.2882\n",
      "     67       10.6176       0.3340       10.6176  0.2692\n",
      "     68       10.6176       0.3340       10.6176  0.2657\n",
      "     69       10.6176       0.3340       10.6176  0.3152\n",
      "     70       10.6176       0.3340       10.6176  0.2318\n",
      "     71       10.6176       0.3340       10.6176  0.1512\n",
      "     72       10.6176       0.3340       10.6176  0.1642\n",
      "     73       10.6176       0.3340       10.6176  0.1548\n",
      "     74       10.6176       0.3340       10.6176  0.1526\n",
      "     75       10.6176       0.3340       10.6176  0.1745\n",
      "     76       10.6176       0.3340       10.6176  0.1489\n",
      "     77       10.6176       0.3340       10.6176  0.1461\n",
      "     78       10.6176       0.3340       10.6176  0.1541\n",
      "     79       10.6176       0.3340       10.6176  0.1496\n",
      "     80       10.6176       0.3340       10.6176  0.1499\n",
      "     81       10.6176       0.3340       10.6176  0.1777\n",
      "     82       10.6176       0.3340       10.6176  0.2672\n",
      "     83       10.6176       0.3340       10.6176  0.3162\n",
      "     84       10.6176       0.3340       10.6176  0.1576\n",
      "     85       10.6176       0.3340       10.6176  0.1544\n",
      "     86       10.6176       0.3340       10.6176  0.1537\n",
      "     87       10.6176       0.3340       10.6176  0.1593\n",
      "     88       10.6176       0.3340       10.6176  0.1447\n",
      "     89       10.6176       0.3340       10.6176  0.1612\n",
      "     90       10.6176       0.3340       10.6176  0.1588\n",
      "     91       10.6176       0.3340       10.6176  0.1715\n",
      "     92       10.6176       0.3340       10.6176  0.1618\n",
      "     93       10.6176       0.3340       10.6176  0.1463\n",
      "     94       10.6176       0.3340       10.6176  0.1447\n",
      "     95       10.6176       0.3340       10.6176  0.2807\n",
      "     96       10.6176       0.3340       10.6176  0.2853\n",
      "     97       10.6176       0.3340       10.6176  0.2833\n",
      "     98       10.6176       0.3340       10.6176  0.1472\n",
      "     99       10.6176       0.3340       10.6176  0.1517\n",
      "    100       10.6176       0.3340       10.6176  0.1571\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1       \u001b[36m10.5158\u001b[0m       \u001b[32m0.3340\u001b[0m       \u001b[35m10.6176\u001b[0m  0.1496\n",
      "      2       10.6176       0.3340       10.6176  0.1527\n",
      "      3       10.6176       0.3340       10.6176  0.1548\n",
      "      4       10.6176       0.3340       10.6176  0.1646\n",
      "      5       10.6176       0.3340       10.6176  0.1609\n",
      "      6       10.6176       0.3340       10.6176  0.1488\n",
      "      7       10.6176       0.3340       10.6176  0.1531\n",
      "      8       10.6176       0.3340       10.6176  0.2392\n",
      "      9       10.6176       0.3340       10.6176  0.2744\n",
      "     10       10.6176       0.3340       10.6176  0.2722\n",
      "     11       10.6176       0.3340       10.6176  0.2996\n",
      "     12       10.6176       0.3340       10.6176  0.2725\n",
      "     13       10.6176       0.3340       10.6176  0.3228\n",
      "     14       10.6176       0.3340       10.6176  0.1396\n",
      "     15       10.6176       0.3340       10.6176  0.1445\n",
      "     16       10.6176       0.3340       10.6176  0.1444\n",
      "     17       10.6176       0.3340       10.6176  0.1519\n",
      "     18       10.6176       0.3340       10.6176  0.1521\n",
      "     19       10.6176       0.3340       10.6176  0.1459\n",
      "     20       10.6176       0.3340       10.6176  0.1601\n",
      "     21       10.6176       0.3340       10.6176  0.1608\n",
      "     22       10.6176       0.3340       10.6176  0.1583\n",
      "     23       10.6176       0.3340       10.6176  0.1487\n",
      "     24       10.6176       0.3340       10.6176  0.1562\n",
      "     25       10.6176       0.3340       10.6176  0.2012\n",
      "     26       10.6176       0.3340       10.6176  0.3193\n",
      "     27       10.6176       0.3340       10.6176  0.1528\n",
      "     28       10.6176       0.3340       10.6176  0.1493\n",
      "     29       10.6176       0.3340       10.6176  0.1457\n",
      "     30       10.6176       0.3340       10.6176  0.1510\n",
      "     31       10.6176       0.3340       10.6176  0.1458\n",
      "     32       10.6176       0.3340       10.6176  0.1518\n",
      "     33       10.6176       0.3340       10.6176  0.1522\n",
      "     34       10.6176       0.3340       10.6176  0.1434\n",
      "     35       10.6176       0.3340       10.6176  0.1438\n",
      "     36       10.6176       0.3340       10.6176  0.1533\n",
      "     37       10.6176       0.3340       10.6176  0.1425\n",
      "     38       10.6176       0.3340       10.6176  0.2148\n",
      "     39       10.6176       0.3340       10.6176  0.3158\n",
      "     40       10.6176       0.3340       10.6176  0.2794\n",
      "     41       10.6176       0.3340       10.6176  0.3226\n",
      "     42       10.6176       0.3340       10.6176  0.1757\n",
      "     43       10.6176       0.3340       10.6176  0.1689\n",
      "     44       10.6176       0.3340       10.6176  0.1564\n",
      "     45       10.6176       0.3340       10.6176  0.1421\n",
      "     46       10.6176       0.3340       10.6176  0.1484\n",
      "     47       10.6176       0.3340       10.6176  0.1446\n",
      "     48       10.6176       0.3340       10.6176  0.1868\n",
      "     49       10.6176       0.3340       10.6176  0.1685\n",
      "     50       10.6176       0.3340       10.6176  0.1501\n",
      "     51       10.6176       0.3340       10.6176  0.1590\n",
      "     52       10.6176       0.3340       10.6176  0.1550\n",
      "     53       10.6176       0.3340       10.6176  0.3258\n",
      "     54       10.6176       0.3340       10.6176  0.2942\n",
      "     55       10.6176       0.3340       10.6176  0.1634\n",
      "     56       10.6176       0.3340       10.6176  0.1669\n",
      "     57       10.6176       0.3340       10.6176  0.1630\n",
      "     58       10.6176       0.3340       10.6176  0.1465\n",
      "     59       10.6176       0.3340       10.6176  0.1664\n",
      "     60       10.6176       0.3340       10.6176  0.1559\n",
      "     61       10.6176       0.3340       10.6176  0.1681\n",
      "     62       10.6176       0.3340       10.6176  0.1684\n",
      "     63       10.6176       0.3340       10.6176  0.1565\n",
      "     64       10.6176       0.3340       10.6176  0.1568\n",
      "     65       10.6176       0.3340       10.6176  0.1585\n",
      "     66       10.6176       0.3340       10.6176  0.2786\n",
      "     67       10.6176       0.3340       10.6176  0.1622\n",
      "     68       10.6176       0.3340       10.6176  0.1877\n",
      "     69       10.6176       0.3340       10.6176  0.1646\n",
      "     70       10.6176       0.3340       10.6176  0.1580\n",
      "     71       10.6176       0.3340       10.6176  0.1465\n",
      "     72       10.6176       0.3340       10.6176  0.1645\n",
      "     73       10.6176       0.3340       10.6176  0.1737\n",
      "     74       10.6176       0.3340       10.6176  0.2595\n",
      "     75       10.6176       0.3340       10.6176  0.1812\n",
      "     76       10.6176       0.3340       10.6176  0.1685\n",
      "     77       10.6176       0.3340       10.6176  0.1596\n",
      "     78       10.6176       0.3340       10.6176  0.1707\n",
      "     79       10.6176       0.3340       10.6176  0.1561\n",
      "     80       10.6176       0.3340       10.6176  0.1660\n",
      "     81       10.6176       0.3340       10.6176  0.1506\n",
      "     82       10.6176       0.3340       10.6176  0.1685\n",
      "     83       10.6176       0.3340       10.6176  0.1596\n",
      "     84       10.6176       0.3340       10.6176  0.1588\n",
      "     85       10.6176       0.3340       10.6176  0.1692\n",
      "     86       10.6176       0.3340       10.6176  0.2677\n",
      "     87       10.6176       0.3340       10.6176  0.1549\n",
      "     88       10.6176       0.3340       10.6176  0.1559\n",
      "     89       10.6176       0.3340       10.6176  0.1460\n",
      "     90       10.6176       0.3340       10.6176  0.1585\n",
      "     91       10.6176       0.3340       10.6176  0.1515\n",
      "     92       10.6176       0.3340       10.6176  0.1551\n",
      "     93       10.6176       0.3340       10.6176  0.1819\n",
      "     94       10.6176       0.3340       10.6176  0.1980\n",
      "     95       10.6176       0.3340       10.6176  0.2732\n",
      "     96       10.6176       0.3340       10.6176  0.1548\n",
      "     97       10.6176       0.3340       10.6176  0.1495\n",
      "     98       10.6176       0.3340       10.6176  0.1499\n",
      "     99       10.6176       0.3340       10.6176  0.1690\n",
      "    100       10.6176       0.3340       10.6176  0.1476\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7246\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.6862\u001b[0m  0.6411\n",
      "      2        \u001b[36m0.6455\u001b[0m       0.6840        \u001b[35m0.6812\u001b[0m  0.5656\n",
      "      3        \u001b[36m0.6293\u001b[0m       \u001b[32m0.7045\u001b[0m        \u001b[35m0.6698\u001b[0m  0.8517\n",
      "      4        \u001b[36m0.6202\u001b[0m       \u001b[32m0.7115\u001b[0m        \u001b[35m0.6634\u001b[0m  0.8162\n",
      "      5        \u001b[36m0.6175\u001b[0m       0.7105        \u001b[35m0.6515\u001b[0m  0.5969\n",
      "      6        \u001b[36m0.6120\u001b[0m       0.7115        \u001b[35m0.6504\u001b[0m  0.6021\n",
      "      7        \u001b[36m0.6105\u001b[0m       \u001b[32m0.7185\u001b[0m        \u001b[35m0.6456\u001b[0m  0.8513\n",
      "      8        0.6108       \u001b[32m0.7250\u001b[0m        \u001b[35m0.6353\u001b[0m  0.5947\n",
      "      9        \u001b[36m0.6064\u001b[0m       0.7165        0.6407  0.5860\n",
      "     10        \u001b[36m0.6064\u001b[0m       0.7165        0.6384  0.5411\n",
      "     11        \u001b[36m0.6039\u001b[0m       0.7165        0.6382  0.6815\n",
      "     12        \u001b[36m0.6007\u001b[0m       \u001b[32m0.7265\u001b[0m        \u001b[35m0.6318\u001b[0m  0.7312\n",
      "     13        \u001b[36m0.5968\u001b[0m       0.7220        \u001b[35m0.6299\u001b[0m  0.5974\n",
      "     14        \u001b[36m0.5962\u001b[0m       \u001b[32m0.7355\u001b[0m        \u001b[35m0.6157\u001b[0m  0.5934\n",
      "     15        \u001b[36m0.5926\u001b[0m       0.7260        0.6270  0.5698\n",
      "     16        \u001b[36m0.5918\u001b[0m       0.7240        0.6356  0.5322\n",
      "     17        \u001b[36m0.5908\u001b[0m       0.7325        0.6308  0.5251\n",
      "     18        \u001b[36m0.5887\u001b[0m       0.7250        0.6312  0.5618\n",
      "     19        \u001b[36m0.5871\u001b[0m       0.7195        0.6415  0.5803\n",
      "     20        \u001b[36m0.5856\u001b[0m       0.7305        0.6168  0.5392\n",
      "     21        \u001b[36m0.5849\u001b[0m       0.7295        0.6367  0.8237\n",
      "     22        \u001b[36m0.5846\u001b[0m       0.7305        0.6363  0.5401\n",
      "     23        \u001b[36m0.5816\u001b[0m       0.7280        0.6459  0.5387\n",
      "     24        \u001b[36m0.5802\u001b[0m       \u001b[32m0.7375\u001b[0m        0.6306  0.5568\n",
      "     25        0.5808       0.7220        0.6535  1.0250\n",
      "     26        0.5804       0.7280        0.6507  0.8752\n",
      "     27        \u001b[36m0.5773\u001b[0m       0.7175        0.6596  0.5441\n",
      "     28        \u001b[36m0.5762\u001b[0m       0.7240        0.6472  0.5559\n",
      "     29        \u001b[36m0.5747\u001b[0m       0.7255        0.6456  0.5813\n",
      "     30        0.5756       0.7225        0.6577  1.0778\n",
      "     31        \u001b[36m0.5745\u001b[0m       0.7170        0.6556  0.8564\n",
      "     32        \u001b[36m0.5731\u001b[0m       0.7245        0.6610  0.5438\n",
      "     33        0.5735       0.7270        0.6534  0.5314\n",
      "     34        \u001b[36m0.5718\u001b[0m       0.7365        0.6442  0.5724\n",
      "     35        0.5730       0.7275        0.6429  0.7652\n",
      "     36        \u001b[36m0.5674\u001b[0m       0.7250        0.6597  0.5437\n",
      "     37        0.5734       0.7285        0.6486  0.5816\n",
      "     38        \u001b[36m0.5665\u001b[0m       0.7270        0.6481  0.6299\n",
      "     39        \u001b[36m0.5662\u001b[0m       0.7330        0.6445  0.5357\n",
      "     40        0.5732       0.7230        0.6416  0.5427\n",
      "     41        0.5687       0.7175        0.6617  0.6151\n",
      "     42        0.5665       0.7310        0.6484  0.9549\n",
      "     43        \u001b[36m0.5644\u001b[0m       0.7315        0.6420  0.5510\n",
      "     44        0.5669       0.7320        0.6417  0.5363\n",
      "     45        0.5647       0.7255        0.6721  0.6985\n",
      "     46        0.5695       0.7350        0.6470  0.5308\n",
      "     47        \u001b[36m0.5604\u001b[0m       0.7305        0.6464  0.5326\n",
      "     48        0.5614       0.7360        0.6492  0.5141\n",
      "     49        0.5604       0.7345        0.6593  0.7440\n",
      "     50        0.5612       0.7315        0.6452  0.5385\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;dtf&#x27;,\n",
       "                                        &lt;__main__.Data_Transformer object at 0x0000013688E27670&gt;),\n",
       "                                       (&#x27;rescale&#x27;,\n",
       "                                        &lt;__main__.CustomScaler object at 0x0000013688E27190&gt;),\n",
       "                                       (&#x27;nn_model&#x27;,\n",
       "                                        &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       "))]),\n",
       "             param_grid={&#x27;nn_model__batch_size&#x27;: [32, 64],\n",
       "                         &#x27;nn_model__lr&#x27;: [0.01, 0.1],\n",
       "                         &#x27;nn_model__max_epochs&#x27;: [10, 50, 100],\n",
       "                         &#x27;nn_model__optimizer&#x27;: [&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;,\n",
       "                                                 &lt;class &#x27;torch.optim.rmsprop.RMSprop&#x27;&gt;]},\n",
       "             scoring=make_scorer(f1_score, average=macro))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[(&#x27;dtf&#x27;,\n",
       "                                        &lt;__main__.Data_Transformer object at 0x0000013688E27670&gt;),\n",
       "                                       (&#x27;rescale&#x27;,\n",
       "                                        &lt;__main__.CustomScaler object at 0x0000013688E27190&gt;),\n",
       "                                       (&#x27;nn_model&#x27;,\n",
       "                                        &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       "))]),\n",
       "             param_grid={&#x27;nn_model__batch_size&#x27;: [32, 64],\n",
       "                         &#x27;nn_model__lr&#x27;: [0.01, 0.1],\n",
       "                         &#x27;nn_model__max_epochs&#x27;: [10, 50, 100],\n",
       "                         &#x27;nn_model__optimizer&#x27;: [&lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;,\n",
       "                                                 &lt;class &#x27;torch.optim.rmsprop.RMSprop&#x27;&gt;]},\n",
       "             scoring=make_scorer(f1_score, average=macro))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;dtf&#x27;,\n",
       "                 &lt;__main__.Data_Transformer object at 0x0000013688E27670&gt;),\n",
       "                (&#x27;rescale&#x27;,\n",
       "                 &lt;__main__.CustomScaler object at 0x0000013688E27190&gt;),\n",
       "                (&#x27;nn_model&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Data_Transformer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.Data_Transformer object at 0x0000013688E27670&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomScaler</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.CustomScaler object at 0x0000013688E27190&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.NeuralNetwork&#x27;&gt;,\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('dtf',\n",
       "                                        <__main__.Data_Transformer object at 0x0000013688E27670>),\n",
       "                                       ('rescale',\n",
       "                                        <__main__.CustomScaler object at 0x0000013688E27190>),\n",
       "                                       ('nn_model',\n",
       "                                        <class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=<class '__main__.NeuralNetwork'>,\n",
       "))]),\n",
       "             param_grid={'nn_model__batch_size': [32, 64],\n",
       "                         'nn_model__lr': [0.01, 0.1],\n",
       "                         'nn_model__max_epochs': [10, 50, 100],\n",
       "                         'nn_model__optimizer': [<class 'torch.optim.adam.Adam'>,\n",
       "                                                 <class 'torch.optim.rmsprop.RMSprop'>]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gsv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn_model__batch_size': 32,\n",
       " 'nn_model__lr': 0.01,\n",
       " 'nn_model__max_epochs': 50,\n",
       " 'nn_model__optimizer': torch.optim.adam.Adam}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gsv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_nn_model__batch_size</th>\n",
       "      <th>param_nn_model__lr</th>\n",
       "      <th>param_nn_model__max_epochs</th>\n",
       "      <th>param_nn_model__optimizer</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.704429</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.673782</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.710414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.684510</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.701483</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.668877</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.452640</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.192988</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.490864</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.597045</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.663224</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.676165</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.694855</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.626682</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.671117</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.655199</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.544374</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.695011</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.585325</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.166917</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_nn_model__batch_size param_nn_model__lr param_nn_model__max_epochs  \\\n",
       "0                          32               0.01                         10   \n",
       "1                          32               0.01                         10   \n",
       "2                          32               0.01                         50   \n",
       "3                          32               0.01                         50   \n",
       "4                          32               0.01                        100   \n",
       "5                          32               0.01                        100   \n",
       "6                          32                0.1                         10   \n",
       "7                          32                0.1                         10   \n",
       "8                          32                0.1                         50   \n",
       "9                          32                0.1                         50   \n",
       "10                         32                0.1                        100   \n",
       "11                         32                0.1                        100   \n",
       "12                         64               0.01                         10   \n",
       "13                         64               0.01                         10   \n",
       "14                         64               0.01                         50   \n",
       "15                         64               0.01                         50   \n",
       "16                         64               0.01                        100   \n",
       "17                         64               0.01                        100   \n",
       "18                         64                0.1                         10   \n",
       "19                         64                0.1                         10   \n",
       "20                         64                0.1                         50   \n",
       "21                         64                0.1                         50   \n",
       "22                         64                0.1                        100   \n",
       "23                         64                0.1                        100   \n",
       "\n",
       "                param_nn_model__optimizer  mean_test_score  rank_test_score  \n",
       "0         <class 'torch.optim.adam.Adam'>         0.704429                2  \n",
       "1   <class 'torch.optim.rmsprop.RMSprop'>         0.673782                8  \n",
       "2         <class 'torch.optim.adam.Adam'>         0.710414                1  \n",
       "3   <class 'torch.optim.rmsprop.RMSprop'>         0.684510                6  \n",
       "4         <class 'torch.optim.adam.Adam'>         0.701483                3  \n",
       "5   <class 'torch.optim.rmsprop.RMSprop'>         0.668877               10  \n",
       "6         <class 'torch.optim.adam.Adam'>         0.452640               18  \n",
       "7   <class 'torch.optim.rmsprop.RMSprop'>         0.192988               19  \n",
       "8         <class 'torch.optim.adam.Adam'>         0.490864               17  \n",
       "9   <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  \n",
       "10        <class 'torch.optim.adam.Adam'>         0.597045               14  \n",
       "11  <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  \n",
       "12        <class 'torch.optim.adam.Adam'>         0.663224               11  \n",
       "13  <class 'torch.optim.rmsprop.RMSprop'>         0.676165                7  \n",
       "14        <class 'torch.optim.adam.Adam'>         0.694855                5  \n",
       "15  <class 'torch.optim.rmsprop.RMSprop'>         0.626682               13  \n",
       "16        <class 'torch.optim.adam.Adam'>         0.671117                9  \n",
       "17  <class 'torch.optim.rmsprop.RMSprop'>         0.655199               12  \n",
       "18        <class 'torch.optim.adam.Adam'>         0.544374               16  \n",
       "19  <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  \n",
       "20        <class 'torch.optim.adam.Adam'>         0.695011                4  \n",
       "21  <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  \n",
       "22        <class 'torch.optim.adam.Adam'>         0.585325               15  \n",
       "23  <class 'torch.optim.rmsprop.RMSprop'>         0.166917               20  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model_gsv.cv_results_\n",
    "result = pd.DataFrame(result)[['param_nn_model__batch_size', 'param_nn_model__lr','param_nn_model__max_epochs', 'param_nn_model__optimizer', 'mean_test_score', 'rank_test_score']]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model_gsv.predict(X_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76       822\n",
      "           1       0.73      0.84      0.78      1217\n",
      "           2       0.64      0.59      0.62       461\n",
      "\n",
      "    accuracy                           0.74      2500\n",
      "   macro avg       0.74      0.71      0.72      2500\n",
      "weighted avg       0.75      0.74      0.74      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 564,  214,   44],\n",
       "       [  86, 1022,  109],\n",
       "       [  16,  171,  274]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30888103e-02, 9.84650433e-01, 2.26077903e-03],\n",
       "       [7.34853558e-03, 9.85004067e-01, 7.64735555e-03],\n",
       "       [3.41168374e-01, 4.66080397e-01, 1.92751274e-01],\n",
       "       ...,\n",
       "       [2.33499352e-02, 9.68199909e-01, 8.45009368e-03],\n",
       "       [5.76199405e-02, 9.40133929e-01, 2.24616705e-03],\n",
       "       [7.19382544e-04, 1.15241855e-01, 8.84038806e-01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_proba = model_gsv.predict_proba(X_test)\n",
    "y_test_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Receiver Operating Characteristic - NeuralNetworkClassifier (PyTorch)')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for class_idx in range(len(model_gsv.best_estimator_.classes_)):\n",
    "    y_true = (y_test == model_gsv.best_estimator_.classes_[class_idx]).astype(int)\n",
    "    y_pred_proba = y_test_pred_proba[:, class_idx]\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'Class {model_gsv.best_estimator_.classes_[class_idx]} (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - NeuralNetworkClassifier (PyTorch)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
